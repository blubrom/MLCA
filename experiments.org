#+EXPORT_EXCLUDE_TAGS: noexport

#+TITLE: Experiments for validating our tool

In order to validate our tool we first need to conduct some
experiments to ensure that it produces results consistent with the
state of the art. Our tool estimates manufacture impacts of the
hardware used and energy consumption over the usage duration (typically
during the training phase of a model). We therefore want to test those
two parts. 
Firstly, we will present experiments aimed at testing the
estimates for the dynamic energy consumption (and the results we will
present will therefore focus only on the energy consumption estimated
and on the Carbon footprint induced by this energy consumption). These experiments will
start by reproducing the same exact results as the
Green Algorithms tool, by first choosing a scenario were we know that
our tool and Green Algorithms use the same data. Then, we will focus
on reproducing results presented in the two surveys of existing tools
(\cite{Bannours2021evaluating} and
\cite{Jay2023experimental}). Finally, we will try to reproduce results
obtained with a different method than the one used by our tool. This
will be done by trying to reproduce results from
\cite{Dinarelli2022toward}, \cite{Cattan2022benchmarking} and
\cite{Strubell2019energy}. We chose those articles because they all
use a different tool (even if measures presented in these three
articles are based on the \gls{RAPL} and \gls{NVLM} tools), because we
were able to contact the authors of
\cite{Dinarelli2022toward,Cattan2022benchmarking} to obtain further
details about the hardware configuration they use ; Because
\cite{Cattan2022benchmarking} presents results about the inference
phase of models which is a phase that is rarely studied and because
\cite{Strubell2019energy} was the paper that made NLP researchers
consider the impacts of the models they produced.
Secondly, we will compare the results our tool produces with \gls{LCA}
results produced by Dell about the impacts of the servers they
sell. This will allow us to validate the estimations of embodied
impacts our tool generates.
Finally, we will try to reproduce the results from
\cite{Luccionni2022estimating}, this step is really important because
this paper conducts an analysis of the global warming potential
induced by the Bloom model. This analysis takes into account embodied
emissions and we use figures they present to define the default
dynamic ratio our tool uses.

* Setup the experiments                                            :noexport:
first, run the program, we will then be able to send it requests with
the following command:

`pipenv run uvicorn boaviztapi.main:app --host=localhost --port 5000`

this must be realised in another terminal and not in emacs because,
since it does not terminate, trying to execute it in your emacs would
make your emacs wait for the death of the process forever.

* Defining some helper functions to easily run experiments and read their results :noexport:
header with all used packages

  #+begin_src python :results output :exports none :session
import numpy as np
import pandas as pd
import copy
import json
import subprocess
from datetime import datetime
import matplotlib.pyplot as plt
import tabulate
  #+end_src

  #+RESULTS:

then, we define a helper function to be able to more easily run
experiments and store their results in a more readable way
#+begin_src python :results output :exports none  :session
def run_experiment(model, filename, directory='../results', silent=False):
  with open("tmp.json", "w") as tmp:
    json.dump(model, tmp)
  path = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + filename + ".json"
  with open(path, "w") as out:
    request = "curl -X 'POST' 'http://localhost:5000/v1/mlca/?verbose=true' -H 'accept: aplication/json' -H 'Content-Type: application/json' -d @tmp.json"
    results = subprocess.run(request, shell=True, check=True, capture_output=True, text=True)
    output = json.JSONDecoder().decode(results.stdout)
    impacts = output["impacts"]
    perspective = output["perspective"]
    if not silent:
      print(f"estimated impacts: {impacts}")
      print(f"to put impacts in perspective: {perspective}")
    json.dump(output, out, indent=4, ensure_ascii=True)
    subprocess.run("rm tmp.json", shell=True)
    return output
#+end_src

#+RESULTS:

Full results are put into the results repository under a name that is
prefixed with the date-time of running the experiment.

As most of the comparisons we are able to make are referring to \gls{GWP} and
energy consumption only, let us also define a helper function
to print those results.

#+begin_src python :results output :exports none  :session
def print_gwp_and_energy(results):
    dynamic_energy = results["impacts"]["energy consumption"]
    direct_gwp = results["impacts"]["gwp"]
    print(f"energy consumption: {dynamic_energy}")
    print(f"dynamic impacts gwp: {direct_gwp}")
    return dynamic_energy['value'], direct_gwp['direct']
#+end_src

#+RESULTS:

For running experiments about the manufacture impacts of servers
#+begin_src python :results output :exports none :session
def run_experiment_server(model, filename, directory='../results', silent=False):
  with open("tmp.json", "w") as tmp:
    json.dump(model, tmp)
  path = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + filename + ".json"
  with open(path, "w") as out:
    request = "curl -X 'POST' 'http://localhost:5000/v1/server/?verbose=true' -H 'accept: aplication/json' -H 'Content-Type: application/json' -d @tmp.json"
    results = subprocess.run(request, shell=True, check=True, capture_output=True, text=True)
    output = json.JSONDecoder().decode(results.stdout)
    impacts = output["impacts"]
    json.dump(output, out, indent=4, ensure_ascii=True)
    subprocess.run("rm tmp.json", shell=True)
    return output

def print_impacts_server(out):
    gwp = out["impacts"]['gwp']
    pe = out["impacts"]['pe']
    adp = out["impacts"]['adp']
    print(f"GWP: {gwp}")
    print(f"PE: {pe}")
    print(f"ADP: {adp}")
#+end_src

#+RESULTS:

For plotting pie charts of the distribution of gwp by components
  #+begin_src python :results output :exports none :session
def get_result_component(results, component):
    return results['verbose'][component + '-1']["impacts"]['gwp']['value']

def get_results_components(results):
    res = {}
    for c in ['CPU', 'RAM', 'SSD', 'POWER_SUPPLY', 'CASE', 'MOTHERBOARD', 'ASSEMBLY']:
        res[c] = get_result_component(results, c)
    return res


def pie_chart(impacts_dict, name,  directory='../results'):
    filename = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + name + ".svg"
    fig, ax = plt.subplots()
    ax.pie(impacts_dict.values(), labels=impacts_dict.keys(), autopct='%1.1f%%')
    ax.set_title("Part Production -" + name + "\nGWP 100 years [kg CO2e]")
    fig.savefig(filename)
    return filename

  #+end_src

  #+RESULTS:


  #+begin_src python :results output :exports none :session
def to_org_table(table):
    return tabulate.tabulate(table, tablefmt='orgtbl', headers="keys", showindex=False)

def rename_multi_index(df, old_col, new_col):
    df.columns = df.columns.values
    df.columns = pd.MultiIndex.from_tuples(df.rename(columns={old_col: new_col}))

def multi_index_to_multiline_header(table):
    names = ['\n'.join(i) for i in table.columns.values]
    table.columns = names
    return table
  #+end_src

  #+RESULTS:


* Checking that we can get the same dynamic consumption estimate as Green Algorithms

To do a first sanity check, we verify that we are able to reproduce
the same results as GA on the dynamic consumption part :

We choose a configuration that we know is available in both databases
(GA version 2.2 at the time of this experiment):
- 1 CPU A8-7680 (4 cores)
- 1 GPU NVIDIA GTX 1080 Ti
- 64 GB Memory

- Use time of 12h 0min
- no PUE / dynamic ratio
- carbon intensity of France is used (51.28 g CO_2 e/kWh)

We are using Green Algorithms v2.2
for an expected result of 196.32g of CO_2 e and 3.83 kWh of dynamic
consumption (this [[http://calculator.green-algorithms.org//?runTime_hour=12&runTime_min=0&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=4&CPUmodel=A8-7680&numberGPUs=1&GPUmodel=NVIDIA%20GTX%201080%20Ti&memory=64&platformType=localServer][link]] should in theory get you to the page with this
exact setup and results but it seems like GA sharing feature is broken right
now).

If we now run the experiment with our tool :
#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/test_equals_ga.json", 'r') as test_ga:
    model_ga = json.load(test_ga)
results = run_experiment(model_ga, "test_equals_ga.json")

print_gwp_and_energy(results)
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 0.2, 'direct': 0.196, 'total': 0.39, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 2.6, 'direct': 49.3, 'total': 52.0, 'unit': 'MJ'}, 'adp': {'embodied': 3.4e-05, 'direct': 2.46e-07, 'total': 3.4e-05, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 3.83, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 0.0002, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 0.0004, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 0.0011, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: energy consumption: {'value': 3.83, 'unit': 'kWh'}
: dynamic impacts gwp: {'embodied': 0.2, 'direct': 0.196, 'total': 0.39, 'unit': 'kgCO2eq'}

we see that we indeed obtain the same results of 196gCO_2 e and 3.83
kWh of dynamic energy consumption.

* replicating results from \cite{Bannour2021evaluating}
In order to replicate results, we first need to gather some
information about the hardware configuration used to run the
experiments. Then, we will face the challenge of inconsistencies in the
data presented in the paper. Finally, we will be able to run
experiments that give the same energy consumption estimates as those
presented in the paper.

** detailing the Hardware configurations
The authors provided us with information about the hardware
configurations used to run  the experiments. 

the facility setup is the [[https://doc.lab-ia.fr/][LaBia]] cluster. We can see that the only nodes using a
20 core CPU are: n[101-102]:

-  2 x Intel Xeon Gold 6148 20 cores / 40 threads @ 2.4 GHz (Skylake)
-  384 GiB of RAM
-  4 x NVIDIA Tesla V100 with 32 GiB of RAM (NVLink)

using 32 GB of RAM and not the full 384.

The lab server on the other hand is the Segur machine, using one GTX 1080 Ti with 11GB of memory.
it is a Dell PowerEdge R730 with 2 GTX 1080 Ti, 2 Intel Ben E5-2620
v4 CPU and 125 GB memory (only 11 of which are requested).

while we do not have the Intel Xeon Gold 6148 in our CPU database, we
can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/120489/intel-xeon-gold-6148-processor-27-5m-cache-2-40-ghz/specifications.html][Intel's website]] that it has a \gls{TDP} of 150W, was released in
2017 with a process of 14nm with the Skylake architecture, this is
sufficient information to add one entry to our database, knowing the
information about the Skylake architecture from [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)][WikiChips]]. 

** Problems with the provided data

Results presented in the paper do not seem coherent from one table to
the other (tables 3 and 4). If we try to convert from energy consumption to carbon
emissions using the presented carbon intensity of 39 gCO_2 e/kWh we do
not at all find the same results as the ones presented.
For instance, for the first method (Yu2020) for the French Press
benchmark, it is indicated 1.38kWh consumption and 350.15g CO_2 e.

We can see that if we are to use the presented carbon intensity, we
get emissions of src_python{return round(39*1.38,1)}
{{{results(=53.8=)}}} gCO_2 e for a 1.38kWh energy consumption. This is
really far from the 350 gCO_2 e presented in the paper.

*** Trying to understand the problem

 Let us check if the factor to convert from table 4 to table 3 is
 constant.
 If it is, it would maybe explain the problems. When filling the table
 the authors might have miss-clicked on the location and the Carbon
 Intensity used would just be the one of another country.

 #+begin_src python :results output :exports none
import numpy as np
emissions = [350.15,260.26,16.67,14.31,20.68,20.03,104.4,102.08,3.83,4.99,5.57,5.67]
energy = [1.38,1.03,0.07,0.06,0.08,0.08,0.41,0.40,.02,.02,.02,.02]
CI = [em / en for en, em in zip(energy, emissions)]
print(CI, np.mean(CI))

 #+end_src

 #+RESULTS:
 : [253.73188405797103, 252.6796116504854, 238.14285714285714, 238.50000000000003, 258.5, 250.375, 254.63414634146343, 255.2, 191.5, 249.5, 278.5, 283.5] 250.39695826606476

 We obtain results around 250 gCO_2 e/kWh with some non negligible
 variations (The smallest conversion factor is of 191.5 gCO_2 e/kWh
 while the highest is of 283.5 gCO_2 e/kWh)

 according to GA's v2.2 database, this carbon intensity of around 250gCO_2
 e/kWh would approximately correspond to Lithuania's one. According to
 the version 1.1 of the data (version seemingly used in the article),
 the closest one would be Hungary.

 Still, we can observe quite important variations in carbon intensity
 to convert from the presented energy consumption to the presented
 carbon emissions, this would tend to infirm the hypothesis of just an
 error of selection in the carbon intensity used. 

 Even if there are obviously problems with the presented data, we still
 want to try and replicate the presented results. Indeed, if the data
 is flawed only in the table presenting the energy consumption or only
 in the table presented the carbon footprint, we might be able to
 reproduce the results of one of the tables (i.e. either the
 consumption or the carbon footprint)

** experiments
It is said that the default \gls{PUE} used is 1.67. In order to replicate
the results, and even if the dynamic ratio and the \gls{PUE} do not have the
same meaning. Since they are both used in the same way we will use a
dynamic ratio of 1.67

we can see in [[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/TDP_gpu.csv][the latest version of Green Algorithms' GPU TDP database]]
that they have a \gls{TDP} value of 300W for a Tesla V100 GPU whereas we
have a \gls{TDP} of 250W for the same card in our database. In order to see
if we can replicate the same consumption and see the difference
resulting from this data-point inconsistency we will try two
versions. One with a V100 and one with a card with a \gls{TDP}
of 300W in our database: the NVIDIA A100 PCIe 80 GB. This will of
course also impact the manufacture impacts but we are here only focusing on
reproducing the same direct impacts

#+begin_src python :results value raw :exports results :session
table = pd.read_csv("expected/expected_bannour.csv", header=[0,1,2,3])

index =  pd.MultiIndex.from_tuples(table.columns.values)
index = index.set_levels(['Facility only', '', '','','','','',''], level=2, verify_integrity=False)
table.columns = index

rename_multi_index(table, ('Method','Unnamed: 0_level_1','','Unnamed: 0_level_3'), ('Method', '','', ''))
rename_multi_index(table,('Task','Unnamed: 1_level_1','','Unnamed: 1_level_3'), ('Task','','', ''))
rename_multi_index(table,('Hardware','Unnamed: 2_level_1','','Unnamed: 2_level_3'),('Hardware','','', ''))


def set(method, task, hardware, col, value):
    table.loc[(table[('Method','','','')] == method) & (table[('Task','','','')] == task) & (table[('Hardware','','','')] == hardware), col] = value

with open("boaviztapi/data/ml_setups/LaBia.json", 'r') as m:
    labia = json.load(m)
with open("boaviztapi/data/ml_setups/Segur.json", 'r') as m:
    segur = json.load(m)

labia["server"]["configuration"]["ram"][0]["capacity"] = 32
segur["server"]["configuration"]["ram"][0]["capacity"] = 11

labia["gpu"][0]['units'] = 1
segur["gpu"][0]['units'] = 1

labia["cpu_usage"] = 0
segur["cpu_usage"] = 0

labia['usage']['gwp_factor'] = 39E-3
segur['usage']['gwp_factor'] = 39E-3

labia['usage']['dynamic_ratio'] = 1.67
segur['usage']['dynamic_ratio'] = 1.67



def estimate(model, task, time_server, time_facility):
   print(task)
   print('server')
   segur["usage"][ "minute_use_time"] = time_server
   output = run_experiment(segur, model + '_' + task + '_Server', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, "Server", ('Estimated', 'Energy', '','(kWh)'), energy)
   set(model, task, "Server", ('Estimated', 'Carbon','','(gCO2e)'), gwp * 1000)
   print('Facility')
   labia["gpu"][0]["model"] = "NVIDIA Tesla V100 PCIe 32 GB"
   labia["usage"][ "minute_use_time"] = time_facility
   output = run_experiment(labia, model + '_' + task + '_Facility', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, 'Facility', ('Estimated', 'Energy','', '(kWh)'), energy)
   set(model, task, 'Facility', ('Estimated', 'Carbon','','(gCO2e)'), gwp * 1000)
   print('Facility same TDP')
   labia["gpu"][0]["model"] = "NVIDIA A100 PCIe 80 GB"
   labia["usage"][ "minute_use_time"] = time_facility
   output = run_experiment(labia, model + '_' + task + '_Facility_match_TDP', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, 'Facility', ('Estimation', 'trying to match', 'Facility only','(kWh)'), energy)
   set(model, task, 'Facility', ('Estimation', 'trying to match', 'Facility only', '(gCO2e)'), gwp * 1000)

print('Yu2020')
estimate("Yu2020", "French Press", 163 + 39/60, 118 + 4/60)
estimate("Yu2020", "EMEA", 9 + 31/60, 6 + 51/60)
estimate("Yu2020", "MEDLINE", 11 + 55/60, 9 + 11/60)

print('\nMa2016')
estimate("Ma2016", "French Press", 58 + 30/60, 46 + 44/60)
estimate("Ma2016", "EMEA", 2 + 14/60, 2 + 27/60)
estimate("Ma2016", "MEDLINE", 3 + 11/60, 2 + 58/60)  

multi_index_to_multiline_header(table)
to_org_table(table)
#+end_src

#+RESULTS:
| Method | Task         | Hardware | Expected | Estimated |      Estimation | Expected | Estimated |      Estimation |
|        |              |          |   Energy |    Energy | trying to match |   Carbon |    Carbon | trying to match |
|        |              |          |          |           |   Facility only |          |           |   Facility only |
|        |              |          |    (kWh) |     (kWh) |           (kWh) |  (gCO2e) |   (gCO2e) |         (gCO2e) |
|--------+--------------+----------+----------+-----------+-----------------+----------+-----------+-----------------|
| Yu2020 | French Press | Server   |     1.38 |      1.16 |             nan |   350.15 |      45.1 |             nan |
| Yu2020 | French Press | Facility |     1.03 |     0.861 |            1.03 |   260.26 |      33.6 |              40 |
| Yu2020 | EMEA         | Server   |     0.07 |    0.0673 |             nan |    16.67 |      2.62 |             nan |
| Yu2020 | EMEA         | Facility |     0.06 |    0.0499 |          0.0595 |    14.31 |      1.95 |            2.32 |
| Yu2020 | MEDLINE      | Server   |     0.08 |    0.0843 |             nan |    20.68 |      3.29 |             nan |
| Yu2020 | MEDLINE      | Facility |     0.08 |    0.0669 |          0.0797 |    20.03 |      2.61 |            3.11 |
| Ma2016 | French Press | Server   |     0.41 |     0.414 |             nan |    104.4 |      16.1 |             nan |
| Ma2016 | French Press | Facility |      0.4 |     0.341 |           0.406 |   102.08 |      13.3 |            15.8 |
| Ma2016 | EMEA         | Server   |     0.02 |    0.0158 |             nan |      3.8 |     0.616 |             nan |
| Ma2016 | EMEA         | Facility |     0.02 |    0.0179 |          0.0213 |     4.99 |     0.697 |            0.83 |
| Ma2016 | MEDLINE      | Server   |     0.02 |    0.0225 |             nan |     5.57 |     0.878 |             nan |
| Ma2016 | MEDLINE      | Facility |     0.02 |    0.0216 |          0.0258 |     5.67 |     0.843 |               1 |

We can see that we are able to obtain the same exact energy consumption
estimates up to rounding (when we do the modifications to the inputed setup for the
facility) except for Yu2020, French Press, Server where we have a
slightly lower estimation than the one proposed in the paper.
We can also see that, as expected, the estimates we do when
considering the "real" setup are lower than the ones presented in the
paper and this can be entirely explained by the difference in \gls{TDP} in
the database.
We can also conclude that the problem in the presented data lies in
the estimates of the carbon footprint and not in the estimates of
energy consumption.


* replicating results from \cite{Jay2023experimental} 

In order to replicate the results from the paper, we first need to
gather some information from the paper and its supplementary material
which is designed to allow for reproducible experiments.

- The hardware used is a Nvidia DGX-1 with two Intel Xeon E5-2698 v4,
512 GB of memory and 8 NVIDIA Tesla V100-SXM2-32GB. 

- The Carbon Intensity for France used in Green Algorithms V2.2 is
51.28gCO_2 e/kWh ([[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/CI_aggregated.csv][latest version of Green Algorithms' Carbon Intensity
Database]])

- To convert from kWh to kJ, one must multiply the result by 3.6E+3.

we can see in [[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/TDP_gpu.csv][the latest version of Green Algorithms' GPU TDP database]]
that they have a \gls{TDP} value of 300W for an NVIDIA V100 GPU whereas we
have a \gls{TDP} of 250W for the same card in our database. As a first
version, just to see if we are able to obtain the same exact results
as those presented in the paper, we will use as GPUs a card with a \gls{TDP}
of 300W in our database: the NVIDIA A100 PCIe 80 GB.

We can also see that the CPU model used is the Xeon E5-2698 v4 with a
tdp 135. However, it isn't available in Green Algorithm, the model
used is the Xeon E5-2697 v4 with a \gls{TDP} of 145W and 18 cores.
In order to reproduce the results presented in the paper, we will use
in our setup one CPU with 40 cores, a \gls{TDP} of 324W (145/18*40) and a
die size of 9.12cm² (2*the die size of a Xeon E5-2698 v4, not relevant
for the computation of energy)

In the notebook accompanying the paper, we can see that the link explaining the configuration used for the CPU benchmarks are
exact copies of the ones for GPU benchmarks. We will therefore assume
that the CPU usage was 1 and GPU usage was 0. This configuration leads
to an energy consumption of 8.58Wh for one minute. Since this value is
strangely similar to the value of 7.58Wh/min used in the paper, we will also assume that there was a mistake when copying
results from the Green Algorithm website and therefore use the value
of 8.58Wh/min instead of the value of 7.58Wh/min to compute the
expected results.

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)
    dgx_1_model_correct = copy.deepcopy(dgx_1_model)

def get_energy_joules(results):
    energy_kWh = results['impacts']['energy consumption']['value']
    energy_J = 3.6E3*energy_kWh
    return(f"energy consumption: {energy_J:.3f} kJ", energy_J)

# expected results
online_tools = {}

# GPU
online_tools['Green Algorithm GPU'] = {}
online_tools['Green Algorithm GPU']['EP'] = (43.18 * 68 / 60) * 3.6 # converting to joules https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=1&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['LU'] = (31.18 * 204 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.7&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['MG'] = (14.26 * 157 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0.2&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.25&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['idle'] = (2.29 * 157 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0&memory=512&platformType=localServer

# CPU
online_tools['Green Algorithm CPU'] = {}
online_tools['Green Algorithm CPU']['EP'] = (8.58 * 50 / 60) * 3.6 # converting to joules https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=1&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['LU'] = (8.58 * 30 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.7&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['MG'] = (8.58 * 125 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0.2&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.25&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['idle'] = (0 * 60 / 60) * 3.6 

def experiment(model, core_type, task, benchmark, cpu_usage, gpu_usage, time):
    print(benchmark)
    model['cpu_usage'] = cpu_usage
    model['gpu_usage'] = gpu_usage
    model['usage']['minute_use_time'] = time
    output = run_experiment(model, f'{core_type}_{benchmark}_{task}', directory='Jay2023experimental')
    s, r = get_energy_joules(output)
    diff ="{:.3f}".format(r - online_tools['Green Algorithm ' + core_type][benchmark])
    print(s, f"difference from expectation: {diff} kJ")
    return r, diff



def experiments_gpu(model, task):
    print('GPU benchmark')
    df = pd.DataFrame(columns=['Benchmark','Value (kJ)','Difference (kJ)'])
    
    energy, diff = experiment(model, 'GPU', task, 'EP', 0, 1, 68/60)
    df = df.append({'Benchmark':'EP','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'GPU', task,'LU', 0, .7, 204/60)
    df = df.append({'Benchmark':'LU','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'GPU', task,'MG', .2, .25, 157/60)
    df = df.append({'Benchmark':'MG','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    return df

def experiments_cpu(model, task):
    print('\nCPU benchmark')
    df = pd.DataFrame(columns=['Benchmark','Value (kJ)','Difference (kJ)'])
    energy, diff = experiment(model, 'CPU', task, 'EP', 1, 0, 50/60)
    df = df.append({'Benchmark':'EP','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'CPU', task, 'LU', 1, 0, 30/60)
    df = df.append({'Benchmark':'LU','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'CPU', task, 'MG', 1, 0, 125/60)
    df = df.append({'Benchmark':'MG','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    return df


def experiments(model,task):
    experiments_gpu(model, task)
    experiments_cpu(model, task)



#print('Replicating the exact results')

dgx_1_model['server']['configuration']['cpu'] = {
          "units": 1,
          "die_size": 9.12,
	  "tdp": 324,
	  "core_units":40
}
dgx_1_model['gpu'] = [
  {
      "units": 8,
      "model": "NVIDIA A100 PCIe 80 GB"
  }
]

#experiments(dgx_1_model)
#print('\nRunning the experiments with the "correct" setup')
#experiments(dgx_1_model_correct)
#+end_src

#+RESULTS:

When trying to obtain the exact same results (same hardware setup as used for
obtaining values with Green Algorithms)
for the GPU benchmark
#+begin_src python :results value raw :exports results :session
to_org_table(experiments_gpu(dgx_1_model, 'match'))
#+end_src

#+RESULTS:
| Benchmark | Value (kJ) | Difference (kJ) |
|-----------+------------+-----------------|
| EP        |     176.04 |          -0.134 |
| LU        |      381.6 |          -0.043 |
| MG        |     134.28 |          -0.049 |

for the CPU benchmarks
#+begin_src python :results value raw :exports results :session
to_org_table(experiments_cpu(dgx_1_model, 'match'))
#+end_src

#+RESULTS:
| Benchmark | Value (kJ) | Difference (kJ) |
|-----------+------------+-----------------|
| EP        |      25.74 |               0 |
| LU        |     15.444 |               0 |
| MG        |      64.44 |            0.09 |


When using the hardware setup really used:
for the GPU benchmark
#+begin_src python :results value raw :exports results :session
to_org_table(experiments_gpu(dgx_1_model_correct, 'correct'))
#+end_src

#+RESULTS:
| Benchmark | Value (kJ) | Difference (kJ) |
|-----------+------------+-----------------|
| EP        |     149.04 |         -27.134 |
| LU        |     324.36 |         -57.283 |
| MG        |        117 |         -17.329 |

for the CPU benchmarks
#+begin_src python :results value raw :exports results :session
to_org_table(experiments_cpu(dgx_1_model_correct, 'correct'))
#+end_src

#+RESULTS:
| Benchmark | Value (kJ) | Difference (kJ) |
|-----------+------------+-----------------|
| EP        |      23.04 |            -2.7 |
| LU        |     13.824 |           -1.62 |
| MG        |       57.6 |           -6.75 |

We can see that we are able to obtain results that are exactly the
same as the expected ones up to rounding errors (difference 3 orders of magnitude
lesser than the value). We can also see that even though the input
value to Green Algorithms does not exactly correspond to the hardware
setup used, the difference to the expected
results isn't too high. The difference between our estimate using
'correct' data and the expected values is around 10 times less than the estimated value..
These results demonstrate the importance of inputting the right
hardware if one wants precise results.

* replicating results from \cite{Dinarelli2022toward}

As for other experiments aiming at reproducing results, we first need
to gather enough information to run our 
experiments. We will also check the consistency of the results
presented in the paper. This will allow us to run our estimates.
We will focus on two results that we will try to reproduce. First the
fine tuning of the SSL model which is the most time consuming task
presented and then we will focus on the training time for the spectro
model, this should allow us to get a good overview of the results.

** setup experiments                                               :noexport:
First, let us define a prototype ml setup. We will use it to define
the different hardware configurations. This will help us easily run
the different experiments to reconstruct the results from the
different tables.

  #+begin_src python :results both :exports none :session
model = {
"server": {},
"gpu": [],
"psf": 1,
"nb_nodes": 1,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "dynamic_ratio": 1,
  "hours_use_time": 0,
  "minute_use_time": 118.04,
  "usage_location": "FRA",
  "gwp_factor": 51E-3
}
}
  #+end_src

  #+RESULTS:



** Trying to find information about the hardware setup

The authors gave us some insight on the hardware used for running
their experiments. Without their help, we would not have been able to
produce a single estimate. 

*** quote from the author                                          :noexport:
#+begin_quote 
En tout cas, pour essayer de te donner les info dont tu as besoin, après si c'est pas ça, ou si tu as besoin d'autres informations, n'hésite pas à demander :
"CPU : nombre de coeurs utilisés, modèle" => je ne sais pas combien de coeur CPU sont utilisé par les modèles wav2vec que j'ai utilisé, mes modèles SLU en utilise un seul.
"GPU : nombre utilisés et modèles, mémoire utilisée" (je présume que
tu voulais écrire "nombre de coeur utilisés") => 
4 GPU pendant 100 heures pour fine-tuner le modèle wav2vec (seulement pour les expériences où il est fine-tuné évidemment), 1 seule GPU pour mes modèles SLU.

Pour la taille des modèles :
environ 308 millions de paramètres pour le modèle wav2vec2
environ 12 millions de paramètres pour le modèle SLU

Pour la mémoire utilisée, on est à environ 80GB de mémoire centrale (RAM de la CPU) et environ 8GB de mémoire GPU pour les entraînements des mes modèles SLU.
Pour le fine-tuning des modèles wav2vec je ne sais pas, je n'ai jamais regardé pendant l'apprentissage de ces modèles, je sais que ça passe pas sur les GPU à 24GB du LIG, du coup j'ai dû le faire sur JZ sur la partition de GPU à 32 GB.
Je présume que la plupart des GPU (4 GPU à 32GB pour rappel) est utilisé par le modèle et les gradients des paramètres, puisque l'apprentissage des modèles SLU sur les mêmes données passe sur des GPU à 12GB du LIG.

Alors, sur JZ j'utilise les Tesla V100-SXM2-32GB .
Au LIG, pour les modèles SLU, j'utilise principalement des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go.
Il m'est arrivé d'utiliser parfois des NVIDIA TITAN X (Pascal) 12Go et des NVIDIA Quadro RTX 6000 24Go.

En fait au LIG c'est OAR qui gère les job, du coup ce n'est pas facile de monitorer exactement où le job est exécuté.
Je sais que si je lance sur une machine donné, ce que je fais parce
que OAR par défaut te met sur la première disponible et du coup tout
le monde se retrouve sur les mêmes machines, il y a telle ou telle
GPU, mais là je ne me rappelle pas dans quelle mesure je lance plus
sur une machine que sur une autre. À priori c'est 90%-95% du temps sur
des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go en mesure
égale.
#+end_quote

*** Hardware for the fine-tuning 
They said that a node from the Jean Zay supercomputer with 4 GPUs with
32GB memory was used for the fine tuning of the wave2vec model. if we look at the [[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][Idris' website]] we
think that the nodes used were from the *v100-32g*, it is the only node
with matching requirements in terms of number of GPU and memory per
GPU.

these nodes have the following hardware configuration :
        +  2 Intel Cascade Lake 6248 (20 cores at 2,5 GHz)
        +  192 GB  memory per node
        +  4 GPU Nvidia Tesla V100 SXM2 32 GB

Because we do not have the Intel Cascade Lake 6248 in our database, we
need to find some information about it. We can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/192446/intel-xeon-gold-6248-processor-27-5m-cache-2-50-ghz/specifications.html][Intel's webpage]]
that it is a processor of the Cascade Lake architecture. On [[https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake#LCC_SoC][Wikichip]],
we can see that Cascade Lake Processors use dies largely similar to
those of the [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)#Core][Skylake cores]]. Combining all of these pieces of
information, we can get an estimation of the details of an Intel
Cascade Lake 6248 :
model: "Xeon Gold 6248"
manufacture date: "2019"
process: 14nm
number of cores: 20
die size: 694 mm² (XCC configuration)

#+begin_src python :results output :exports none :session
jean_zay = copy.deepcopy(model)
jean_zay["server"]["configuration"] = {
    "cpu": {
      "units": 2,
      "model": "Xeon 6248"
    },
    "ram": [
      {
        "units": 1,
        "capacity": 192
      }
    ]
  }
jean_zay["gpu"] = [
  {
    "units": 4,
    "model": "NVIDIA Tesla V100 SXM2 32 GB"
  }
]
#+end_src

#+RESULTS:

*** Hardware for training the models

We are told that training uses only one GPU at a time and that it uses
roughly half of the time a RTX 2080 Ti and the other half a GTX 1080
Ti, to represent this, we will put the two different models in the
list of GPUs and use a 'gpu usage' of .5.
We are also told that the training uses 80 GB memory with no
additional information on the hardware used.
Since we do not know any more precise information, we will use the
default values of our tool to complete the missing pieces of information

    #+begin_src python :results output :exports none :session

training_SLU_model = copy.deepcopy(model)
training_SLU_model["gpu"] = [
  {
    "units": 1,
    "model": "NVIDIA GeForce RTX 2080 Ti 11GB"
  },
  {
    "units":1,
    "model": "NVIDIA GeForce GTX 1080 Ti"
  }
]
training_SLU_model["gpu_usage"] = .5
training_SLU_model["server"]["configuration"] = {
    "ram": [
      {
        "units": 1,
        "capacity": 80
      }
    ]
}
    
    #+end_src

    #+RESULTS:

** coherency of the results

One first good news is that information are coherent with themselves.
Using the indicated (in the paper) carbon intensity of 51gCO_2 e/kWh
used and indicated energy consumption, we are able to find back the carbon emissions
indicated in the table. The only problem is that for table 1, it seems
that there was a translation error when filling the table. The figures
are written in the french notation with "," separating units from
decimals and not the usual ".".
For instance, if we look at the first line of table 1, we can read
a consumption of 4,473 kWh, that we can translate to 4.473 kWh.
We obtain src_python{return 4.473*51} {{{results(=228.123=)}}}g CO_2 e, the same value as indicated in the paper.

We then only need to be able to find coherent energy consumption
values to obtain comparable results.

** Estimating energy consumption

*** fine tuning of the SSL model

    #+begin_src python :results output :exports none :session
jean_zay["usage"]["hours_use_time"] = 100
jean_zay["usage"]["minute_use_time"] = 0
output = run_experiment(jean_zay, "fine_tuning_SSL", directory='Dinarelli2022toward')
print_gwp_and_energy(output)
    #+end_src

    #+RESULTS:
    : estimated impacts: {'gwp': {'embodied': 3.8, 'direct': 5.46, 'total': 9.3, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 49.0, 'direct': 1210.0, 'total': 1300.0, 'unit': 'MJ'}, 'adp': {'embodied': 0.00053, 'direct': 5.21e-06, 'total': 0.00054, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 107.0, 'unit': 'kWh'}}
    : to put impacts in perspective: {'relative_SNBC': {'value': 0.0046, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 0.0094, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 0.017, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
    : energy consumption: {'value': 107.0, 'unit': 'kWh'}
    : dynamic impacts gwp: {'embodied': 3.8, 'direct': 5.46, 'total': 9.3, 'unit': 'kgCO2eq'}

We can see that we obtain an estimate of 5.46kg CO_2 e for the direct
impacts and a dynamic consumption of 107 kWh, which is close to the
4.729kg CO_2 e and 97.720 kWh presented in the paper. The fact that
results aren't a perfect match and slightly higher than presented can
be explained by the fact that measures presented were carried out
based on a measurement tool (CarbonTracker). (results presented are
borrowed from \cite{Evain2021task} using the methodology from \cite{parcollet2021energy})

*** Table 1

    #+begin_src python :result value raw :exports results :session
table = pd.read_csv('expected/expected_dinarelli.csv', header=[0,1])
rename_multi_index(table, ('model', 'Unnamed: 0_level_1'), ('model', ''))

def set(model, col, value):
    table.loc[table[('model','')] == model, col] = value


def estimate(steps, hours, minutes):
    name = f"spectro {steps} steps"
    print(name +  ":")
    training_SLU_model['usage']['hours_use_time'] = hours
    training_SLU_model['usage']['minute_use_time'] = minutes
    output = run_experiment(training_SLU_model, f'PortMEDIA_spectro_{steps}-steps',  directory='Dinarelli2022toward')
    energy, gwp = print_gwp_and_energy(output)
    set(name, ('estimated', 'power (kWh)'), energy)
    set(name, ('estimated', 'carbon (gCO2e)'), int(gwp * 1000))

estimate(3,36,14)
estimate(2,24,14)
estimate(1,15,52)

to_org_table(multi_index_to_multiline_header(table))
    #+end_src

    #+RESULTS:
    : | model           |       expected |     estimated |         expected |        estimated |
    : |                 |    power (kWh) |   power (kWh) |   carbon (gCO2e) |   carbon (gCO2e) |
    : |-----------------+----------------+---------------+------------------+------------------|
    : | spectro 3 steps |          4.473 |         10.1  |              228 |              517 |
    : | spectro 2 steps |          2.989 |          6.78 |              152 |              346 |
    : | spectro 1 step  |          1.708 |          4.44 |               87 |              226 |

We can see that we obtain carbon emission estimates around 3 times higher than
those presented in the paper. It is expected that we obtain higher
estimates than the measurements as presented in \cite{Jay2023experimental}

* results from \cite{Cattan2022benchmarking}

This paper studies the gains and impacts of choosing to use one type
of NLP model in a system. It evaluates the impacts of training the
models but also of running inferences.


We try to replicate the following results:

Coûts  ́ecologiques et  ́energétiques passés à l’échelle
Steps Inférences sur 1 semaine (27 Millions d’appels)
| Tasks                        |    MEDIA |        |        |  ATIS-FR |        |       |
| Models                       |     Time | Energy |    CO2 |     Time | Energy |   CO2 |
|                              | (Heures) |  (MWh) |   (Kg) | (Heures) |  (MWh) |  (Kg) |
| FlauBERTbase                 |    20.19 | 204.24 | 147.84 |     3.08 |  30.88 | 22.33 |
| CamemBERTlarge, CCNet 135 Gb |    50.63 | 512.67 | 371.14 |     7.36 |  74.23 | 53.75 |
| CamemBERTbase, OSCAR 138 Gb  |    20.23 | 204.67 | 148.15 |     3.27 |  32.57 | 23.56 |
| CamemBERTbase, CCNet 135 Gb  |    15.57 | 157.39 | 113.96 |     2.55 |  24.79 | 17.94 |
| CamemBERTbase, OSCAR 4 Gb    |    15.89 | 160.70 | 116.35 |     2.52 |  25.18 | 18.25 |
| CamemBERTbase, CCNet 4 Gb    |    15.64 | 158.08 | 114.42 |     2.59 |  25.49 | 18.48 |
| CamemBERTbase, Wiki 4 Gb     |    15.38 | 155.46 | 112.57 |     2.50 |  24.95 | 18.10 |
| FrALBERTbase, Wiki 4 Gb      |     9.11 |  92.02 |  66.61 |     1.39 |  13.71 |  9.93 |
| XLM-Rbase                    |    17.20 | 173.94 | 125.90 |     2.40 |  25.72 | 18.63 |
| XLM-Rlarge                   |    55.68 | 563.95 | 408.25 |     8.02 |  76.08 | 58.60 |
| mBERTbase                    |    17.95 | 181.41 | 131.36 |     2.48 |  24.72 | 17.94 |
| distill-mBERTbase            |    15.06 | 152.08 | 110.11 |     2.35 |  23.25 | 16.79 |
| small-mBERTbase-fr           |    16.45 | 166.24 | 120.35 |     2.46 |  24.56 | 17.79 |

these results were obtained by scaling up the results obtained in
\cite{Cattan2022benchmarking} for one inference to account for the
weekly number of requests the search engine of Qwant receives.
As always, we will need to first find the hardware configuration used,
then we will check the coherency of the expected results and run our experiments.

** Hardware configuration

We where told that the hardware used was an NVIDIA DGX equipped with 8
NVIDIA Tesla V100 SMX2 16GB. I was not able to find such a
configuration on NVIDIA's Website but since the Tesla V100 SMX2 32GB
GPU present in an NVIDIA DGX-1 server have the same exact \gls{TDP}, we will
suppose that this is the hardware used.
 
** running experiments

We can run the experiments and compare the results with the expected
results: 

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)

def estimate(model, task, time):
   print(model + ": " + task)
   dgx_1_model["usage"][ "hours_use_time"] = time
   output = run_experiment(dgx_1_model, model + '_' + task,  directory='Cattan2022benchmarking', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   return energy, gwp
#+end_src

#+RESULTS:


#+begin_src python :results value raw :exports results :session

table = pd.read_csv('expected/cattan_benchmarking.csv', sep=';', header=[0,1,2])

rename_multi_index(table, ('Tasks', 'Models', 'Unnamed: 0_level_2'), ('Tasks', 'Models', ''))

def set(model, task, col, val):
    table.loc[table[('Tasks', 'Models', '')] == model, (task,col)] = val

dgx_1_model['usage']['minute_use_time'] = 0
dgx_1_model['usage']['usage_location'] = "USA"

def estimate_and_set(model, task, time):
   energy, gwp = estimate(model,task,time)
   set(model, task, 'Estimated Energy', energy/1000)
   set(model, task, 'Estimated CO2', gwp)

print('MEDIA')
estimate_and_set('FlauBERTbase', 'MEDIA', 20.19)
estimate_and_set('CamemBERTlarge, CCNet 135 Gb', 'MEDIA', 50.63)
estimate_and_set('CamemBERTbase, OSCAR 138 Gb', 'MEDIA',  20.23)
estimate_and_set('CamemBERTbase, CCNet 135 Gb', 'MEDIA', 15.57)
estimate_and_set('CamemBERTbase, OSCAR 4 Gb', 'MEDIA', 15.89)
estimate_and_set('CamemBERTbase, CCNet 4 Gb', 'MEDIA', 15.64)
estimate_and_set('CamemBERTbase, Wiki 4 Gb', 'MEDIA', 15.38)
estimate_and_set('FrALBERTbase, Wiki 4 Gb', 'MEDIA', 9.11)
estimate_and_set('XLM-Rbase', 'MEDIA', 17.20)
estimate_and_set('XLM-Rlarge', 'MEDIA', 55.68)
estimate_and_set('mBERTbase', 'MEDIA', 17.95)
estimate_and_set('distill-mBERTbase', 'MEDIA', 15.06)
estimate_and_set('small-mBERTbase-fr', 'MEDIA', 16.45)
print('ATIS-FR')
estimate_and_set('FlauBERTbase', 'ATIS-FR', 3.08)
estimate_and_set('CamemBERTlarge, CCNet 135 Gb','ATIS-FR', 7.36)
estimate_and_set('CamemBERTbase, OSCAR 138 Gb', 'ATIS-FR',  3.27)
estimate_and_set('CamemBERTbase, CCNet 135 Gb', 'ATIS-FR', 2.55)
estimate_and_set('CamemBERTbase, OSCAR 4 Gb', 'ATIS-FR', 2.52)
estimate_and_set('CamemBERTbase, CCNet 4 Gb','ATIS-FR', 2.59)
estimate_and_set('CamemBERTbase, Wiki 4 Gb','ATIS-FR', 2.50)
estimate_and_set('FrALBERTbase, Wiki 4 Gb', 'ATIS-FR', 1.39)
estimate_and_set('XLM-Rbase', 'ATIS-FR', 2.40)
estimate_and_set('XLM-Rlarge', 'ATIS-FR', 8.02)
estimate_and_set('mBERTbase', 'ATIS-FR', 2.48)
estimate_and_set('distill-mBERTbase','ATIS-FR', 2.35)
estimate_and_set('small-mBERTbase-fr','ATIS-FR', 2.46)


to_org_table(multi_index_to_multiline_header(table))
   #+end_src

   #+RESULTS:
   | Tasks                        |    MEDIA |           MEDIA |            MEDIA |        MEDIA |         MEDIA |  ATIS-FR |         ATIS-FR |          ATIS-FR |      ATIS-FR |       ATIS-FR |
   | Models                       |     Time | Expected Energy | Estimated Energy | Expected CO2 | Estimated CO2 |     Time | Expected Energy | Estimated Energy | Expected CO2 | Estimated CO2 |
   |                              | (Heures) |           (MWh) |            (MWh) |         (Kg) |          (Kg) | (Heures) |           (MWh) |            (MWh) |         (Kg) |          (Kg) |
   |------------------------------+----------+-----------------+------------------+--------------+---------------+----------+-----------------+------------------+--------------+---------------|
   | FlauBERTbase                 |    20.19 |          204.24 |           0.0442 |       147.84 |          2.27 |     3.08 |           30.88 |          0.00675 |        22.33 |         0.346 |
   | CamemBERTlarge, CCNet 135 Gb |    50.63 |          512.67 |            0.111 |       371.14 |          5.69 |     7.36 |           74.23 |           0.0161 |        53.75 |         0.827 |
   | CamemBERTbase, OSCAR 138 Gb  |    20.23 |          204.67 |           0.0443 |       148.15 |          2.27 |     3.27 |           32.57 |          0.00716 |        23.56 |         0.367 |
   | CamemBERTbase, CCNet 135 Gb  |    15.57 |          157.39 |           0.0341 |       113.96 |          1.75 |     2.55 |           24.79 |          0.00559 |        17.94 |         0.286 |
   | CamemBERTbase, OSCAR 4 Gb    |    15.89 |           160.7 |           0.0348 |       116.35 |          1.79 |     2.52 |           25.18 |          0.00552 |        18.25 |         0.283 |
   | CamemBERTbase, CCNet 4 Gb    |    15.64 |          158.08 |           0.0343 |       114.42 |          1.76 |     2.59 |           25.49 |          0.00567 |        18.48 |         0.291 |
   | CamemBERTbase, Wiki 4 Gb     |    15.38 |          155.46 |           0.0337 |       112.57 |          1.73 |      2.5 |           24.95 |          0.00548 |         18.1 |         0.281 |
   | FrALBERTbase, Wiki 4 Gb      |     9.11 |           92.02 |             0.02 |        66.61 |          1.02 |     1.39 |           13.71 |          0.00305 |         9.93 |         0.156 |
   | XLM-Rbase                    |     17.2 |          173.94 |           0.0377 |        125.9 |          1.93 |      2.4 |           25.72 |          0.00526 |        18.63 |          0.27 |
   | XLM-Rlarge                   |    55.68 |          563.95 |            0.122 |       408.25 |          6.26 |     8.02 |           76.08 |           0.0176 |         58.6 |         0.901 |
   | mBERTbase                    |    17.95 |          181.41 |           0.0393 |       131.36 |          2.02 |     2.48 |           24.72 |          0.00543 |        17.94 |         0.279 |
   | distill-mBERTbase            |    15.06 |          152.08 |            0.033 |       110.11 |          1.69 |     2.35 |           23.25 |          0.00515 |        16.79 |         0.264 |
   | small-mBERTbase-fr           |    16.45 |          166.24 |            0.036 |       120.35 |          1.85 |     2.46 |           24.56 |          0.00539 |        17.79 |         0.276 |

We can see that we obtain results as low as 4 orders of magnitude
lower than the expected results. This massive difference cannot be
easily explained and is a really surprising result.

** Explaining the massive differences between our estimates and the expected results

#+begin_src python :results output :exports none
print(3.500 * 8)
print(8*250 + 512*.3725 + 2*135)
print(8*250 + 512*.3725)

print(3.5 * 121.8/3600)
#+end_src

#+RESULTS:
: 28.0
: 2460.72
: 2190.72
: 0.11841666666666667

In our estimates, the consumption of one DGX-1 is estimated at
2460W (if we were to suppose that CPUs are running at full capacity)
and 2190W if we suppose that CPUs do not run. This is significantly lower than the 3500W provided by NVIDIA
and can be due at least in part to the fact that we do not account for
storage in our estimation.

Results are way lower than those presented. however, the presented
results seem at least surprising. If we use the consumption value
provided by NVIDIA of 3500W for one DGX-1 [[https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/dgx-1/dgx-1-rhel-centos-datasheet-update-r2_Updates_NV_web_fr_FR.pdf][DGX-1 datasheet]]. If used for
8 hours like for ATIS-FR with XLM-Rlarge, we would expect a
consumption of 28kWh. This is extremely far from the 76MWh
presented. There is therefore a problem in the expected data or (more
probably) in the hardware configuration used. 

#+begin_src python :results output :exports none
# dividing emissions by energy consumption to get Carbon Intensity
print(204.24E+3 / 147.84E+3)
print(512.67/  371.14)
print(92.02/ 66.61)
print(30.88/ 22.33)
print(74.23/53.75)
#+end_src

#+RESULTS:
: 1.3814935064935066
: 1.381338578434014
: 1.3814742531151478
: 1.3828929690998657
: 1.3810232558139535

Furthermore we can see that conversion from energy consumption to
carbon emissions make us remark that the carbon intensity seemingly
used is approximately 1.38 gCO_2 e/kWh. This is extremely low as the
Carbon Intensity for France is estimated between 50 and 200 gCO_2
e/kWh.

In order to get further insight on what could cause these
inconsistencies we will try and reproduce results from
\cite{Cattan2022usability} which uses the same configuration. If
results from this paper are consistent with our estimates, this would
tend to confirm that there is a problem in the data presented in
\cite{Cattan2022benchmarking} and not in our estimates

** table from \cite{Cattan2022usability}

It is said that only one V100 GPU is used for training the different
models. (we will suppose that it was done on one DGX-1 server)
   
   #+begin_src python :results output :exports both
import numpy as np
energy = [1.08,3.10,.57,1.14,3.30,1.07,1.09,1.06]
emission = [317.87,914.27,167.8,337.70,973.29,317.02,321.42,314.17]
print(np.mean([em / en for en, em in zip(energy, emission)]))
   #+end_src

   #+RESULTS:
   : 295.2935224349162

We can see that the carbon intensity used seems to be of 295 gCO_2 e /
kWh.

*** results

we can see on [[https://github.com/Breakend/experiment-impact-tracker][Experiment-Impact-Tracker's repository]] that they by default use a \gls{PUE}
of 1.58, in order to replicate their results. We will choose to use
this value of 1.58 as dynamic ratio.

We can suppose that during training only the GPU is used at full
capacity. we can also try a scenario where one core of one GPU is used
during training. This would lead to including a cpu usage of 1/20
(since the CPU has 20 cores).

Table \ref{tab:cattan_usability} presents the results of these
experiments :

#+begin_src python :results output :exports none :session
table = pd.read_csv('expected/cattan_usability.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('model', '', ''))
rename_multi_index(table, ('estimate', 'Unnamed: 1_level_1', 'Unnamed: 1_level_2'), ('estimate', '',''))
rename_multi_index(table, ('time', 'Unnamed: 2_level_1','(s)'),('time','','(s)'))


def set(model, estimate, col, val):
    table.loc[(table[('model','','')] == model) & (table[('estimate','','')] == estimate), col] = val

with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)

dgx_1_model['usage']['gwp_factor'] = 295E-3
dgx_1_model['usage']['dynamic_ratio'] = 1.58
dgx_1_model["gpu"][0]['units'] = 1
dgx_1_model['server']['configuration']['cpu']['units'] = 1

def FQuAD_train_estimate(model, time_seconds):
    dgx_1_model["cpu_usage"] = 0
    energy, gwp = estimate(model, 'FQuAD_train_lower', time_seconds/3600)
    set(model, 'lower', ('estimated','energy','(kWh)'), energy)
    set(model, 'lower', ('estimated','carbon','(kgCO2e)'), gwp)
    dgx_1_model["cpu_usage"] = 1/20
    energy, gwp = estimate(model, 'FQuAD_train_upper', time_seconds/3600)
    set(model, 'upper', ('estimated','energy','(kWh)'), energy)
    set(model, 'upper', ('estimated','carbon','(kgCO2e)'), gwp)
#+end_src

#+RESULTS:

   #+begin_src python :results value raw :exports results :session
FQuAD_train_estimate('CamemBERT_base', 7207)
FQuAD_train_estimate('CamemBERT_large', 19445)
FQuAD_train_estimate('FraLBERT_base', 3816)
FQuAD_train_estimate('XLM-R_base', 7676)
FQuAD_train_estimate('XLM-R_large', 21137)
FQuAD_train_estimate('mBERT_base', 7333)
FQuAD_train_estimate('small-mBERT_base', 7190)
FQuAD_train_estimate('distil-mBERT_base', 6466)

to_org_table(multi_index_to_multiline_header(table))
   #+end_src

   #+RESULTS:
   | model            | estimate |  time | expected | estimated | expected | estimated |
   |                  |          |       |   energy |    energy |   carbon |    carbon |
   |                  |          |   (s) |    (kWh) |     (kWh) | (kgCO2e) |  (kgCO2e) |
   |------------------+----------+-------+----------+-----------+----------+-----------|
   | CamemBERT_base    | lower    |  7207 |     1.08 |      1.41 |    0.317 |     0.415 |
   | CamemBERT_base    | upper    |  7207 |     1.08 |      1.43 |    0.317 |     0.421 |
   | CamemBERT_large   | lower    | 19445 |      3.1 |      3.77 |    0.914 |      1.11 |
   | CamemBERT_large   | upper    | 19445 |      3.1 |      3.83 |    0.914 |      1.13 |
   | FrALBERT_base     | lower    |  3816 |     0.57 |      0.75 |    0.167 |     0.221 |
   | FrALBERT_base     | upper    |  3816 |     0.57 |     0.761 |    0.167 |     0.225 |
   | XLM-R_base        | lower    |  7676 |     1.14 |       1.5 |    0.337 |     0.441 |
   | XLM-R_base        | upper    |  7676 |     1.14 |      1.52 |    0.337 |     0.448 |
   | XLM-R_large       | lower    | 21137 |      3.3 |       4.1 |    0.973 |      1.21 |
   | XLM-R_large       | upper    | 21137 |      3.3 |      4.16 |    0.973 |      1.23 |
   | mBERT_base        | lower    |  7333 |     1.07 |      1.43 |    0.317 |     0.422 |
   | mBERT_base        | upper    |  7333 |     1.07 |      1.45 |    0.317 |     0.428 |
   | samll-mBERT_base  | lower    |  7190 |     1.09 |       1.4 |    0.321 |     0.414 |
   | samll-mBERT_base  | upper    |  7190 |     1.09 |      1.42 |    0.321 |      0.42 |
   | distil-mBERT_base | lower    |  6466 |     1.06 |      1.26 |    0.314 |     0.372 |
   | distil-mBERT_base | upper    |  6466 |     1.06 |      1.28 |    0.314 |     0.378 |

We can see that for upper and lower estimates we obtain results slightly higher that those presented
in the paper but in the same order of magnitude. This is expected
since estimation tools tend to provide higher (and closer to reality) estimates than
measurement tools. However, we can also see that the estimation tool (\cite{Jay2023experimental})
does not capture some subtleties. For instance small-mBERT_base
training is quicker than mBERT_base one. However this does not
translate to smaller energy consumption most probably because one
model training uses more resources than the other one. Without fine
knowledge of the processing units usage, we cannot provide very
precise estimations and track small changes such as this one.


All of these results tend to confirm that there are problems with the
data available in \cite{Cattan2022benchmarking} but that the data from
\cite{Cattan2022usability} confirms us the hardware configuration used.

** New experiment :

After pointing out the problems in the data to the authors, they ran a
new experiment on the Segur machine. The following results
were obtained using Experiment-Impact-Tracker :

| cpu_hours                |   1.0428555555555554 |
| gpu_hours                |   0.9933892874755572 |
| estimated_carbon_impact_kg | 0.024094323442314113 |
| total_power              |   0.4302695971583645 |
| kw_hr_gpu                 |   0.2516560133562949 |
| kw_hr_cpu                 |  0.02066651649077121 |
| exp_len_hours             |  0.5388999266756905  |

from these results, and knowing that the Segur machine is equipped with
2 20 core CPUs with 125 GB RAM  and 2 GTX 1080 Ti,
we can estimate that approximately 2 cores (1.04/.53) were used at
full capacity during training, which equates to 1/20 usage. The two
GPU also seem to have been used at full capacity.
we can deduce the used Carbon Intensity by dividing the estimated
carbon by the measured power

#+begin_src python :results value :exports none
return 0.024094323442314113 / 0.4302695971583645 * 1000
#+end_src

#+RESULTS:
: 55.99820113119911

this result of 56 gCO_2 e/kWh lead us to think that the Carbon
Intensity of France was used. (which would be logical since the
experiment was run in France)

We also know that Experiment Impact Tracker uses a \gls{PUE} of 1.58, in
order to try and reproduce these results, we will use a dynamic ratio
of 1.58. We will also try with the base dynamic ratio and see the difference

All of this allows us to run the following experiment to try and
reproduce these results

#+begin_src python :results value raw :exports results :session
with open("boaviztapi/data/ml_setups/Segur.json", 'r') as m:
    segur = json.load(m)

segur['usage']['minute_use_time'] = 0
segur['usage']['usage_location'] = "FRA"
segur['usage']['gwp_factor'] = 0.024094323442314113 / 0.4302695971583645
segur['cpu_usage'] = 1/20

def estimate(model, task, time):
   print(model + ": " + task)
   segur["usage"]["hours_use_time"] = time
   output = run_experiment(segur, model + '_' + task,  directory='Cattan2022benchmarking', silent=True)
   return print_gwp_and_energy(output)

energy_estimated, gwp_estimated = estimate('FrALBERTbase, Wiki 4 Gb trained on Segur', 'MEDIA', 0.5388999266756905)
segur['usage']['dynamic_ratio'] = 1.58
energy_match, gwp_match = estimate('FrALBERTbase_Wiki 4_Gb_trained_on_Segur_match', 'MEDIA', 0.5388999266756905)

df = pd.DataFrame(columns=['','Expected','Estimated', 'Match'])
df = df.append({'':'energy (kWh)','Expected':0.43,'Estimated':energy_estimated,'Match':energy_match}, ignore_index=True)
df = df.append({'':'Carbon (kgCO2e)','Expected':0.0241,'Estimated':gwp_estimated,'Match':gwp_match}, ignore_index=True)
to_org_table(df)
#+end_src

#+RESULTS:
|                 | Expected | Estimated |  Match |
|-----------------+----------+-----------+--------|
| energy (kWh)    |     0.43 |     0.855 |  0.436 |
| Carbon (kgCO2e) |   0.0241 |    0.0479 | 0.0244 |


We can see that we obtain very close results (a little bit higher just
as expected) when trying to get an
exact match by using a dynamic ratio of 1.58 and estimates are
approximately doubled when using the base dynamic ratio which stands
around 3.


# Estimate about the inference phase.

#+begin_src python :results value :exports none
return 0.02 * 40
#+end_src

#+RESULTS:
: 0.8


* estimations from \cite{Strubell2019energy} 

** Information about the hardware configuration

It is described in the paper that estimates are conducted by training
all models for a maximum of 24h. They use RAPL and NVIDIA System
Management Interface to measure the average consumption of the CPUs and
GPUs. 
All models are trained on one NVIDIA TITAN X except for ELMo
which is trained on 3 GTX 1080 Ti.
They then transcribe these results to estimates by using the training
time given in the paper and the description of the hardware given in
the paper.

No figures are presented regarding the average consumption of the
memory, CPU and GPU (separated). We only know about the model of GPU used for
estimating the consumption and the total estimated consumption for
training each model. We will therefore not give any value for
the CPU and ram and run our estimates as is. We will see what results
we obtain. We would like, not to obtain exact results since it wont be
possible given the information missing. Since they use measurement
tools, we can think that using a modeling using the \gls{TDP} will give
an higher result but since we do not know the quantity of memory used
and the CPU used, we are not sure that the results will be higher
(even if we can hypothesize that the CPU average consumption is
negligible compared to the GPU consumption.)

One reassuring point is that GTX 1080 Ti, V100, P100 and Titan X GPUs have the same
\gls{TDP} so the consumption estimated should make sense.

They use a \gls{PUE} of 1.58 and a Carbon Intensity of 0.954 pounds CO_2
e/kWh for American electricity production which is equivalent to
432.72 g CO_2 e/kWh.

#+begin_src python :results output :exports none :session
def convert_pounds_kg(x):
    return  0.453592 * x

def convert_kg_pounds(x):
    return  1 / 0.453592 * x

print(convert_pounds_kg(.954) * 1000)
#+end_src

#+RESULTS:
: 432.726768

** Checking the Coherency of the presented results

Since there are no estimates given for models trained on TPUs, we will
in the first time at least ignore these models.

Since table 3 presents the estimated consumption used, we can first
check the coherency of the table by seeing if we can reproduce the
same energy consumption by multiplying the power by the training time
and the \gls{PUE}

#+begin_src python :results value :exports none
return list(map(lambda x: 1.58/1000*x, (1415.78*12, 1515.43*84, 517.66*336, 12041.51*79, 1515.43*274120)))
#+end_src

#+RESULTS:
| 26.8431888 | 201.12786960000003 | 274.8153408 | 1503.0212782 | 656347.281128 |

We can see that, up to rounding we obtain the same results.
We can also check that we obtain the same carbon emissions.

#+begin_src python :results value :exports none
return list(map(lambda x: x*.954, [27,201,275,1507,656347])) 
#+end_src

#+RESULTS:
| 25.758 | 191.754 | 262.34999999999997 | 1437.6779999999999 | 626155.038 |

Also the same up to rounding errors

** running our estimations

For a first check, we will compare the estimated energy consumption of
just the GPUs with the presented hardware consumption. The \gls{TDP} of a
P100 GPU is 250W, also the same as the one of a GTX 1080 ti.


#+begin_src python :results value :exports results
return [
("model", "estimated", "measured"),
None,
("Transformer_base", 250*8, 1415.78),
("Transformer_big",250*8, 1515.43),
('ELMo',250*3, 517.66),
("BERT_base",250*64, 12041.51),
("NAS",250*8, 1515.43)
]
#+end_src

#+RESULTS:
| model           | estimated | measured |
|-----------------+-----------+----------|
| Transformer_base |      2000 |  1415.78 |
| Transformer_big  |      2000 |  1515.43 |
| ELMo            |       750 |   517.66 |
| BERT_base        |     16000 | 12041.51 |
| NAS             |      2000 |  1515.43 |

We can see that, as expected since the provided consumption result
from using measurement tools, the estimated consumption is bigger
(approximately + 1/3) than
the measured consumption. Still, it remains in the same order of
magnitude.

#+begin_src python :results value :exports none :session
[
('model', 'estimated pounds', 'estimated kg'),
None,
('Transformer_base',26,round(convert_pounds_kg(26),2)),
('Transformer_big',192,round(convert_pounds_kg(192),2)),
('BERT_base',1438,round(convert_pounds_kg(1438),2)),
('NAS',626155,round(convert_pounds_kg(626155),2)),
('ELMo',262,round(convert_pounds_kg(262),2))
]
#+end_src

#+RESULTS:
| model           | estimated pounds | estimated kg |
|-----------------+------------------+--------------|
| Transformer_base |               26 |        11.79 |
| Transformer_big  |              192 |        87.09 |
| BERT_base        |             1438 |       652.27 |
| NAS             |           626155 |     284018.9 |
| ELMo            |              262 |       118.84 |


#+begin_src python :results value raw :exports results :session
table = pd.read_csv('expected/training_strubell.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('model', '',''))

def set(model, col, val):
    table.loc[table[('model', '','')] == model, col] = val

base_model = {
"server": {
    "configuration":{
        "ram": [
            {
                "units" : 0
            }
        ]
    }
},
"gpu": [
    {
        "units": 1,
        "model": "NVIDIA GTX TITAN X"
    }
],
"psf": 1,
"nb_nodes": 1,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "hours_use_time": 0,
  "usage_location": "USA",
}
}

model_match = copy.deepcopy(base_model)

model_match["usage"] = {
  "dynamic_ratio": 1.58,
  "hours_use_time": 0,
  "usage_location": "USA",
  "gwp_factor": 432.72E-3
}


def estimate(model, task,  name, nb_gpus, time):
    print(name)
    model["gpu"][0]["units"] = nb_gpus
    model["usage"]["hours_use_time"] = time
    output = run_experiment(model, task + '_' +  name, directory='Strubell2019energy')
    energy, gwp = print_gwp_and_energy(output)
    print(f"direct gwp: {convert_kg_pounds(gwp):.2f} lbs")
    set(name, ('estimated','energy ' + task, '(kWh)'), int(energy))
    set(name, ('estimated','CO2e ' + task, '(kg)'), int(gwp))
    set(name, ('estimated','CO2e ' + task, '(lbs)'), int(convert_kg_pounds(gwp)))    

def estimates(model, task):
    estimate(model, task, "Transformer_base", 8, 12)
    estimate(model, task, "Transformer_big", 8, 84)
    estimate(model, task, "BERT_base", 64, 79)
    estimate(model, task, "NAS", 8, 274120)
    model["gpu"] = [{
        "units": 3,
        "model": "NVIDIA GeForce GTX 1080 Ti"
    }]
    estimate(model, task, "ELMo", 3, 336)

print("estimates match")
estimates(model_match, "match")
print("\n\nestimates base parameters")
estimates(base_model, "base")


to_org_table(multi_index_to_multiline_header(table))
#+end_src

#+RESULTS:
| model           | expected |    estimated |   estimated | expected |  estimated | estimated | expected |  estimated |   estimated |
|                 |   energy | energy match | energy base |     CO2e | CO2e match | CO2e base |     CO2e | CO2e match |   CO2e base |
|                 |    (kWh) |        (kWh) |       (kWh) |     (kg) |       (kg) |      (kg) |    (lbs) |      (lbs) |       (lbs) |
|-----------------+----------+--------------+-------------+----------+------------+-----------+----------+------------+-------------|
| Transformer_base |       27 |           38 |          74 |    11.79 |         16 |        27 |       26 |         36 |          61 |
| Transformer_big  |      201 |          267 |         523 |    87.09 |        116 |       194 |      192 |        255 |         427 |
| BERT_base        |     1507 |         2000 |        3920 |   652.17 |        865 |      1450 |     1438 |       1907 |        3196 |
| NAS             |   656347 |       871000 |    1.71e+06 |   284018 |     377000 |    632000 |   626155 |     831143 | 1.39332e+06 |
| ELMo            |      275 |          404 |         793 |   118.84 |        175 |       293 |      262 |        385 |         645 |

Table \ref{tab:strubell_training} presents the results of our
estimates. We can see that we obtain estimates that are, as expected, a little
bit higher than those presented, the differences between the match and base setups can be explained by
two things: the used Carbon Intensity for the USA in the base values
is 370gCO_2 e/kWh instead of the 432gCO_2 e/kWh when trying to match.
The dynamic ratio is roughly twice as high when using the base value
compared to using the indicated \gls{PUE}.

** hyper-parameter search

To complement the case study on hyper-parameter search and costs not
only on training one model but of the whole process, let us try and
reproduce similar results, which we would be able to study also in
terms of the other impacts estimated by our tool.

#+begin_src python :results value raw :exports results :session
table = pd.read_csv('expected/cost_strubell.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('Models', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('Models', '', ''))
rename_multi_index(table, ('Hours', 'Unnamed: 1_level_1', 'Unnamed: 1_level_2'), ('Hours', '', ''))

def set(model, col, val):
    table.loc[table[('Models', '', '')] == model, col] = val

model = {
    "server": {
	"configuration":{
	    "ram": [
		{
		    "units" : 1,
		    "capacity": 1
		}
	    ]
	}
    },
    "gpu": [
	{
	    "units": 1,
	    "model": "NVIDIA GTX TITAN X"
	}
    ],
    "psf": 1,
    "nb_nodes": 1,
    "cpu_usage": 0,
    "gpu_usage": 1,
    "usage": {
      "hours_use_time": 0,
      "usage_location": "USA",
    }
}

def estimate(time, name):
    model["usage"]["hours_use_time"] = time
    output = run_experiment(model, name, "Strubell2019energy")
    energy = output["impacts"]["energy consumption"]["value"]
    cost = energy *.12
    print(f"Direct energy consumption: {energy} kWh, translates to a cost of {cost:2f} $")
    return cost, energy

def estimate_and_set(time, name):
    cost, energy = estimate(time, name)
    set(int(name), ('Estimated', 'energy', '(kWh)'), round(energy,0))
    set(int(name), ('Estimated', 'electricity', 'cost ($)'), round(cost,0))

estimate_and_set(120, '1')
estimate_and_set(2880, '24')
estimate_and_set(239942, '4789')

to_org_table(multi_index_to_multiline_header(table))
#+end_src

#+RESULTS:
| Models |  Hours | Expected | Estimated |    Expected |   Estimated |
|        |        |   energy |    energy | electricity | electricity |
|        |        |    (kWh) |     (kWh) |    cost ($) |    cost ($) |
|--------+--------+----------+-----------+-------------+-------------|
|      1 |    120 |     41.7 |        93 |           5 |          11 |
|     24 |   2880 |      983 |      2230 |         118 |         268 |
|   4789 | 239942 |    82250 |    186000 |        9870 |       22320 |

We can see that we still obtain values approximately twice as high as
the ones presented. This fact can be mostly explained by the
difference between using a \gls{PUE} of 1.58 and a dynamic ratio of 3.1

** integrating Life cycle to previous analyses

#+begin_src python :results output :exports results :session
estimate(239942, "4789_jobs_with_ram")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 2800.0, 'direct': 68800.0, 'total': 72000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 39000.0, 'direct': 2110000.0, 'total': 2200000.0, 'unit': 'MJ'}, 'adp': {'embodied': 0.76, 'direct': 0.0183, 'total': 0.78, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 186000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 36.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 73.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 25.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 186000.0 kWh, translates to a cost of 22320.000000 $
: (22320.0, 186000.0)


We can see that the full impacts estimated for performing the whole
model search, hyper-parameter tuning and training represents the annual
impacts of 36 persons if we place ourselves in a scenario where we
would respect the "Stratégie Nationale Bas Carbone" for France
by 2050. If we place ourselves in the framework of the Planetary
boundaries, where if we want to stay sustainable, societies must not
overpass the planetary boundaries. The whole process accounts for the
maximal annual impacts of 73 persons in terms of Green House Gas
emissions and the annual impacts of 25 persons in terms of resource
depletion.

Of course, if computations were to run in a country with a
less carbon intensive electricity mix, green warming potential would
be lower. Still, the impacts on resources depletion are very
important, and, in this estimation, we do not take into account any (1
GB) memory on the server that runs the experiments. 

If we were to add memory, for instance 512 GB of memory, we would
obtain the following estimation

#+begin_src python :results output :exports results :session
model["server"]["configuration"]["ram"][0]["capacity"] = 512
estimate(239942, "4789_jobs_with_ram")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 12000.0, 'direct': 121000.0, 'total': 130000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 160000.0, 'direct': 3720000.0, 'total': 3900000.0, 'unit': 'MJ'}, 'adp': {'embodied': 1.0, 'direct': 0.0323, 'total': 1.1, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 327000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 67.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 140.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 34.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 327000.0 kWh, translates to a cost of 39240.000000 $

with expected impacts as high as the maximal annual ones of 140 persons
in terms of \gls{GWP} and 34 persons in terms of Resources depletion.

As a title of comparison, if we were to make the same estimates but
running in France, we would obtain the following (with a carbon
intensity of 98gCO_2 e/kWh)

#+begin_src python :results output :exports results :session
model["usage"]["usage_location"] = "FRA"
estimate(239942, "4789_jobs_with_ram_France")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 12000.0, 'direct': 32100.0, 'total': 45000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 160000.0, 'direct': 3700000.0, 'total': 3900000.0, 'unit': 'MJ'}, 'adp': {'embodied': 1.0, 'direct': 0.0159, 'total': 1.1, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 327000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 22.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 45.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 33.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 327000.0 kWh, translates to a cost of 39240.000000 $

It would still represent the maximal annual emissions of 45 persons in
terms of \gls{GWP} and the maximal impacts of 33 persons in terms of
resources depletion




* comparing manufacture impacts with Dell LCAs 

** Dell R740 
   #+begin_src python :results output :exports results :session
with open("boaviztapi/data/devices/server/dellR740.json", 'r') as m:
    R740 = json.load(m)

#print(R740)
out = run_experiment_server(R740, "R740", directory='../results')
print_impacts_server(out)



def print_results_components(results):
    impact_dict = {}
    impact_dict["MAINBOARD"] =  get_result_component(results,"MOTHERBOARD") +  get_result_component(results,"CPU")
    for c in ['RAM', 'SSD']:
        r = get_result_component(results,c)
        impact_dict[c] = r
        print(f'{c} gwp: {r} kgCO2eq')
    total = 0
    for c in ['POWER_SUPPLY', 'CASE', 'ASSEMBLY']:
        total += get_result_component(results,c)
    impact_dict['OTHER'] = total
    print(f'Other component GWP impacts: {total:.0f} kgCO2eq')
    return impact_dict

impact_dict = print_results_components(out)
impact_dict["SSD_3.84GB"] = out['verbose']['SSD-2']["impacts"]['gwp']['value']

   #+end_src

   #+RESULTS:
   : GWP: {'manufacture': 2400.0, 'use': 1170.0, 'unit': 'kgCO2eq'}
   : PE: {'manufacture': 31000.0, 'use': 39700.0, 'unit': 'MJ'}
   : ADP: {'manufacture': 0.19, 'use': 0.000198, 'unit': 'kgSbeq'}
   : RAM gwp: 540.0 kgCO2eq
   : SSD gwp: 24.0 kgCO2eq
   : Other component GWP impacts: 302 kgCO2eq

   #+begin_src python :results pp :exports both :session
impact_dict
   #+end_src

   #+RESULTS:
   : {'MAINBOARD': 111.69999999999999,
   :  'OTHER': 302.0,
   :  'RAM': 540.0,
   :  'SSD': 24.0,
   :  'SSD_3.84GB': 1440.0}

  wdfsdf

#+begin_src python :results value :exports both :session
#l = [(n, v) for (n,v) in impact_dict]
tabulate.tabulate(impact_dict.items(), tablefmt='orgtbl')
   #+end_src

   #+RESULTS:
   : | MAINBOARD  |  111.7 |
   : | RAM        |  540   |
   : | SSD        |   24   |
   : | OTHER      |  302   |
   : | SSD_3.84GB | 1440   |


| Component | ACV DELL - GWP (kgCO2eq) | MLCA - GWP (kgCO2eq) | Boavizta - GWP (kgCO2eq) |
| CPU       |                       47 |                 45.6 |                       43 |
| RAM       |                      533 |                  540 |                      534 |
| SSD       |                       64 |                   24 |                       24 |
| OTHER     |                      266 |                  368 |                      369 |
| TOTAL     |                      910 |                  970 |                      970 |

We can see that we obtain more or less the same results even after the
modifications to the way CPU impacts are computed or some bugfixes.

#+begin_src python :results file :exports results :session
pie_chart(impact_dict, 'R740')
#+end_src

#+RESULTS:
[[file:results/../results/12-05-23_20-28_R740.svg]]


** Dell R6515, R7515, R7525

#+begin_src python :results output :exports both
total_energy = (213.92 + 595.11 + 347.16 + 207.39)*4
CI_europe = (3450 - 1343) / total_energy
CI_US = (4280 - 1343) / total_energy 
print(total_energy, CI_europe, CI_US)

print(0.15216000000000002 * 4 *365 * 24)
#+end_src

#+RESULTS:
: 5454.32 0.386299300371082 0.5384722568532833
: 5331.6864000000005

#+begin_src python :results output :exports both :session

with open("boaviztapi/data/devices/server/R6515.json", 'r') as m:
    R6515 = json.load(m)

R6515["usage"]["workload"] = {
      "100": {
        "time": 2.4/24,
        "power": 1.0
      },
      "50": {
        "time": 8.4/24,
        "power": 184.1/244.2 
      },
      "10": {
        "time": 7.2/24,
        "power":  132.1/244.2
      },
      "idle": {
        "time": 6/24,
        "power": 94.7/244.2
      }
    }


print("Europe Scenario")
R6515["usage"]["usage_location"] = "EEE"
R6515["usage"]["gwp_factor"] =  0.386299300371082
out = run_experiment_server(R6515, "R6515_Europe", directory='../results')
print_impacts_server(out)

print("US Scenario")
R6515["usage"]["usage_location"] = "USA"
R6515["usage"]["gwp_factor"] = 0.5384722568532833
out = run_experiment_server(R6515, "R6515_USA", directory='../results')
print_impacts_server(out)


R6525 = R6515
R6525["configuration"]['cpu']['units'] = 2
R6525["configuration"]['ram'][0]['units'] = 16

print("R6525 US Scenario")
out = run_experiment_server(R6525, "R6525_USA", directory='../results')
print_impacts_server(out)
#+end_src 

#+RESULTS:
#+begin_example
Europe Scenario
GWP: {'manufacture': 1200.0, 'use': 2060.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 15000.0, 'use': 68600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.13, 'use': 0.000342, 'unit': 'kgSbeq'}
US Scenario
GWP: {'manufacture': 1200.0, 'use': 2870.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 15000.0, 'use': 60600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.13, 'use': 0.000526, 'unit': 'kgSbeq'}
R6525 US Scenario
GWP: {'manufacture': 1600.0, 'use': 2870.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 21000.0, 'use': 60600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.17, 'use': 0.000526, 'unit': 'kgSbeq'}
#+end_example

#+begin_quote

In the case of Dell R6515, the manufacturing has a contribution of 1,343 kg CO2e, approximately 39% to
the total of the life cycle impact in the light-medium use scenario

#+end_quote

For the manufacture of the R6515, we obtain an estimate of 1200 kgCO_2
e when the expected results stand at 1343 kgCO_2 e.

For the R6525, we obtain an estimate of 1600 kgCO_2 e when the expected
result stands at 1709 kgCO_2 e.


* replicating the Bloom estimates from \cite{Luccioni2022estimating}

** Gathering information about the setup
To replicate their experiments, we first need to gather some
information on the time duration and hardware setup for the training
phase.

We can see in the paper that the training phase lasted for 118 days, 5
hours and 41 minutes for a total of 1,082,990 GPU hours. (table 1)

in section 4.1, we can read that training used on average 48 computing
nodes with 8 GPUs each.


#+begin_src python :results value :exports none
real_time_hours = 118*24 + 5 + 41/60
estimated_gpu_hours = real_time_hours * 48 * 8
return estimated_gpu_hours
#+end_src

#+RESULTS:
: 1089670.4

Combining the real time and these information about the setup, we obtain an estimate of the number of GPU hours of 1,089,670.4 hours
this gives us a pretty close figure to the real GPU time.

It is written in the paper that training took place on the Jean Zay
supercomputer, using [[https://buy.hpe.com/fr/fr/compute/apollo-systems/apollo-6500-system/apollo-6500-system/hpe-apollo-6500-gen10-plus-system/p/1013092236][HPE's Apollo 6500 Gen10 Plus]]. We can read on
their website that it uses AMD EPYC 7000 Series CPUs. Combining this
information with information about the Jean Zay supercomputer on
[[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][IDRIS's website]], we can see that only the **gpu_p5**  partition uses
such CPUs. 
We can conclude that for each of the 48 used nodes, the server
configuration is :
+ 2 CPUs : AMD Milan EPYC 7543
+ 512 Go of Memory
+ 8 NVIDIA A100 SXM4 80Go

** comparing the server footprint with the PCF sheet.

   In section 4.1, it is stated that they use values provided in the
   [[https://www.hpe.com/psnow/doc/a50005151enw][HPE ProLiant DL345 Gen10 Plus PCF]], the closest server with
   information provided. In this PCF sheet, we can read that servers
   are of type rack and that the estimated Carbon Footprint is of
   2503.2 kg CO_2 e.
   If we try our tool with the server configuration used for training,
   we obtain :

   #+begin_src python :results output :exports results :session
server = {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}
out = run_experiment_server(server, "HPE ProLiant DL345 Gen10 Plus")
print_impacts_server(out)
ram_gwp = out['verbose']["RAM-1"]['impacts']['gwp']
print(f"RAM impact GWP: {ram_gwp}")
   #+end_src

   #+RESULTS:
   : GWP: {'manufacture': 2300.0, 'use': 1170.0, 'unit': 'kgCO2eq'}
   : PE: {'manufacture': 29000.0, 'use': 39700.0, 'unit': 'MJ'}
   : ADP: {'manufacture': 0.17, 'use': 0.000198, 'unit': 'kgSbeq'}
   : RAM impact GWP: {'value': 1800.0, 'unit': 'kgCO2eq'}

we can see manufacture impacts of 2300 kg CO_2 e. This impact is close
to the 2500 kgCO_2 e provided on the PCF sheet and is mainly impacted
by the quantity of memory used, as it accounts for 1800 kg CO_2 e.

** comparing the GPU footprint with the chosen value

In section 4.1, it is stated that a value of 150 kg CO_2 e is
chosen. Taking a look at the source, there is no real justification
given for that value. Given that in \cite{Loubet2023life} a small GPUs
manufacture is estimated at emitting around 30 kg CO_2 e, we can
hypothesize that GPU manufacture impacts would be in the order of 50
to 150 kg CO_2 e.

#+begin_src shell :results output :exports none
curl -X 'POST' \
  'http://localhost:5000/v1/component/gpu?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "NVIDIA A100 SXM4 80 GB"
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"manufacture":310.0,"use":"not implemented","unit":"kgCO2eq"},"pe":{"manufacture":3900.0,"use":"not implemented","unit":"MJ"},"adp":{"manufacture":0.03,"use":"not implemented","unit":"kgSbeq"}},"verbose":{"units":1,"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":310.0,"unit":"kgCO2eq"},"pe":{"value":3900.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}

For the specific model used, the "NVIDIA A100 SMX4 80GB", we can see
a manufacture impact of 310 kgCO_2 e. this impact is mainly influenced
by the quantity of memory on the GPU with 290 kg CO_2 e.
These are preliminary results since the base value for gpu impacts is
not properly set yet.

** Estimating the total impacts

with all of the previous information, we can run the estimation

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/test_bloom.json",'r') as bloom:
    bloom_model = json.load(bloom)
out = run_experiment(bloom_model,"bloom")
embodied = out["verbose"]["embodied impacts"]["gwp"]
dynamic = out["verbose"]["dynamic impacts"]["gwp"]
dynamic_energy = out['verbose']['dynamic energy consumption']
print(f"embodied impacts gwp: {embodied}")
print(f"dynamic impacts gwp: {dynamic}")
print(f"dynamic energy consumption: {dynamic_energy}")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 15000.0, 'direct': 83100.0, 'total': 98000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 190000.0, 'direct': 18300000.0, 'total': 18000000.0, 'unit': 'MJ'}, 'adp': {'embodied': 1.3, 'direct': 0.0788, 'total': 1.3, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 1620000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 49.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 99.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 42.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: embodied impacts gwp: {'server': 7000.0, 'gpus': 7600.0, 'unit': 'kgCO2eq'}
: dynamic impacts gwp: {'value': 26800.0, 'gpus': 22400.0, 'ram': 1350.0, 'cpus': 3140.0, 'unit': 'kgCO2eq'}
: dynamic energy consumption: {'value': 10900.0, 'unit': 'kWh'}

we can see in the results (full result in results/datetime bloom.json) that we obtain close figures to those in the
paper.
with embodied impacts of 7T CO_2 e for the servers and 7.6T for the
GPUs to compare with the 7.6T for the servers and 3.6 T for the GPUs
in the paper. Most of the difference is due to estimated impacts of
300 kgCO_2 e for one GPU while it was estimated to 125 kgCO_2 e in the
paper.

For the dynamic consumption, we obtain an estimate of 26.8T CO_2 e,
mainly due to the GPUs (accountable for 25T, the only difference with
the figure obtained in the paper being the slightly off conversion
from real time to GPU hours) while the memory, not accounted for in
the paper brings another 1.5T CO_2 e.

The only thing that differs greatly is the value for the idle
consumption. (not so surprising since figures differ quite a lot).


* Conclusions

After these experiments trying to evaluate the validity of our tool,
we can draw some conclusions, firstly about the challenges of
replicating results and then about the validity of our tool.

** about the replication of results

Overall, reproducing results from different papers proved way harder
than expected. Indeed, Unless a real effort is made by authors to allow replication of
their results, it is most of the time really difficult to find
enough information to run estimates and reproduce their
results.
This is also particularly true for results produced
using a measurement tool, indeed, If the hardware on which those
results were produced isn't detailed, it is impossible to
reproduce the experiments and check the quality of the results
presented. We were only able to conduct experiments for all of these
papers because we were able to contact the authors and they were
able to give us some insight about the hardware configuration of their experiments.

Even when we had enough information to run our estimates precisely
enough to hopefully match the expected results, we faced multiple
times important errors and inconsistencies in the data presented in
different tables. This was for example the case with the results
presented in \cite{Bannour2021evaluating} and in
\cite{Cattan2022benchmarking}. This was also the case to a lesser
extent in \cite{Jay2023experimental} were a notable effort for
reproducibility was realised by the authors but there were still
some problems and assumptions that needed to be made in order to
reproduce the results. 
After pointing out the problems with the data presented in
\cite{Cattan2022benchmarking}, the authors conducted new experiments
to resolve the problems with their data and we were able to reproduce
these new results.

** about the validity of the tool

Running new experiments often required us to gather some information
about a CPU not present in our database. This was not needed for
GPUs. It seems like there is much more diversity in CPUs used than in
GPU used. However, it was relatively easy to find all the information
we needed when encountering a new CPU and when running estimations
about GPU intensive tasks such as training NLP models, the CPU usage
is often set close to 0. Moreover, CPU manufacturing does not play a
huge part in the manufacturing impacts of a server in terms of
\gls{GWP}, it does however play an important part of the impacts in
terms of mineral resource usage (ADP)

We were unfortunately not able to find experiments to demonstrate the
validity of other indicators than the Global Warming Potential.

Still, we can see that overall, we were able to reproduce results for the
dynamic consumption and for the embodied impacts. These experiments
also demonstrate the usability of our tool in diverse scenarios.


* remaining stuff TODO                                             :noexport:

faire des jolis camemberts ?
de manière générale rédiger la section sur la comparaison aux ACV.


faire un truc sur la variation du dynamic ratio ?
variation de la durée de vie ?
baisser le dynamic ratio mais baisser la durée de vie du
matériel. (scenario à la patterson)






/!\ résultats de variabilité qui exploitent ADP dans strubell, à
modifier quand changement dynamic ratio sera fait.


modifier le code pour mettre des valeurs approximatives pour les GPU
modifier dynamic ratio
