#+EXPORT_EXCLUDE_TAGS: noexport

#+TITLE: Experiments for validating our tool

In order to validate our tool we first need to conduct some
experiments to ensure that it produces results consistent with the
state of the art. Our tool estimates manufacture impacts of the
hardware used and energy consumption over the usage duration (typically
during the training phase of a model). We therefore want to test those
two parts. 
Firstly, we will present experiments aimed at testing the
estimates for the dynamic energy consumption (and the results we will
present will therefore focus only on the energy consumption estimated
and on the Carbon footprint induced by this energy consumption). These experiments will
start in section \ref{sec:ga} by reproducing the same exact results as the
Green Algorithms tool, by first choosing a scenario were we know that
our tool and Green Algorithms use the same data. Then, in sections
\ref{sec:bannour} and  \ref{sec:jay} we will focus
on reproducing results presented in the two surveys of existing tools
(\cite{Bannours2021evaluating} and
\cite{Jay2023experimental}). Finally, in sections \ref{sec:dinarelli},
\ref{sec:cattan} and \ref{sec:strubell} we will try to reproduce results
obtained with a different method than the one used by our tool. This
will be done by trying to reproduce results from
\cite{Dinarelli2022toward}, \cite{Cattan2022benchmarking} and
\cite{Strubell2019energy}. We chose those articles because they all
use a different tool (even if measures presented in these three
articles are based on the \gls{RAPL} and \gls{NVLM} tools), because we
were able to contact the authors of
\cite{Dinarelli2022toward,Cattan2022benchmarking} to obtain further
details about the hardware configuration they use ; Because
\cite{Cattan2022benchmarking} presents results about the inference
phase of models which is a phase that is rarely studied and because
\cite{Strubell2019energy} was the paper that made NLP researchers
consider the impacts of the models they produced.
Secondly, in section \ref{sec:manufacture_comparison} we will compare the results our tool produces with \gls{LCA}
results produced by Dell about the impacts of the servers they
sell. This will allow us to validate the estimations of embodied
impacts our tool generates.
Finally, in section \ref{sec:bloom} we will try to reproduce the results from
\cite{Luccionni2022estimating}, this step is really important because
this paper conducts an analysis of the global warming potential
induced by the Bloom model. This analysis takes into account embodied
emissions and we use figures they present to define the default
dynamic ratio our tool uses.

* Setup the experiments                                            :noexport:
first, run the program, we will then be able to send it requests with
the following command:

`pipenv run uvicorn boaviztapi.main:app --host=localhost --port 5000`

this must be realised in another terminal and not in emacs because,
since it does not terminate, trying to execute it in your emacs would
make your emacs wait for the death of the process forever.

* Defining some helper functions to easily run experiments and read their results :noexport:

#+NAME: attr_wrap
#+BEGIN_SRC sh :var data="" :var caption="caption" :results output
  printf "#+ATTR_LATEX: :float t :caption \\caption{$caption} \n"
  echo "$data"
#+END_SRC

#+RESULTS: attr_wrap
: #+ATTR_LATEX: :float t :caption \caption{caption} 
: 

** python
header with all used packages

  #+begin_src python :results silent :exports none :session
import numpy as np
import pandas as pd
import copy
import json
import subprocess
from datetime import datetime
import matplotlib.pyplot as plt
import tabulate
import re
  #+end_src

  #+RESULTS:

then, we define a helper function to be able to more easily run
experiments and store their results in a more readable way
#+begin_src python :results output :exports none  :session
def run_experiment(model, filename, directory='../results', silent=False):
    with open("tmp.json", "w") as tmp:
        json.dump(model, tmp)
    path = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + filename + ".json"
    with open(path, "w") as out:
        request = "curl -X 'POST' 'http://localhost:5000/v1/mlca/?verbose=true' -H 'accept: aplication/json' -H 'Content-Type: application/json' -d @tmp.json"
        results = subprocess.run(request, shell=True, check=True, capture_output=True, text=True)
        output = json.JSONDecoder().decode(results.stdout)
        impacts = output["impacts"]
        perspective = output["perspective"]
        if not silent:
            print(f"estimated impacts: {impacts}")
            print(f"to put impacts in perspective: {perspective}")
        json.dump(output, out, indent=4, ensure_ascii=True)
        subprocess.run("rm tmp.json", shell=True)
        return output
#+end_src

#+RESULTS:


Full results are put into the results repository under a name that is
prefixed with the date-time of running the experiment.

As most of the comparisons we are able to make are referring to \gls{GWP} and
energy consumption only, let us also define a helper function
to print those results.

#+begin_src python :results output :exports none  :session
def print_gwp_and_energy(results):
    dynamic_energy = results["impacts"]["energy consumption"]
    direct_gwp = results["impacts"]["gwp"]
    print(f"energy consumption: {dynamic_energy}")
    print(f"usage impacts gwp: {direct_gwp}")
    return dynamic_energy['value'], direct_gwp['direct']
#+end_src

#+RESULTS:

For running experiments about the manufacture impacts of servers
#+begin_src python :results output :exports none :session
def run_experiment_server(model, filename, directory='../results', silent=False):
  with open("tmp.json", "w") as tmp:
    json.dump(model, tmp)
  path = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + filename + ".json"
  with open(path, "w") as out:
    request = "curl -X 'POST' 'http://localhost:5000/v1/server/?verbose=true' -H 'accept: aplication/json' -H 'Content-Type: application/json' -d @tmp.json"
    results = subprocess.run(request, shell=True, check=True, capture_output=True, text=True)
    output = json.JSONDecoder().decode(results.stdout)
    impacts = output["impacts"]
    json.dump(output, out, indent=4, ensure_ascii=True)
    subprocess.run("rm tmp.json", shell=True)
    return output

def print_impacts_server(out):
    gwp = out["impacts"]['gwp']
    pe = out["impacts"]['pe']
    adp = out["impacts"]['adp']
    print(f"GWP: {gwp}")
    print(f"PE: {pe}")
    print(f"ADP: {adp}")
#+end_src

#+RESULTS:

For plotting pie charts of the distribution of gwp by components
  #+begin_src python :results output :exports none :session
def get_result_component(results, component):
    return results['verbose'][component + '-1']["impacts"]['gwp']['value']

def get_results_components(results):
    res = {}
    for c in ['CPU', 'RAM', 'SSD', 'POWER_SUPPLY', 'CASE', 'MOTHERBOARD', 'ASSEMBLY']:
        res[c] = get_result_component(results, c)
    return res


def pie_chart(impacts_dict, name,  directory='../results'):
    filename = "results/" + directory + '/' + datetime.now().strftime("%d-%m-%y_%H-%M") + "_" + name + ".svg"
    fig, ax = plt.subplots()
    ax.pie(impacts_dict.values(), labels=impacts_dict.keys(), autopct='%1.1f%%')
    ax.set_title("Part Production -" + name + "\nGWP 100 years [kg CO2e]")
    fig.savefig(filename)
    return filename

  #+end_src

  #+RESULTS:


  #+begin_src python :results output :exports none :session
def to_org_table(table):
    return tabulate.tabulate(table, tablefmt='orgtbl', headers="keys", showindex=False)

def rename_multi_index(df, old_col, new_col):
    df.columns = df.columns.values
    df.columns = pd.MultiIndex.from_tuples(df.rename(columns={old_col: new_col}))

def multi_index_to_multiline_header(table):
    names = ['\n'.join(i) for i in table.columns.values]
    table.columns = names
    return table
  #+end_src

  #+RESULTS:

#+begin_src python :results output :session :exports both
def get_results(out):
    gwp = out["impacts"]['gwp']['total']
    pe = out["impacts"]['pe']['total']
    adp = out["impacts"]['adp']['total']
    return gwp,adp,pe
#+end_src

#+RESULTS:

** R
#+begin_src R :results silent :session *R* :exports both
library(ggplot2)
library(dplyr)
library(scales)
#+end_src

#+begin_src R :results output :session *R* :exports both
  get_bar_plot = function(data, name){
data$process <- factor(data$process, levels = unique(data$process))
 data %>%
  ggplot(aes(x = component, y = GWP, fill=process)) +
  geom_col(width = 0.8, position="dodge") +
  scale_x_discrete(labels = label_wrap(10)) +
  labs(x = "Component",
       y  = "GWP (kgCO_2 e)",
       title = paste("Component-wise comparison of the carbon footprint\n of manufacturing of the", name, "server")) +
    scale_color_manual(values =
                       c("darkgreen", "blue", "purple")) +
  theme(text = element_text(size = 20))  ;
  }
#+end_src

#+RESULTS:


* Checking that we can get the same dynamic consumption estimate as Green Algorithms
#+LaTeX: \label{sec:ga}
To do a first sanity check, we verify that we are able to reproduce
the same results as GA on the dynamic consumption part :

We choose a configuration that we know is available in both databases
(GA version 2.2 at the time of this experiment):
- 1 CPU A8-7680 (4 cores)
- 1 GPU NVIDIA GTX 1080 Ti
- 64 GB Memory

- Use time of 12h 0min
- no PUE / dynamic ratio
- carbon intensity of France is used (51.28 g CO_2 e/kWh)

We are using Green Algorithms v2.2
for an expected result of 196.32g of CO_2 e and 3.83 kWh of dynamic
consumption (this [[http://calculator.green-algorithms.org//?runTime_hour=12&runTime_min=0&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=4&CPUmodel=A8-7680&numberGPUs=1&GPUmodel=NVIDIA%20GTX%201080%20Ti&memory=64&platformType=localServer][link]] should in theory get you to the page with this
exact setup and results but it seems like GA sharing feature is broken right
now).

If we now run the experiment with our tool :
#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/test_equals_ga.json", 'r') as test_ga:
    model_ga = json.load(test_ga)
results = run_experiment(model_ga, "test_equals_ga.json")

print_gwp_and_energy(results)
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 0.2, 'direct': 0.196, 'total': 0.4, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 2.6, 'direct': 49.3, 'total': 52.0, 'unit': 'MJ'}, 'adp': {'embodied': 3.3e-05, 'direct': 2.46e-07, 'total': 3.3e-05, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 3.83, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 0.0002, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 0.0004, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 0.0011, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: energy consumption: {'value': 3.83, 'unit': 'kWh'}
: dynamic impacts gwp: {'embodied': 0.2, 'direct': 0.196, 'total': 0.4, 'unit': 'kgCO2eq'}

we see that we indeed obtain the same results of 196gCO_2 e and 3.83
kWh of dynamic energy consumption.

* replicating results from \cite{Bannour2021evaluating}
#+LaTeX: \label{sec:bannour}
In order to replicate results, we first need to gather some
information about the hardware configuration used to run the
experiments. Then, we will face the challenge of inconsistencies in the
data presented in the paper. Finally, we will be able to run
experiments that give the same energy consumption estimates as those
presented in the paper.

** detailing the Hardware configurations
The authors provided us with information about the hardware
configurations used to run  the experiments. 

the facility setup is the [[https://doc.lab-ia.fr/][LaBia]] cluster. We can see that the only nodes using a
20 core CPU are: n[101-102]:

-  2 x Intel Xeon Gold 6148 20 cores / 40 threads @ 2.4 GHz (Skylake)
-  384 GiB of RAM
-  4 x NVIDIA Tesla V100 with 32 GiB of RAM (NVLink)

using 32 GB of RAM and not the full 384.

The lab server on the other hand is the Segur machine, using one GTX 1080 Ti with 11GB of memory.
it is a Dell PowerEdge R730 with 2 GTX 1080 Ti, 2 Intel Ben E5-2620
v4 CPU and 125 GB memory (only 11 of which are requested).

while we do not have the Intel Xeon Gold 6148 in our CPU database, we
can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/120489/intel-xeon-gold-6148-processor-27-5m-cache-2-40-ghz/specifications.html][Intel's website]] that it has a \gls{TDP} of 150W, was released in
2017 with a process of 14nm with the Skylake architecture, this is
sufficient information to add one entry to our database, knowing the
information about the Skylake architecture from [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)][WikiChips]]. 

** Problems with the provided data

Results presented in the paper do not seem coherent from one table to
the other (tables 3 and 4). If we try to convert from energy consumption to carbon
emissions using the presented carbon intensity of 39 gCO_2 e/kWh we do
not at all find the same results as the ones presented.
For instance, for the first method (Yu2020) for the French Press
benchmark, it is indicated 1.38kWh consumption and 350.15g CO_2 e.

We can see that if we are to use the presented carbon intensity, we
get emissions of src_python{return round(39*1.38,1)}
{{{results(=53.8=)}}} gCO_2 e for a 1.38kWh energy consumption. This is
really far from the 350 gCO_2 e presented in the paper.

*** Trying to understand the problem

 Let us check if the factor to convert from table 4 to table 3 is
 constant.
 If it is, it would maybe explain the problems. When filling the table
 the authors might have miss-clicked on the location and the Carbon
 Intensity used would just be the one of another country.

 #+begin_src python :results output :exports none
import numpy as np
emissions = [350.15,260.26,16.67,14.31,20.68,20.03,104.4,102.08,3.83,4.99,5.57,5.67]
energy = [1.38,1.03,0.07,0.06,0.08,0.08,0.41,0.40,.02,.02,.02,.02]
CI = [em / en for en, em in zip(energy, emissions)]
print(CI, np.mean(CI))

 #+end_src

 #+RESULTS:
 : [253.73188405797103, 252.6796116504854, 238.14285714285714, 238.50000000000003, 258.5, 250.375, 254.63414634146343, 255.2, 191.5, 249.5, 278.5, 283.5] 250.39695826606476

 We obtain results around 250 gCO_2 e/kWh with some non negligible
 variations (The smallest conversion factor is of 191.5 gCO_2 e/kWh
 while the highest is of 283.5 gCO_2 e/kWh)

 according to GA's v2.2 database, this carbon intensity of around 250gCO_2
 e/kWh would approximately correspond to Lithuania's one. According to
 the version 1.1 of the data (version seemingly used in the article),
 the closest one would be Hungary.

 Still, we can observe quite important variations in carbon intensity
 to convert from the presented energy consumption to the presented
 carbon emissions, this would tend to infirm the hypothesis of just an
 error of selection in the carbon intensity used. 

 Even if there are obviously problems with the presented data, we still
 want to try and replicate the presented results. Indeed, if the data
 is flawed only in the table presenting the energy consumption or only
 in the table presented the carbon footprint, we might be able to
 reproduce the results of one of the tables (i.e. either the
 consumption or the carbon footprint)

** experiments
It is said that the default \gls{PUE} used is 1.67. In order to replicate
the results, and even if the dynamic ratio and the \gls{PUE} do not have the
same meaning. Since they are both used in the same way we will use a
dynamic ratio of 1.67

we can see in [[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/TDP_gpu.csv][the latest version of Green Algorithms' GPU TDP database]]
that they have a \gls{TDP} value of 300W for a Tesla V100 GPU whereas we
have a \gls{TDP} of 250W for the same card in our database. In order to see
if we can replicate the same consumption and see the difference
resulting from this data-point inconsistency we will try two
versions. One with a V100 and one with a card with a \gls{TDP}
of 300W in our database: the NVIDIA A100 PCIe 80 GB. This will of
course also impact the manufacture impacts but we are here only focusing on
reproducing the same direct impacts

#+begin_src python :post attr_wrap(caption="Comparison of our estimates with the expected results for the different NER experiments, the columns 'trying to match' present a scenario where we volontarily choose an  NVIDIA A100 PCIe 80 GB card to match the TDP used in Green Algorithms", data=*this*) :results drawer :exports results :session
table = pd.read_csv("expected/expected_bannour.csv", header=[0,1,2,3])

index =  pd.MultiIndex.from_tuples(table.columns.values)
index = index.set_levels(['Facility only', '', '','','','','',''], level=2, verify_integrity=False)
table.columns = index

rename_multi_index(table, ('Method','Unnamed: 0_level_1','','Unnamed: 0_level_3'), ('Method', '','', ''))
rename_multi_index(table,('Task','Unnamed: 1_level_1','','Unnamed: 1_level_3'), ('Task','','', ''))
rename_multi_index(table,('Hardware','Unnamed: 2_level_1','','Unnamed: 2_level_3'),('Hardware','','', ''))


def set(method, task, hardware, col, value):
    table.loc[(table[('Method','','','')] == method) & (table[('Task','','','')] == task) & (table[('Hardware','','','')] == hardware), col] = value

with open("boaviztapi/data/ml_setups/LaBia.json", 'r') as m:
    labia = json.load(m)
with open("boaviztapi/data/ml_setups/Segur.json", 'r') as m:
    segur = json.load(m)

labia["server"]["configuration"]["ram"][0]["capacity"] = 32
segur["server"]["configuration"]["ram"][0]["capacity"] = 11

labia["gpu"][0]['units'] = 1
segur["gpu"][0]['units'] = 1

labia["cpu_usage"] = 0
segur["cpu_usage"] = 0

labia['usage']['gwp_factor'] = 39E-3
segur['usage']['gwp_factor'] = 39E-3

labia['usage']['dynamic_ratio'] = 1.67
segur['usage']['dynamic_ratio'] = 1.67



def estimate(model, task, time_server, time_facility):
   print(task)
   print('server')
   segur["usage"][ "minute_use_time"] = time_server
   output = run_experiment(segur, model + '_' + task + '_Server', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, "Server", ('Estimated', 'Energy', '','(kWh)'), energy)
   set(model, task, "Server", ('Estimated', 'Carbon','','(gCO2e)'), gwp * 1000)
   print('Facility')
   labia["gpu"][0]["model"] = "NVIDIA Tesla V100 PCIe 32 GB"
   labia["usage"][ "minute_use_time"] = time_facility
   output = run_experiment(labia, model + '_' + task + '_Facility', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, 'Facility', ('Estimated', 'Energy','', '(kWh)'), energy)
   set(model, task, 'Facility', ('Estimated', 'Carbon','','(gCO2e)'), gwp * 1000)
   print('Facility same TDP')
   labia["gpu"][0]["model"] = "NVIDIA A100 PCIe 80 GB"
   labia["usage"][ "minute_use_time"] = time_facility
   output = run_experiment(labia, model + '_' + task + '_Facility_match_TDP', directory='Bannour2021evaluating', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   set(model, task, 'Facility', ('Estimation', 'trying to match', 'Facility only','(kWh)'), energy)
   set(model, task, 'Facility', ('Estimation', 'trying to match', 'Facility only', '(gCO2e)'), gwp * 1000)

print('Yu2020')
estimate("Yu2020", "French Press", 163 + 39/60, 118 + 4/60)
estimate("Yu2020", "EMEA", 9 + 31/60, 6 + 51/60)
estimate("Yu2020", "MEDLINE", 11 + 55/60, 9 + 11/60)

print('\nMa2016')
estimate("Ma2016", "French Press", 58 + 30/60, 46 + 44/60)
estimate("Ma2016", "EMEA", 2 + 14/60, 2 + 27/60)
estimate("Ma2016", "MEDLINE", 3 + 11/60, 2 + 58/60)  

multi_index_to_multiline_header(table)
to_org_table(table)
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :float t :caption \caption{Comparison of our estimates with the expected results for the different NER experiments, the columns 'trying to match' present a scenario where we volontarily choose an  NVIDIA A100 PCIe 80 GB card to match the TDP used in Green Algorithms} 
| Method   | Task         | Hardware   |   Expected |   Estimated |        Estimation |   Expected |   Estimated |        Estimation |
|          |              |            |     Energy |      Energy |   trying to match |     Carbon |      Carbon |   trying to match |
|          |              |            |            |             |     Facility only |            |             |     Facility only |
|          |              |            |      (kWh) |       (kWh) |             (kWh) |    (gCO2e) |     (gCO2e) |           (gCO2e) |
|----------+--------------+------------+------------+-------------+-------------------+------------+-------------+-------------------|
| Yu2020   | French Press | Server     |       1.38 |      1.16   |          nan      |     350.15 |      45.1   |            nan    |
| Yu2020   | French Press | Facility   |       1.03 |      0.861  |            1.03   |     260.26 |      33.6   |             40    |
| Yu2020   | EMEA         | Server     |       0.07 |      0.0673 |          nan      |      16.67 |       2.62  |            nan    |
| Yu2020   | EMEA         | Facility   |       0.06 |      0.0499 |            0.0595 |      14.31 |       1.95  |              2.32 |
| Yu2020   | MEDLINE      | Server     |       0.08 |      0.0843 |          nan      |      20.68 |       3.29  |            nan    |
| Yu2020   | MEDLINE      | Facility   |       0.08 |      0.0669 |            0.0797 |      20.03 |       2.61  |              3.11 |
| Ma2016   | French Press | Server     |       0.41 |      0.414  |          nan      |     104.4  |      16.1   |            nan    |
| Ma2016   | French Press | Facility   |       0.4  |      0.341  |            0.406  |     102.08 |      13.3   |             15.8  |
| Ma2016   | EMEA         | Server     |       0.02 |      0.0158 |          nan      |       3.8  |       0.616 |            nan    |
| Ma2016   | EMEA         | Facility   |       0.02 |      0.0179 |            0.0213 |       4.99 |       0.697 |              0.83 |
| Ma2016   | MEDLINE      | Server     |       0.02 |      0.0225 |          nan      |       5.57 |       0.878 |            nan    |
| Ma2016   | MEDLINE      | Facility   |       0.02 |      0.0216 |            0.0258 |       5.67 |       0.843 |              1    |
:end:

Table \ref{tab:bannour} presents the estimate our tool produces in
comparison with the Expected values presented in the paper. We can see that we are able to obtain the same exact energy consumption
estimates up to rounding (when we do the modifications to the inputed setup for the
facility) except for Yu2020, French Press, Server where we have a
slightly lower estimation than the one proposed in the paper.
We can also see that, as expected, the estimates we do when
considering the "real" setup are lower than the ones presented in the
paper and this can be entirely explained by the difference in \gls{TDP} in
the database.
We can also conclude that the problem in the presented data lies in
the estimates of the carbon footprint and not in the estimates of
energy consumption.


* replicating results from \cite{Jay2023experimental} 
#+LaTeX: \label{sec:jay}
In order to replicate the results from the paper, we first need to
gather some information from the paper and its supplementary material
which is designed to allow for reproducible experiments.

- The hardware used is a Nvidia DGX-1 with two Intel Xeon E5-2698 v4, 512 GB of memory and 8 NVIDIA Tesla V100-SXM2-32GB. 
- The Carbon Intensity for France used in Green Algorithms V2.2 is
  51.28gCO_2 e/kWh ([[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/CI_aggregated.csv][latest version of Green Algorithms' Carbon
  Intensity Database]])
- To convert from kWh to kJ, one must multiply the result by 3.6E+3.

we can see in [[https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/TDP_gpu.csv][the latest version of Green Algorithms' GPU TDP database]]
that they have a \gls{TDP} value of 300W for an NVIDIA V100 GPU whereas we
have a \gls{TDP} of 250W for the same card in our database. As a first
version, just to see if we are able to obtain the same exact results
as those presented in the paper, we will use as GPUs a card with a \gls{TDP}
of 300W in our database: the NVIDIA A100 PCIe 80 GB.

We can also see that the CPU model used is the Xeon E5-2698 v4 with a
tdp 135. However, it isn't available in Green Algorithm, the model
used is the Xeon E5-2697 v4 with a \gls{TDP} of 145W and 18 cores.
In order to reproduce the results presented in the paper, we will use
in our setup one CPU with 40 cores, a \gls{TDP} of 324W (145/18*40) and a
die size of 9.12cm² (2*the die size of a Xeon E5-2698 v4, not relevant
for the computation of energy)

In the notebook accompanying the paper, we can see that the link explaining the configuration used for the CPU benchmarks are
exact copies of the ones for GPU benchmarks. We will therefore assume
that the CPU usage was 1 and GPU usage was 0. This configuration leads
to an energy consumption of 8.58Wh for one minute. Since this value is
strangely similar to the value of 7.58Wh/min used in the paper, we will also assume that there was a mistake when copying
results from the Green Algorithm website and therefore use the value
of 8.58Wh/min instead of the value of 7.58Wh/min to compute the
expected results.

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)
    dgx_1_model_correct = copy.deepcopy(dgx_1_model)

def get_energy_joules(results):
    energy_kWh = results['impacts']['energy consumption']['value']
    energy_J = 3.6E3*energy_kWh
    return(f"energy consumption: {energy_J:.3f} kJ", energy_J)

# expected results
online_tools = {}

# GPU
online_tools['Green Algorithm GPU'] = {}
online_tools['Green Algorithm GPU']['EP'] = (43.18 * 68 / 60) * 3.6 # converting to joules https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=1&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['LU'] = (31.18 * 204 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.7&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['MG'] = (14.26 * 157 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0.2&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.25&memory=512&platformType=localServer
online_tools['Green Algorithm GPU']['idle'] = (2.29 * 157 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0&memory=512&platformType=localServer

# CPU
online_tools['Green Algorithm CPU'] = {}
online_tools['Green Algorithm CPU']['EP'] = (8.58 * 50 / 60) * 3.6 # converting to joules https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=1&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['LU'] = (8.58 * 30 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.7&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['MG'] = (8.58 * 125 / 60) * 3.6 # https://green-algorithms.org//?runTime_hour=0&runTime_min=1&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=40&CPUmodel=Xeon%20E5-2697%20v4&usageCPUradio=Yes&usageCPU=0.2&numberGPUs=8&GPUmodel=NVIDIA%20Tesla%20V100&usageGPUradio=Yes&usageGPU=0.25&memory=512&platformType=localServer
online_tools['Green Algorithm CPU']['idle'] = (0 * 60 / 60) * 3.6 

def experiment(model, core_type, task, benchmark, cpu_usage, gpu_usage, time):
    print(benchmark)
    model['cpu_usage'] = cpu_usage
    model['gpu_usage'] = gpu_usage
    model['usage']['minute_use_time'] = time
    output = run_experiment(model, f'{core_type}_{benchmark}_{task}', directory='Jay2023experimental')
    s, r = get_energy_joules(output)
    diff ="{:.3f}".format(r - online_tools['Green Algorithm ' + core_type][benchmark])
    print(s, f"difference from expectation: {diff} kJ")
    return r, diff



def experiments_gpu(model, task):
    print('GPU benchmark')
    df = pd.DataFrame(columns=['Benchmark','Value (kJ)','Difference (kJ)'])
    
    energy, diff = experiment(model, 'GPU', task, 'EP', 0, 1, 68/60)
    df = df.append({'Benchmark':'EP','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'GPU', task,'LU', 0, .7, 204/60)
    df = df.append({'Benchmark':'LU','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'GPU', task,'MG', .2, .25, 157/60)
    df = df.append({'Benchmark':'MG','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    return df

def experiments_cpu(model, task):
    print('\nCPU benchmark')
    df = pd.DataFrame(columns=['Benchmark','Value (kJ)','Difference (kJ)'])
    energy, diff = experiment(model, 'CPU', task, 'EP', 1, 0, 50/60)
    df = df.append({'Benchmark':'EP','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'CPU', task, 'LU', 1, 0, 30/60)
    df = df.append({'Benchmark':'LU','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    energy, diff = experiment(model, 'CPU', task, 'MG', 1, 0, 125/60)
    df = df.append({'Benchmark':'MG','Difference (kJ)':diff,'Value (kJ)':energy}, ignore_index=True)
    return df


def experiments(model,task):
    experiments_gpu(model, task)
    experiments_cpu(model, task)



#print('Replicating the exact results')

dgx_1_model['server']['configuration']['cpu'] = {
          "units": 1,
          "die_size": 9.12,
	  "tdp": 324,
	  "core_units":40
}
dgx_1_model['gpu'] = [
  {
      "units": 8,
      "model": "NVIDIA A100 PCIe 80 GB"
  }
]

#experiments(dgx_1_model)
#print('\nRunning the experiments with the "correct" setup')
#experiments(dgx_1_model_correct)
#+end_src

#+RESULTS:

Table \ref{tab:benchmark} present the results obtained when trying to match the expected results (same hardware setup as used for
obtaining values with Green Algorithms) and Table \ref{tab:benchmark_real_hardware} present the results obtained When using the hardware setup really used.
#+begin_src python :post attr_wrap(caption="GPU benchmark", data=*this*) :results drawer :exports results :session
to_org_table(experiments_gpu(dgx_1_model, 'match'))
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :float t :caption \caption{Caption} 
| Benchmark   |   Value (kJ) |   Difference (kJ) |
|-------------+--------------+-------------------|
| EP          |       176.04 |            -0.134 |
| LU          |       381.6  |            -0.043 |
| MG          |       134.28 |            -0.049 |
:end:

#+begin_src python :post attr_wrap(caption="CPU benchmark", data=*this*) :results drawer :exports results :session
to_org_table(experiments_cpu(dgx_1_model, 'match'))
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :float t :caption \caption{CPU benchmark} 
| Benchmark   |   Value (kJ) |   Difference (kJ) |
|-------------+--------------+-------------------|
| EP          |       25.74  |              0    |
| LU          |       15.444 |              0    |
| MG          |       64.44  |              0.09 |
:end:

#+begin_src python :post attr_wrap(caption="GPU benchmark", data=*this*) :results drawer :exports results :session
to_org_table(experiments_gpu(dgx_1_model_correct, 'correct'))
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :float t :caption \caption{GPU benchmark} 
| Benchmark   |   Value (kJ) |   Difference (kJ) |
|-------------+--------------+-------------------|
| EP          |       149.04 |           -27.134 |
| LU          |       324.36 |           -57.283 |
| MG          |       117    |           -17.329 |
:end:

#+begin_src python :post attr_wrap(caption="CPU benchmark", data=*this*) :results drawer :exports results :session
to_org_table(experiments_cpu(dgx_1_model_correct, 'correct'))
#+end_src

#+RESULTS:
:results:
#+ATTR_LATEX: :float t :caption \caption{CPU benchmark} 
| Benchmark   |   Value (kJ) |   Difference (kJ) |
|-------------+--------------+-------------------|
| EP          |       23.04  |             -2.7  |
| LU          |       13.824 |             -1.62 |
| MG          |       57.6   |             -6.75 |
:end:

We can see that we are able to obtain results that are exactly the
same as the expected ones up to rounding errors (difference 3 orders of magnitude
lesser than the value). We can also see that even though the input
value to Green Algorithms does not exactly correspond to the hardware
setup used, the difference to the expected
results isn't too high. The difference between our estimate using
'correct' data and the expected values is around 10% of the estimated value.
These results demonstrate the importance of inputting the right
hardware if one wants precise results.

* replicating results from \cite{Dinarelli2022toward}
#+LaTeX:  \label{sec:dinarelli}
As for other experiments aiming at reproducing results, we first need
to gather enough information to run our 
experiments. We will also check the consistency of the results
presented in the paper. This will allow us to run our estimates.
We will focus on two results that we will try to reproduce. First the
fine tuning of the SSL model which is the most time consuming task
presented and then we will focus on the training time for the spectro
model, this should allow us to get a good overview of the results.

** setup experiments                                               :noexport:
First, let us define a prototype ml setup. We will use it to define
the different hardware configurations. This will help us easily run
the different experiments to reconstruct the results from the
different tables.

  #+begin_src python :results both :exports none :session
model = {
"server": {},
"gpu": [],
"psf": 1,
"nb_nodes": 1,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "dynamic_ratio": 1,
  "hours_use_time": 0,
  "minute_use_time": 118.04,
  "usage_location": "FRA",
  "gwp_factor": 51E-3
}
}
  #+end_src

  #+RESULTS:



** Trying to find information about the hardware setup

The authors gave us some insight on the hardware used for running
their experiments. Without their help, we would not have been able to
produce a single estimate. 

*** quote from the author                                          :noexport:
#+begin_quote 
En tout cas, pour essayer de te donner les info dont tu as besoin, après si c'est pas ça, ou si tu as besoin d'autres informations, n'hésite pas à demander :
"CPU : nombre de coeurs utilisés, modèle" => je ne sais pas combien de coeur CPU sont utilisé par les modèles wav2vec que j'ai utilisé, mes modèles SLU en utilise un seul.
"GPU : nombre utilisés et modèles, mémoire utilisée" (je présume que
tu voulais écrire "nombre de coeur utilisés") => 
4 GPU pendant 100 heures pour fine-tuner le modèle wav2vec (seulement pour les expériences où il est fine-tuné évidemment), 1 seule GPU pour mes modèles SLU.

Pour la taille des modèles :
environ 308 millions de paramètres pour le modèle wav2vec2
environ 12 millions de paramètres pour le modèle SLU

Pour la mémoire utilisée, on est à environ 80GB de mémoire centrale (RAM de la CPU) et environ 8GB de mémoire GPU pour les entraînements des mes modèles SLU.
Pour le fine-tuning des modèles wav2vec je ne sais pas, je n'ai jamais regardé pendant l'apprentissage de ces modèles, je sais que ça passe pas sur les GPU à 24GB du LIG, du coup j'ai dû le faire sur JZ sur la partition de GPU à 32 GB.
Je présume que la plupart des GPU (4 GPU à 32GB pour rappel) est utilisé par le modèle et les gradients des paramètres, puisque l'apprentissage des modèles SLU sur les mêmes données passe sur des GPU à 12GB du LIG.

Alors, sur JZ j'utilise les Tesla V100-SXM2-32GB .
Au LIG, pour les modèles SLU, j'utilise principalement des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go.
Il m'est arrivé d'utiliser parfois des NVIDIA TITAN X (Pascal) 12Go et des NVIDIA Quadro RTX 6000 24Go.

En fait au LIG c'est OAR qui gère les job, du coup ce n'est pas facile de monitorer exactement où le job est exécuté.
Je sais que si je lance sur une machine donné, ce que je fais parce
que OAR par défaut te met sur la première disponible et du coup tout
le monde se retrouve sur les mêmes machines, il y a telle ou telle
GPU, mais là je ne me rappelle pas dans quelle mesure je lance plus
sur une machine que sur une autre. À priori c'est 90%-95% du temps sur
des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go en mesure
égale.
#+end_quote

*** Hardware for the fine-tuning 
The author said that a node from the Jean Zay supercomputer with 4 GPUs with
32GB memory was used for the fine tuning of the wave2vec model. if we look at the [[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][Idris' website]] we
think that the nodes used were from the *v100-32g*, it is the only node
with matching requirements in terms of number of GPU and memory per
GPU.

these nodes have the following hardware configuration :
        +  2 Intel Cascade Lake 6248 (20 cores at 2,5 GHz)
        +  192 GB  memory per node
        +  4 GPU Nvidia Tesla V100 SXM2 32 GB

Because we do not have the Intel Cascade Lake 6248 in our database, we
need to find some information about it. We can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/192446/intel-xeon-gold-6248-processor-27-5m-cache-2-50-ghz/specifications.html][Intel's webpage]]
that it is a processor of the Cascade Lake architecture. On [[https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake#LCC_SoC][Wikichip]],
we can see that Cascade Lake Processors use dies largely similar to
those of the [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)#Core][Skylake cores]]. Combining all of these pieces of
information, we can get an estimation of the details of an Intel
Cascade Lake 6248 :
- model: "Xeon Gold 6248"
- manufacture date: "2019"
- process: 14nm
- number of cores: 20
- die size: 694 mm² (XCC configuration)

#+begin_src python :results output :exports none :session
jean_zay = copy.deepcopy(model)
jean_zay["server"]["configuration"] = {
    "cpu": {
      "units": 2,
      "model": "Xeon 6248"
    },
    "ram": [
      {
        "units": 1,
        "capacity": 192
      }
    ]
  }
jean_zay["gpu"] = [
  {
    "units": 4,
    "model": "NVIDIA Tesla V100 SXM2 32 GB"
  }
]
#+end_src

#+RESULTS:

*** Hardware for training the models

We are told that training uses only one GPU at a time and that it uses
roughly half of the time a RTX 2080 Ti and the other half a GTX 1080
Ti, to represent this, we will put the two different models in the
list of GPUs and use a 'gpu usage' of .5.
We are also told that the training uses 80 GB memory with no
additional information on the hardware used.
Since we do not know any more precise information, we will use the
default values of our tool to complete the missing pieces of information

    #+begin_src python :results output :exports none :session

training_SLU_model = copy.deepcopy(model)
training_SLU_model["gpu"] = [
  {
    "units": 1,
    "model": "NVIDIA GeForce RTX 2080 Ti 11GB"
  },
  {
    "units":1,
    "model": "NVIDIA GeForce GTX 1080 Ti"
  }
]
training_SLU_model["gpu_usage"] = .5
training_SLU_model["server"]["configuration"] = {
    "ram": [
      {
        "units": 1,
        "capacity": 80
      }
    ]
}
    
    #+end_src

    #+RESULTS:

** coherency of the results

One first good news is that information are coherent with themselves.
Using the indicated (in the paper) carbon intensity of 51gCO_2 e/kWh
used and indicated energy consumption, we are able to find back the carbon emissions
indicated in the table. The only problem is that for table 1, it seems
that there was a translation error when filling the table. The figures
are written in the french notation with "," separating units from
decimals and not the usual ".".
For instance, if we look at the first line of table 1, we can read
a consumption of 4,473 kWh, that we can translate to 4.473 kWh.
We obtain src_python{return 4.473*51} {{{results(=228.123=)}}}g CO_2 e, the same value as indicated in the paper.

We then only need to be able to find coherent energy consumption
values to obtain comparable results.

** Estimating energy consumption

*** fine tuning of the SSL model

    #+begin_src python :results output :exports none :session
jean_zay["usage"]["hours_use_time"] = 100
jean_zay["usage"]["minute_use_time"] = 0
output = run_experiment(jean_zay, "fine_tuning_SSL", directory='Dinarelli2022toward')
print_gwp_and_energy(output)
    #+end_src

    #+RESULTS:
    : estimated impacts: {'gwp': {'embodied': 4.0, 'direct': 5.46, 'total': 9.4, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 49.0, 'direct': 1210.0, 'total': 1300.0, 'unit': 'MJ'}, 'adp': {'embodied': 0.0005, 'direct': 5.21e-06, 'total': 0.00051, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 107.0, 'unit': 'kWh'}}
    : to put impacts in perspective: {'relative_SNBC': {'value': 0.0047, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 0.0096, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 0.016, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
    : energy consumption: {'value': 107.0, 'unit': 'kWh'}
    : dynamic impacts gwp: {'embodied': 4.0, 'direct': 5.46, 'total': 9.4, 'unit': 'kgCO2eq'}

When running an estimate of the impacts of the fine tuning, we can see that we obtain an estimate of 5.46kg CO_2 e for the direct
impacts and a dynamic consumption of 107 kWh, which is close to the
4.729kg CO_2 e and 97.720 kWh presented in the paper. The fact that
results aren't a perfect match and slightly higher than presented can
be explained by the fact that measures presented were carried out
based on a measurement tool (CarbonTracker). (results presented are
borrowed from \cite{Evain2021task} using the methodology from \cite{parcollet2021energy})

*** Table 1
We now turn our focus towards replicating the measure of impacts for
the spectro experiments presented in the Table 1 of the paper.
#+begin_src python :post attr_wrap(caption="Comparison of our estimates with the measures presented on the spectro experiments", data=*this*) :results drawer :exports results :session
table = pd.read_csv('expected/expected_dinarelli.csv', header=[0,1,2])
rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('model', '', ''))

def set(model, col, value):
    table.loc[table[('model','', '')] == model, col] = value


def estimate(steps, hours, minutes):
    name = f"spectro {steps} steps"
    print(name +  ":")
    training_SLU_model['usage']['hours_use_time'] = hours
    training_SLU_model['usage']['minute_use_time'] = minutes
    output = run_experiment(training_SLU_model, f'PortMEDIA_spectro_{steps}-steps',  directory='Dinarelli2022toward')
    energy, gwp = print_gwp_and_energy(output)
    set(name, ('estimated', 'power', '(kWh)'), energy)
    set(name, ('estimated', 'carbon', '(gCO2e)'), int(gwp * 1000))

estimate(3,36,14)
estimate(2,24,14)
estimate(1,15,52)

to_org_table(multi_index_to_multiline_header(table))
    #+end_src

    #+RESULTS:
    :results:
    #+ATTR_LATEX: :float t :caption \caption{Comparison of our estimates with the measures presented on the spectro experiments} 
    | model           |   expected |   estimated |   expected |   estimated |
    |                 |      power |       power |     carbon |      carbon |
    |                 |      (kWh) |       (kWh) |    (gCO2e) |     (gCO2e) |
    |-----------------+------------+-------------+------------+-------------|
    | spectro 3 steps |      4.473 |       10.1  |        228 |         517 |
    | spectro 2 steps |      2.989 |        6.78 |        152 |         346 |
    | spectro 1 step  |      1.708 |        4.44 |         87 |         226 |
    :end:

Table \ref{tab:dinarelli} compares our estimates with the presented
measures on the spectro experiments. We can see that we obtain carbon emission estimates around 3 times higher than
those presented in the paper, This difference is important but results
are still in the same order of magnitude. It is expected that we obtain higher
estimates than the measurements as presented in
\cite{Jay2023experimental} but the difference could potentially be
explained by the lack of information about the GPU usage (if GPUs were
running at 30\% capacity for instance) during training.

* results from \cite{Cattan2022benchmarking}
#+LaTeX:  \label{sec:cattan}
This paper studies the gains and impacts of choosing to use one type
of NLP model in a system. It evaluates the impacts of training the
models but also of running inferences.


We try to replicate results that were obtained by scaling up the results obtained in
\cite{Cattan2022benchmarking} for one inference to account for the
weekly number of requests the search engine of Qwant receives.
As always, we will need to first find the hardware configuration used,
then we will check the coherency of the expected results and run our experiments.

** Hardware configuration

We where told that the hardware used was an NVIDIA DGX equipped with 8
NVIDIA Tesla V100 SMX2 16GB. I was not able to find such a
configuration on NVIDIA's Website but since the Tesla V100 SMX2 32GB
GPU present in an NVIDIA DGX-1 server have the same exact \gls{TDP}, we will
suppose that this is the hardware used.
 
** running experiments

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)

def estimate(model, task, time):
   print(model + ": " + task)
   dgx_1_model["usage"][ "hours_use_time"] = time
   output = run_experiment(dgx_1_model, model + '_' + task,  directory='Cattan2022benchmarking', silent=True)
   energy, gwp = print_gwp_and_energy(output)
   return energy, gwp
#+end_src

#+RESULTS:


#+begin_src python :post attr_wrap(caption="Comparison of our estimates with the presented measures", data=*this*) :results drawer :exports results :session

table = pd.read_csv('expected/cattan_benchmarking.csv', sep=';', header=[0,1,2])

rename_multi_index(table, ('Tasks', 'Models', 'Unnamed: 0_level_2'), ('Tasks', 'Models', ''))

def set(model, task, col, val):
    table.loc[table[('Tasks', 'Models', '')] == model, (task,col)] = val

dgx_1_model['usage']['minute_use_time'] = 0
dgx_1_model['usage']['usage_location'] = "USA"

def estimate_and_set(model, task, time):
   energy, gwp = estimate(model,task,time)
   set(model, task, 'Estimated Energy', energy/1000)
   set(model, task, 'Estimated CO2', gwp)

print('MEDIA')
estimate_and_set('FlauBERTbase', 'MEDIA', 20.19)
estimate_and_set('CamemBERTlarge, CCNet 135 Gb', 'MEDIA', 50.63)
estimate_and_set('CamemBERTbase, OSCAR 138 Gb', 'MEDIA',  20.23)
estimate_and_set('CamemBERTbase, CCNet 135 Gb', 'MEDIA', 15.57)
estimate_and_set('CamemBERTbase, OSCAR 4 Gb', 'MEDIA', 15.89)
estimate_and_set('CamemBERTbase, CCNet 4 Gb', 'MEDIA', 15.64)
estimate_and_set('CamemBERTbase, Wiki 4 Gb', 'MEDIA', 15.38)
estimate_and_set('FrALBERTbase, Wiki 4 Gb', 'MEDIA', 9.11)
estimate_and_set('XLM-Rbase', 'MEDIA', 17.20)
estimate_and_set('XLM-Rlarge', 'MEDIA', 55.68)
estimate_and_set('mBERTbase', 'MEDIA', 17.95)
estimate_and_set('distill-mBERTbase', 'MEDIA', 15.06)
estimate_and_set('small-mBERTbase-fr', 'MEDIA', 16.45)
print('ATIS-FR')
estimate_and_set('FlauBERTbase', 'ATIS-FR', 3.08)
estimate_and_set('CamemBERTlarge, CCNet 135 Gb','ATIS-FR', 7.36)
estimate_and_set('CamemBERTbase, OSCAR 138 Gb', 'ATIS-FR',  3.27)
estimate_and_set('CamemBERTbase, CCNet 135 Gb', 'ATIS-FR', 2.55)
estimate_and_set('CamemBERTbase, OSCAR 4 Gb', 'ATIS-FR', 2.52)
estimate_and_set('CamemBERTbase, CCNet 4 Gb','ATIS-FR', 2.59)
estimate_and_set('CamemBERTbase, Wiki 4 Gb','ATIS-FR', 2.50)
estimate_and_set('FrALBERTbase, Wiki 4 Gb', 'ATIS-FR', 1.39)
estimate_and_set('XLM-Rbase', 'ATIS-FR', 2.40)
estimate_and_set('XLM-Rlarge', 'ATIS-FR', 8.02)
estimate_and_set('mBERTbase', 'ATIS-FR', 2.48)
estimate_and_set('distill-mBERTbase','ATIS-FR', 2.35)
estimate_and_set('small-mBERTbase-fr','ATIS-FR', 2.46)


to_org_table(multi_index_to_multiline_header(table))
   #+end_src

   #+RESULTS:
   :results:
   #+ATTR_LATEX: :float t :caption \caption{Comparison of our estimates with the presented measures} 
   | Tasks                        |      MEDIA |             MEDIA |              MEDIA |          MEDIA |           MEDIA |    ATIS-FR |           ATIS-FR |            ATIS-FR |        ATIS-FR |         ATIS-FR |
   | Models                       |       Time |   Expected Energy |   Estimated Energy |   Expected CO2 |   Estimated CO2 |       Time |   Expected Energy |   Estimated Energy |   Expected CO2 |   Estimated CO2 |
   |                              |   (Heures) |             (MWh) |              (MWh) |           (Kg) |            (Kg) |   (Heures) |             (MWh) |              (MWh) |           (Kg) |            (Kg) |
   |------------------------------+------------+-------------------+--------------------+----------------+-----------------+------------+-------------------+--------------------+----------------+-----------------|
   | FlauBERTbase                 |      20.19 |            204.24 |             0.0442 |         147.84 |            2.27 |       3.08 |             30.88 |            0.00675 |          22.33 |           0.346 |
   | CamemBERTlarge, CCNet 135 Gb |      50.63 |            512.67 |             0.111  |         371.14 |            5.69 |       7.36 |             74.23 |            0.0161  |          53.75 |           0.827 |
   | CamemBERTbase, OSCAR 138 Gb  |      20.23 |            204.67 |             0.0443 |         148.15 |            2.27 |       3.27 |             32.57 |            0.00716 |          23.56 |           0.367 |
   | CamemBERTbase, CCNet 135 Gb  |      15.57 |            157.39 |             0.0341 |         113.96 |            1.75 |       2.55 |             24.79 |            0.00559 |          17.94 |           0.286 |
   | CamemBERTbase, OSCAR 4 Gb    |      15.89 |            160.7  |             0.0348 |         116.35 |            1.79 |       2.52 |             25.18 |            0.00552 |          18.25 |           0.283 |
   | CamemBERTbase, CCNet 4 Gb    |      15.64 |            158.08 |             0.0343 |         114.42 |            1.76 |       2.59 |             25.49 |            0.00567 |          18.48 |           0.291 |
   | CamemBERTbase, Wiki 4 Gb     |      15.38 |            155.46 |             0.0337 |         112.57 |            1.73 |       2.5  |             24.95 |            0.00548 |          18.1  |           0.281 |
   | FrALBERTbase, Wiki 4 Gb      |       9.11 |             92.02 |             0.02   |          66.61 |            1.02 |       1.39 |             13.71 |            0.00305 |           9.93 |           0.156 |
   | XLM-Rbase                    |      17.2  |            173.94 |             0.0377 |         125.9  |            1.93 |       2.4  |             25.72 |            0.00526 |          18.63 |           0.27  |
   | XLM-Rlarge                   |      55.68 |            563.95 |             0.122  |         408.25 |            6.26 |       8.02 |             76.08 |            0.0176  |          58.6  |           0.901 |
   | mBERTbase                    |      17.95 |            181.41 |             0.0393 |         131.36 |            2.02 |       2.48 |             24.72 |            0.00543 |          17.94 |           0.279 |
   | distill-mBERTbase            |      15.06 |            152.08 |             0.033  |         110.11 |            1.69 |       2.35 |             23.25 |            0.00515 |          16.79 |           0.264 |
   | small-mBERTbase-fr           |      16.45 |            166.24 |             0.036  |         120.35 |            1.85 |       2.46 |             24.56 |            0.00539 |          17.79 |           0.276 |
   :end:

Table \ref{tab:cattan} compares our estimates with the presented
measures. We can see that we obtain results as low as 4 orders of magnitude
lower than the expected results. This massive difference cannot be
easily explained and is a really surprising result.

** Explaining the massive differences between our estimates and the expected results

#+begin_src python :results output :exports none
print(3.500 * 8)
print(8*250 + 512*.3725 + 2*135)
print(8*250 + 512*.3725)

print(3.5 * 121.8/3600)
#+end_src

#+RESULTS:
: 28.0
: 2460.72
: 2190.72
: 0.11841666666666667

In our estimates, the consumption of one DGX-1 is estimated at
2460W (if we were to suppose that CPUs are running at full capacity)
and 2190W if we suppose that CPUs do not run. This is significantly lower than the 3500W provided by NVIDIA
and can be due at least in part to the fact that we do not account for
storage in our estimation.

Results are way lower than those presented. however, the presented
results seem at least surprising. If we use the consumption value
provided by NVIDIA of 3500W for one DGX-1 [[https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/dgx-1/dgx-1-rhel-centos-datasheet-update-r2_Updates_NV_web_fr_FR.pdf][DGX-1 datasheet]]. If used for
8 hours like for ATIS-FR with XLM-Rlarge, we would expect a
consumption of 28kWh. This is extremely far from the 76MWh
presented. There is therefore a problem in the expected data or (more
probably) in the hardware configuration used. 

#+begin_src python :results output :exports none
# dividing emissions by energy consumption to get Carbon Intensity
print(204.24E+3 / 147.84E+3)
print(512.67/  371.14)
print(92.02/ 66.61)
print(30.88/ 22.33)
print(74.23/53.75)
#+end_src

#+RESULTS:
: 1.3814935064935066
: 1.381338578434014
: 1.3814742531151478
: 1.3828929690998657
: 1.3810232558139535

Furthermore we can see that conversion from energy consumption to
carbon emissions make us remark that the carbon intensity seemingly
used is approximately 1.38 gCO_2 e/kWh. This is extremely low as the
Carbon Intensity for France is estimated between 50 and 200 gCO_2
e/kWh.

In order to get further insight on what could cause these
inconsistencies we will try and reproduce results from
\cite{Cattan2022usability} which uses the same configuration. If
results from this paper are consistent with our estimates, this would
tend to confirm that there is a problem in the data presented in
\cite{Cattan2022benchmarking} and not in our estimates.

** table from \cite{Cattan2022usability}

It is said that only one V100 GPU is used for training the different
models. (we will suppose that it was done on one DGX-1 server)
   
   #+begin_src python :results output :exports none
import numpy as np
energy = [1.08,3.10,.57,1.14,3.30,1.07,1.09,1.06]
emission = [317.87,914.27,167.8,337.70,973.29,317.02,321.42,314.17]
print(np.mean([em / en for en, em in zip(energy, emission)]))
   #+end_src

   #+RESULTS:
   : 295.2935224349162

We can see that the carbon intensity used seems to be of 295 gCO_2 e /
kWh.

we can see on [[https://github.com/Breakend/experiment-impact-tracker][Experiment-Impact-Tracker's repository]] that they by default use a \gls{PUE}
of 1.58, in order to replicate their results. We will choose to use
this value of 1.58 as dynamic ratio.

We can suppose that during training only the GPU is used at full
capacity. we can also try a scenario where one core of one GPU is used
during training. This would lead to including a cpu usage of 1/20
(since the CPU has 20 cores).

Table \ref{tab:cattan_usability} presents the results of these
experiments :

#+begin_src python :results output :exports none :session
table = pd.read_csv('expected/cattan_usability.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('model', '', ''))
rename_multi_index(table, ('estimate', 'Unnamed: 1_level_1', 'Unnamed: 1_level_2'), ('estimate', '',''))
rename_multi_index(table, ('time', 'Unnamed: 2_level_1','(s)'),('time','','(s)'))


def set(model, estimate, col, val):
    table.loc[(table[('model','','')] == model) & (table[('estimate','','')] == estimate), col] = val

with open("boaviztapi/data/ml_setups/Nvidia_DGX-1.json", 'r') as m:
    dgx_1_model = json.load(m)

dgx_1_model['usage']['gwp_factor'] = 295E-3
dgx_1_model['usage']['dynamic_ratio'] = 1.58
dgx_1_model["gpu"][0]['units'] = 1
dgx_1_model['server']['configuration']['cpu']['units'] = 1

def FQuAD_train_estimate(model, time_seconds):
    dgx_1_model["cpu_usage"] = 0
    energy, gwp = estimate(model, 'FQuAD_train_lower', time_seconds/3600)
    set(model, 'lower', ('estimated','energy','(kWh)'), energy)
    set(model, 'lower', ('estimated','carbon','(kgCO2e)'), gwp)
    dgx_1_model["cpu_usage"] = 1/20
    energy, gwp = estimate(model, 'FQuAD_train_upper', time_seconds/3600)
    set(model, 'upper', ('estimated','energy','(kWh)'), energy)
    set(model, 'upper', ('estimated','carbon','(kgCO2e)'), gwp)
#+end_src

#+RESULTS:

#+begin_src python :post attr_wrap(caption="Comparison of our estimates with the presented measures of impact for training the different models. The lower estimates correspond to a scenario where we suppose CPUs weren't used during training and upper estimates correspond to a scenario where we suppose that one CPU core was used  during training", data=*this*) :results drawer :exports results :session
FQuAD_train_estimate('CamemBERT_base', 7207)
FQuAD_train_estimate('CamemBERT_large', 19445)
FQuAD_train_estimate('FraLBERT_base', 3816)
FQuAD_train_estimate('XLM-R_base', 7676)
FQuAD_train_estimate('XLM-R_large', 21137)
FQuAD_train_estimate('mBERT_base', 7333)
FQuAD_train_estimate('small-mBERT_base', 7190)
FQuAD_train_estimate('distil-mBERT_base', 6466)

to_org_table(multi_index_to_multiline_header(table))
   #+end_src

   #+RESULTS:
   :results:
   #+ATTR_LATEX: :float t :caption \caption{Comparison of our estimates with the presented measures of impact for training the different models. The lower estimates correspond to a scenario where we suppose CPUs weren't used during training and upper estimates correspond to a scenario where we suppose that one CPU core was used  during training} 
   | model             | estimate   |   time |   expected |   estimated |   expected |   estimated |
   |                   |            |        |     energy |      energy |     carbon |      carbon |
   |                   |            |    (s) |      (kWh) |       (kWh) |   (kgCO2e) |    (kgCO2e) |
   |-------------------+------------+--------+------------+-------------+------------+-------------|
   | CamemBERT_base    | lower      |   7207 |       1.08 |       1.41  |      0.317 |       0.415 |
   | CamemBERT_base    | upper      |   7207 |       1.08 |       1.43  |      0.317 |       0.421 |
   | CamemBERT_large   | lower      |  19445 |       3.1  |       3.77  |      0.914 |       1.11  |
   | CamemBERT_large   | upper      |  19445 |       3.1  |       3.83  |      0.914 |       1.13  |
   | FrALBERT_base     | lower      |   3816 |       0.57 |       0.75  |      0.167 |       0.221 |
   | FrALBERT_base     | upper      |   3816 |       0.57 |       0.761 |      0.167 |       0.225 |
   | XLM-R_base        | lower      |   7676 |       1.14 |       1.5   |      0.337 |       0.441 |
   | XLM-R_base        | upper      |   7676 |       1.14 |       1.52  |      0.337 |       0.448 |
   | XLM-R_large       | lower      |  21137 |       3.3  |       4.1   |      0.973 |       1.21  |
   | XLM-R_large       | upper      |  21137 |       3.3  |       4.16  |      0.973 |       1.23  |
   | mBERT_base        | lower      |   7333 |       1.07 |       1.43  |      0.317 |       0.422 |
   | mBERT_base        | upper      |   7333 |       1.07 |       1.45  |      0.317 |       0.428 |
   | samll-mBERT_base  | lower      |   7190 |       1.09 |       1.4   |      0.321 |       0.414 |
   | samll-mBERT_base  | upper      |   7190 |       1.09 |       1.42  |      0.321 |       0.42  |
   | distil-mBERT_base | lower      |   6466 |       1.06 |       1.26  |      0.314 |       0.372 |
   | distil-mBERT_base | upper      |   6466 |       1.06 |       1.28  |      0.314 |       0.378 |
   :end:

We can see that for upper and lower estimates we obtain results slightly higher that those presented
in the paper but in the same order of magnitude. This is expected
since estimation tools tend to provide higher (and closer to reality) estimates than
measurement tools. However, we can also see that the estimation tool (\cite{Jay2023experimental})
does not capture some subtleties. For instance small-mBERT_base
training is quicker than mBERT_base one. However this does not
translate to smaller energy consumption most probably because one
model training uses more resources than the other one. Without fine
knowledge of the processing units usage, we cannot provide very
precise estimations and track small changes such as this one.


All of these results tend to confirm that there are problems with the
data available in \cite{Cattan2022benchmarking} but that the data from
\cite{Cattan2022usability} confirms us the hardware configuration used.

** New experiment :

After pointing out the problems in the data to the authors, they ran a
new experiment on the Segur machine. Table \ref{tab:cattan_new}
presents the newly obtained results using Experiment-Impact-Tracker :

#+ATTR_LATEX: :float t :caption \caption{Presentation of the new measures after re-running the training on another machine} 
| cpu_hours                |   1.0428555555555554 |
| gpu_hours                |   0.9933892874755572 |
| estimated_carbon_impact_kg | 0.024094323442314113 |
| total_power              |   0.4302695971583645 |
| kw_hr_gpu                 |   0.2516560133562949 |
| kw_hr_cpu                 |  0.02066651649077121 |
| exp_len_hours             |  0.5388999266756905  |

from these results, and knowing that the Segur machine is equipped with
2 20 core CPUs with 125 GB RAM  and 2 GTX 1080 Ti,
we can estimate that approximately 2 cores (1.04/.53) were used at
full capacity during training, which equates to 1/20 usage. The two
GPU also seem to have been used at full capacity.
we can deduce the used Carbon Intensity by dividing the estimated
carbon by the measured power

#+begin_src python :results value :exports none
return 0.024094323442314113 / 0.4302695971583645 * 1000
#+end_src

#+RESULTS:
: 55.99820113119911

this result of 56 gCO_2 e/kWh lead us to think that the Carbon
Intensity of France was used. (which would be logical since the
experiment was run in France)

We also know that Experiment Impact Tracker uses a \gls{PUE} of 1.58, in
order to try and reproduce these results, we will use a dynamic ratio
of 1.58. We will also try with the base dynamic ratio and see the difference

All of this allows us to run the following experiment to try and
reproduce these results

#+begin_src python :post attr_wrap(caption="Comparison of our estimates with the newly obtained measures. The match scenario uses a dynamic ratio of 1.58 while the Estimated scenario usses the base dynamic ratio of 1.83", data=*this*) :results drawer :exports results :session
with open("boaviztapi/data/ml_setups/Segur.json", 'r') as m:
    segur = json.load(m)

segur['usage']['minute_use_time'] = 0
segur['usage']['usage_location'] = "FRA"
segur['usage']['gwp_factor'] = 0.024094323442314113 / 0.4302695971583645
segur['cpu_usage'] = 1/20

def estimate(model, task, time):
   print(model + ": " + task)
   segur["usage"]["hours_use_time"] = time
   output = run_experiment(segur, model + '_' + task,  directory='Cattan2022benchmarking', silent=True)
   return print_gwp_and_energy(output)

energy_estimated, gwp_estimated = estimate('FrALBERTbase, Wiki 4 Gb trained on Segur', 'MEDIA', 0.5388999266756905)
segur['usage']['dynamic_ratio'] = 1.58
energy_match, gwp_match = estimate('FrALBERTbase_Wiki 4_Gb_trained_on_Segur_match', 'MEDIA', 0.5388999266756905)

df = pd.DataFrame(columns=['','Expected','Estimated', 'Match'])
df = df.append({'':'energy (kWh)','Expected':0.43,'Estimated':energy_estimated,'Match':energy_match}, ignore_index=True)
df = df.append({'':'Carbon (kgCO2e)','Expected':0.0241,'Estimated':gwp_estimated,'Match':gwp_match}, ignore_index=True)
to_org_table(df)
#+end_src

#+RESULTS:
|                 | Expected | Estimated |  Match |
|-----------------+----------+-----------+--------|
| energy (kWh)    |     0.43 |     0.507 |  0.436 |
| Carbon (kgCO2e) |   0.0241 |    0.0284 | 0.0244 |


Table \ref{tab:cattan_new_results} compares the estimates produced in
both scenatio with the new measures. We can see that we obtain very close results (a little bit higher just
as expected) when trying to get an
exact match by using a dynamic ratio of 1.58 and estimates are
increased when using the base dynamic ratio which stands
around 1.83.


# Estimate about the inference phase.

#+begin_src python :results value :exports none
return 0.02 * 40
#+end_src

#+RESULTS:
: 0.8


* estimations from \cite{Strubell2019energy} 
#+LaTeX:  \label{sec:strubell}
** Information about the hardware configuration

It is described in the paper that estimates are conducted by training
all models for a maximum of 24h. They use RAPL and NVIDIA System
Management Interface to measure the average consumption of the CPUs and
GPUs. 
All models are trained on one NVIDIA TITAN X except for ELMo
which is trained on 3 GTX 1080 Ti.
They then transcribe these results to estimates by using the training
time given in the paper and the description of the hardware given in
the paper.

No figures are presented regarding the average consumption of the
memory, CPU and GPU (separated). We only know about the model of GPU used for
estimating the consumption and the total estimated consumption for
training each model. We will therefore not give any value for
the CPU and ram and run our estimates as is. We will see what results
we obtain. We would like, not to obtain exact results since it wont be
possible given the information missing. Since they use measurement
tools, we can think that using a modeling using the \gls{TDP} will give
an higher result but since we do not know the quantity of memory used
and the CPU used, we are not sure that the results will be higher
(even if we can hypothesize that the CPU average consumption is
negligible compared to the GPU consumption.)

One reassuring point is that GTX 1080 Ti, V100, P100 and Titan X GPUs have the same
\gls{TDP} so the consumption estimated should make sense.

They use a \gls{PUE} of 1.58 and a Carbon Intensity of 0.954 pounds CO_2
e/kWh for American electricity production which is equivalent to
432.72 gCO_2 e/kWh.

#+begin_src python :results output :exports none :session
def convert_pounds_kg(x):
    return  0.453592 * x

def convert_kg_pounds(x):
    return  1 / 0.453592 * x

print(convert_pounds_kg(.954) * 1000)
#+end_src

#+RESULTS:
: 432.726768

** Checking the Coherency of the presented results

Since there are no estimates given for models trained on TPUs, we will
in the first time at least ignore these models.

Since table 3 of the paper presents the estimated consumption used, we can first
check the coherency of the table by seeing if we can reproduce the
same energy consumption by multiplying the power by the training time
and the \gls{PUE}

#+begin_src python :results value :exports none
return list(map(lambda x: 1.58/1000*x, (1415.78*12, 1515.43*84, 517.66*336, 12041.51*79, 1515.43*274120)))
#+end_src

#+RESULTS:
| 26.8431888 | 201.12786960000003 | 274.8153408 | 1503.0212782 | 656347.281128 |

We can see that, up to rounding we obtain the same results.
We can also check that we obtain the same carbon emissions.

#+begin_src python :results value :exports none
return list(map(lambda x: x*.954, [27,201,275,1507,656347])) 
#+end_src

#+RESULTS:
| 25.758 | 191.754 | 262.34999999999997 | 1437.6779999999999 | 626155.038 |

Also the same up to rounding errors. We can now serenely proceed with
running our estimations.

** running our estimations

*** First checks :noexport:
For a first check, we will compare the estimated power consumption of
just the GPUs with the presented hardware consumption. The \gls{TDP} of a
P100 GPU is 250W, also the same as the one of a GTX 1080 ti.


#+begin_src python :results value :exports none
return [
("model", "estimated", "measured"),
None,
("Transformer_base", 250*8, 1415.78),
("Transformer_big",250*8, 1515.43),
('ELMo',250*3, 517.66),
("BERT_base",250*64, 12041.51),
("NAS",250*8, 1515.43)
]
#+end_src

#+RESULTS:
| model           | estimated | measured |
|-----------------+-----------+----------|
| Transformer_base |      2000 |  1415.78 |
| Transformer_big  |      2000 |  1515.43 |
| ELMo            |       750 |   517.66 |
| BERT_base        |     16000 | 12041.51 |
| NAS             |      2000 |  1515.43 |

#+ATTR_LATEX: :float t :caption \caption{Comparison of estimated and measured power consumption. Estimates only take into account the GPU used} 
| model           | estimated | measured |
|-----------------+-----------+----------|
| Transformer_base |      2000 |  1415.78 |
| Transformer_big  |      2000 |  1515.43 |
| ELMo            |       750 |   517.66 |
| BERT_base        |     16000 | 12041.51 |
| NAS             |      2000 |  1515.43 |

Table \ref{tab:strubell_gpu} compares the estimated power consumption
when only accounting for the GPUs with the power consumption measures
presented in the paper. We can see that, as expected since the provided consumption result
from using measurement tools, the estimated consumption is bigger
(approximately one third bigger) than
the measured consumption. Still, it remains in the same order of
magnitude.

#+begin_src python :results value :exports none :session
[
('model', 'estimated pounds', 'estimated kg'),
None,
('Transformer_base',26,round(convert_pounds_kg(26),2)),
('Transformer_big',192,round(convert_pounds_kg(192),2)),
('BERT_base',1438,round(convert_pounds_kg(1438),2)),
('NAS',626155,round(convert_pounds_kg(626155),2)),
('ELMo',262,round(convert_pounds_kg(262),2))
]
#+end_src

#+RESULTS:
| model           | estimated pounds | estimated kg |
|-----------------+------------------+--------------|
| Transformer_base |               26 |        11.79 |
| Transformer_big  |              192 |        87.09 |
| BERT_base        |             1438 |       652.27 |
| NAS             |           626155 |     284018.9 |
| ELMo            |              262 |       118.84 |


*** approximating the GPU usage factor

Using the ratio of average measured power consumption to total TDP, we
can deduce an approximation of the GPU usage factor (assuming that the
vast majority of power draw comes from the GPUs)

| model           | estimated | measured |
|-----------------+-----------+----------|
| Transformer_base |      2000 |  1415.78 |
| Transformer_big  |      2000 |  1515.43 |
| ELMo            |       750 |   517.66 |
| BERT_base        |     16000 | 12041.51 |

#+begin_src python :results silent :session :exports none
usage_dict = {
'Transformer_base': 1415.78/2000, 'Transformer_big': 1515.43/2000,'ELMo': 517.66/750, 'BERT_base': 12041.51/16000
}
#+end_src

#+begin_src python :results value :exports results
return [('model', 'estimated GPU usage'),None,('Transformer_base', 1415.78/2000), ('Transformer_big', 1515.43/2000),('ELMo', 517.66/750),('BERT_base',12041.51/16000)]
#+end_src

#+RESULTS:
| model           | estimated GPU usage |
|-----------------+---------------------|
| Transformer_base |             0.70789 |
| Transformer_big  |            0.757715 |
| ELMo            |  0.6902133333333333 |
| BERT_base        |         0.752594375 |


*** estimates

#+begin_src python :post attr_wrap(caption="Comparison of the presented measures with our estimates", data=*this*) :results drawer :exports results :session
table = pd.read_csv('expected/training_strubell.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('model', '',''))

def set(model, col, val):
    table.loc[table[('model', '','')] == model, col] = val

base_model = {
"server": {
    "configuration":{
        "ram": [
            {
                "units" : 0
            }
        ]
    }
},
"gpu": [
    {
        "units": 1,
        "model": "NVIDIA GTX TITAN X"
    }
],
"psf": 1,
"nb_nodes": 1,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "hours_use_time": 0,
  "usage_location": "USA",
}
}

model_match = copy.deepcopy(base_model)

model_match["usage"] = {
  "dynamic_ratio": 1.58,
  "hours_use_time": 0,
  "usage_location": "USA",
  "gwp_factor": 432.72E-3
}


def estimate(model, task,  name, nb_gpus, time):
    print(name)
    model["gpu"][0]["units"] = nb_gpus
    model["usage"]["hours_use_time"] = time
    model['gpu_usage'] = usage_dict[name]
    output = run_experiment(model, task + '_' +  name, directory='Strubell2019energy')
    energy, gwp = print_gwp_and_energy(output)
    print(f"direct gwp: {convert_kg_pounds(gwp):.2f} lbs")
    set(name, ('estimated','energy ' + task, '(kWh)'), int(energy))
    set(name, ('estimated','CO2e ' + task, '(kg)'), int(gwp))
    set(name, ('estimated','CO2e ' + task, '(lbs)'), int(convert_kg_pounds(gwp)))    

def estimates(model, task):
    estimate(model, task, "Transformer_base", 8, 12)
    estimate(model, task, "Transformer_big", 8, 84)
    estimate(model, task, "BERT_base", 64, 79)
    #estimate(model, task, "NAS", 8, 274120)
    model["gpu"] = [{
        "units": 3,
        "model": "NVIDIA GeForce GTX 1080 Ti"
    }]
    estimate(model, task, "ELMo", 3, 336)

print("estimates match")
estimates(model_match, "match")
print("\n\nestimates base parameters")
estimates(base_model, "base")


to_org_table(multi_index_to_multiline_header(table))
#+end_src

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :float t :caption \caption{Comparison of the presented measures with our estimates} 
| model            |   expected |      estimated |     estimated |   expected |    estimated |   estimated |   expected |    estimated |      estimated |
|                  |     energy |   energy match |   energy base |       CO2e |   CO2e match |   CO2e base |       CO2e |   CO2e match |      CO2e base |
|                  |      (kWh) |          (kWh) |         (kWh) |       (kg) |         (kg) |        (kg) |      (lbs) |        (lbs) |          (lbs) |
|------------------+------------+----------------+---------------+------------+--------------+-------------+------------+--------------+----------------|
| Transformer_base |         27 |             27 |     31        |      11.79 |           11 |          11 |         26 |           25 |   25           |
| Transformer_big  |        201 |            203 |    235        |      87.09 |           87 |          87 |        192 |          193 |  192           |
| BERT_base        |       1507 |           1500 |   1750        |     652.17 |          651 |         646 |       1438 |         1435 | 1424           |
| NAS              |     656347 |         871000 |      1.71e+06 |  284018    |       377000 |      632000 |     626155 |       831143 |    1.39332e+06 |
| ELMo             |        275 |            281 |    326        |     118.84 |          122 |         121 |        262 |          268 |  266           |
:END:

Table \ref{tab:strubell_training} presents the results of our
estimates on two different scenarios. The first one (match) uses the
same \gls{PUE} and \gls{CI} as presented in the paper while the second
(base) uses the base values of our tool for the dynamic ratio and \gls{CI} of the USA. We can see that we obtain estimates that are, as expected, a little
bit higher than those presented.
We can explain the higher estimated energy when using the base values
for our tool because of the difference in Dynamic ratio. We use as
base value a dynamic ratio of 1.83 when the match scenario uses a
dynamic ratio of 1.58. We can also see that the estimated carbon
footprint is slightly higher in the match scenario than in the base
scenario ; this can be explained by the difference in \gls{CI}
used. Indeed, the \gls{CI} for the USA in the base values
is 370gCO_2 e/kWh instead of the 432gCO_2 e/kWh when trying to match.

** hyper-parameter search

To complement the case study on hyper-parameter search and costs not
only on training one model but of the whole process, let us try and
reproduce similar results, which we would be able to study also in
terms of the other impacts estimated by our tool.

#+begin_src python :post attr_wrap(caption="Comparison of the expected energy consumption and cost with our estimates", data=*this*) :results drawer :exports results :session
table = pd.read_csv('expected/cost_strubell.csv', sep=',', header=[0,1,2])

rename_multi_index(table, ('Models', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2'), ('Models', '', ''))
rename_multi_index(table, ('Hours', 'Unnamed: 1_level_1', 'Unnamed: 1_level_2'), ('Hours', '', ''))

def set(model, col, val):
    table.loc[table[('Models', '', '')] == model, col] = val

model = {
    "server": {
	"configuration":{
	    "ram": [
		{
		    "units" : 1,
		    "capacity": 1
		}
	    ]
	}
    },
    "gpu": [
	{
	    "units": 1,
	    "model": "NVIDIA GTX TITAN X"
	}
    ],
    "psf": 1,
    "nb_nodes": 1,
    "cpu_usage": 0,
    "gpu_usage": 1,
    "usage": {
      "hours_use_time": 0,
      "usage_location": "USA",
    }
}

def estimate(time, name):
    model["usage"]["hours_use_time"] = time
    output = run_experiment(model, name, "Strubell2019energy")
    energy = output["impacts"]["energy consumption"]["value"]
    cost = energy *.12
    print(f"Direct energy consumption: {energy} kWh, translates to a cost of {cost:2f} $")
    return cost, energy

def estimate_and_set(time, name):
    cost, energy = estimate(time, name)
    set(int(name), ('Estimated', 'energy', '(kWh)'), round(energy,0))
    set(int(name), ('Estimated', 'electricity', 'cost ($)'), round(cost,0))

estimate_and_set(120, '1')
estimate_and_set(2880, '24')
estimate_and_set(239942, '4789')

to_org_table(multi_index_to_multiline_header(table))
#+end_src

#+RESULTS:
:RESULTS:
#+ATTR_LATEX: :float t :caption \caption{Comparison of the expected energy consumption and cost with our estimates} 
|   Models |   Hours |   Expected |   Estimated |      Expected |     Estimated |
|          |         |     energy |      energy |   electricity |   electricity |
|          |         |      (kWh) |       (kWh) |      cost ($) |      cost ($) |
|----------+---------+------------+-------------+---------------+---------------|
|        1 |     120 |       41.7 |          55 |             5 |             7 |
|       24 |    2880 |      983   |        1320 |           118 |           158 |
|     4789 |  239942 |    82250   |      110000 |          9870 |         13200 |
:END:

Table \ref{tab:strubell_cost} compares the estimated energy consumption
and elecrity costs with the expected ones. We can see that we still obtain higher energy consumption  values thans
the ones presented. This fact can be mostly explained by the
difference between using a \gls{PUE} of 1.58 and a dynamic ratio of 1.83

** integrating Life cycle to previous analyses

If we now look at the full estimates produced by our tool and not only
on the direct impacts, 
#+begin_src python :results output :exports none :session
estimate(239942, "4789_jobs_with_ram")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 2900.0, 'direct': 40800.0, 'total': 44000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 39000.0, 'direct': 1250000.0, 'total': 1300000.0, 'unit': 'MJ'}, 'adp': {'embodied': 0.74, 'direct': 0.0109, 'total': 0.75, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 110000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 22.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 44.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 24.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 110000.0 kWh, translates to a cost of 13200.000000 $
: (13200.0, 110000.0)


We can see that the full impacts estimated for performing the whole
model search, hyper-parameter tuning and training represents the annual
impacts of 22 persons if we place ourselves in a scenario where we
would respect the "Stratégie Nationale Bas Carbone" for France
by 2050. If we place ourselves in the framework of the Planetary
boundaries, where if we want to stay sustainable, societies must not
overpass the planetary boundaries. The whole process accounts for the
maximal annual impacts of 44 persons in terms of Green House Gas
emissions and the annual impacts of 24 persons in terms of resource
depletion.

Of course, if computations were to be run in a country with a
less carbon intensive electricity mix, green warming potential would
be lower. Still, the impacts on resources depletion are very
important, and, in this estimation, we do not take into account any (1
GB) memory on the server that runs the experiments. 

If we were to add memory, for instance 512 GB of memory, we would
obtain the following estimation

#+begin_src python :results output :exports none :session
model["server"]["configuration"]["ram"][0]["capacity"] = 512
estimate(239942, "4789_jobs_with_ram")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 13000.0, 'direct': 71800.0, 'total': 84000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 160000.0, 'direct': 2200000.0, 'total': 2400000.0, 'unit': 'MJ'}, 'adp': {'embodied': 1.0, 'direct': 0.0191, 'total': 1.0, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 194000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 42.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 86.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 33.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 194000.0 kWh, translates to a cost of 23280.000000 $

with expected impacts as high as the maximal annual ones of 86 persons
in terms of \gls{GWP} and 33 persons in terms of Resources depletion
when not exceeding the planetary boundaries.

As a title of comparison, if we were to make the same estimates but
running in France, we would obtain the following (with a \gls{CI} of 98gCO_2 e/kWh)

#+begin_src python :results output :exports none :session
model["usage"]["usage_location"] = "FRA"
estimate(239942, "4789_jobs_with_ram_France")
#+end_src

#+RESULTS:
: estimated impacts: {'gwp': {'embodied': 13000.0, 'direct': 19000.0, 'total': 32000.0, 'unit': 'kgCO2eq'}, 'pe': {'embodied': 160000.0, 'direct': 2190000.0, 'total': 2300000.0, 'unit': 'MJ'}, 'adp': {'embodied': 1.0, 'direct': 0.00943, 'total': 1.0, 'unit': 'kgSbeq'}, 'energy consumption': {'value': 194000.0, 'unit': 'kWh'}}
: to put impacts in perspective: {'relative_SNBC': {'value': 16.0, 'unit': 'Emissions of X Person per year in the "Stratégie Nationale Bas Carbone (SNBC)" sustanability objectives for France'}, 'relative_PB_Climate_Change': {'value': 32.0, 'unit': 'person in a scenario where the Planetary Boundary for Climate Change is not exceded'}, 'relative_PB_ADP': {'value': 32.0, 'unit': 'person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded'}}
: Direct energy consumption: 194000.0 kWh, translates to a cost of 23280.000000 $

It would still represent the maximal annual emissions of 32 persons in
terms of \gls{GWP} or in terms of \gls{ADP}

This small change in \gls{ADP} impact can be explained by the fact that most of
the impacts on ressource depletion are due to manufacturing the
hardware used. This demonstrates the importance of both considering
embodied impacts and of considering other impacts than just the carbon footprint



** New exepriments with finer accounting of the servers used

As it is really complex to find data regarding the hardware used in
TPUs, the experiments done with google's TPU will not be included

for the ELMo and Transformer case, the papers do not detail the
hardware. Just the graphics cards used are indicated in Caswani et. al
for the transformer models. 

For the memory use and CPU used for these two models:
- According to [[https://docs.deeppavlov.ai/en/0.9.0/apiref/models/elmo.html][this blogpost]], 32GB memory are required to train ELmo
- According to [[https://www.trentonbricken.com/TransformerMemoryRequirements/][this blogpost]], 32GB memory should also work to train a
  Transformer with 65M parameters and 64GB memory should work to train
  a Transformer with 213M parameters
- for the CPU, a CPU used in servers from the same period will be
  used, specificaly, the CPU used in the Nvidia DGX-2H server, that
  was used to train BERT in the experiments described in the Strubell
  *et al.* paper: 2 Intel Xeon Platinum 8174

For the GPU usage factor, in order to not overestimate too much, a
value will be computed from the total consumption estimated by
Strubell and colleagues (supposing that the vast majority of
consumption comes from the GPU, the power consumption indicatged in
the paper are entirely attributed to the GPU).

For the remaining hardware, we will use the default values of MLCA.

*** experiments setup

define the setup that will be used to run Transformer and ELMo
experiments.   

#+begin_src python :results output :session :exports none
base_setup = {
"server": {
"configuration": {
      "cpu": {
        "units": 2,
        "model": "Xeon Platinum 8174"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 32
        }
      ]
    }
},
"gpu": [
    {
        "units": 1,
        "model": "NVIDIA Tesla P100 PCIe 16GB"
    }
],
"psf": 1,
"nb_nodes": 1,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "hours_use_time": 79.2,
  "usage_location": "USA",
}
}
#+end_src

#+RESULTS:

For Bert, it is stated in the paper that the estimates where run on
Nvidia 4 DGX-2H servers whose specifications are available at [[https://www.nvidia.com/content/dam/en-zz/es_em/Solutions/Data-Center/dgx-2/dgx-2h-datasheet-us-nvidia-841283-r6-web.pdf][this
website]], each server comprising 2 Intel Xeon Platinum 8174 CPU, 2*
960GB NVME SSDs, 1.5TB memory 

#+begin_src python :results output :session :exports none
with open("boaviztapi/data/devices/server/DGX-2H.json", 'r') as m:
    DGX_2H = json.load(m)

DGX_2H_setup = {
"server": DGX_2H,
"gpu": [
    {
        "units": 16,
        "model": "NVIDIA Tesla V100 SXM2 32 GB"
    }
],
"psf": 1,
"nb_nodes": 4,
"cpu_usage": 0,
"gpu_usage": 1,
"usage": {
  "hours_use_time": 79.2,
  "usage_location": "USA",
}
}
#+end_src

#+RESULTS:

create the different models for the different sensitivity analyses

#+begin_src python :results output :session :exports none
def get_min_alloc_setup(model):
    setup_min_alloc = copy.deepcopy(model)
    setup_min_alloc['average_usage'] = .95
    setup_min_alloc['hardware_replacement_rate'] = 8
    return setup_min_alloc

def get_max_alloc_setup(model):
    setup_max_alloc = copy.deepcopy(model)
    setup_max_alloc['average_usage'] = .1
    setup_max_alloc['hardware_replacement_rate'] = 1
    return setup_max_alloc

def get_facebook_alloc_setup(model):
    setup_max_alloc = copy.deepcopy(model)
    setup_max_alloc['average_usage'] = .5
    setup_max_alloc['hardware_replacement_rate'] = 3
    return setup_max_alloc


def get_different_density(model, density):
    setup_new_density = copy.deepcopy(model)
    setup_new_density['gpu'][0]['memory_density'] = density
    setup_new_density['server']['configuration']['ram'][0]['density'] = density
    return setup_new_density

def get_different_location(model,location):
    setup_new_location = copy.deepcopy(model)
    setup_new_location['usage']['usage_location'] = location
    return setup_new_location
#+end_src

#+RESULTS:

define functions to run the estimates

#+begin_src python :results output :session :exports none
def estimate(model, task,  name, gpu, nb_gpus, time):
    print(name)
    model["gpu"][0]["units"] = nb_gpus
    model["gpu"][0]['model'] = gpu
    model["usage"]["hours_use_time"] = time
    model['gpu_usage'] = usage_dict[name]
    model_min = get_min_alloc_setup(model)
    model_max = get_max_alloc_setup(model)
    model_facebook = get_facebook_alloc_setup(model)
    output_base = run_experiment(model, task + '_' +  name, directory='Strubell2019energy')
    output_min = run_experiment(model_min, task + '_min_alloc_' +  name, directory='Strubell2019energy')
    output_max = run_experiment(model_max, task + '_max_alloc' +  name, directory='Strubell2019energy')
    output_facebook = run_experiment(model_facebook, task + '_facebook_' +  name, directory='Strubell2019energy')
    gwp,adp,pe = get_results(output_base)
    gwp_facebook, adp_facebook, pe_facebook = get_results(output_facebook)
    gwp_min,adp_min,pe_min = get_results(output_min) 
    gwp_max,adp_max,pe_max = get_results(output_max)
   
    set(name, (task, 'GWP', 'base','(\COtwo{})'), gwp)
    set(name, (task, 'GWP', 'min','(\COtwo{})'), gwp_min)
    set(name, (task, 'GWP', 'facebook','(\COtwo{})'), gwp_facebook)
    set(name, (task, 'GWP', 'max','(\COtwo{})'), gwp_max)
    set(name, (task, 'ADP', 'base','(\Sbe{})'),adp) 
    set(name, (task, 'ADP', 'min','(\Sbe{})'),adp_min) 
    set(name, (task, 'ADP', 'facebook','(\Sbe{})'),adp_facebook) 
    set(name, (task, 'ADP','max' ,'(\Sbe{})'),adp_max) 
    set(name, (task, 'PE', 'base','(MJ)'), pe)   
    set(name, (task, 'PE', 'min','(MJ)'), pe_min)      
    set(name, (task, 'PE', 'facebook','(MJ)'), pe_facebook)  
    set(name, (task, 'PE', 'max','(MJ)'), pe_max)  

def estimates(model_base, model_BERT, task):
    estimate(model_base, task, "Transformer_base", 'NVIDIA Tesla P100 PCIe 16 GB', 8, 12)
    estimate(model_base, task, "Transformer_big", 'NVIDIA Tesla P100 PCIe 16 GB',  8, 84)
    estimate(model_base, task, "ELMo", 'NVIDIA GeForce GTX 1080 Ti', 3, 336)
    estimate(model_BERT, task, "BERT_base", 'NVIDIA Tesla V100 SXM2 32 GB', 16, 79)
#+end_src

#+RESULTS:


*** sensitivity

To test the sensitivity of the results on the different parameters,
changes to the density of memory, lifespan of servers and usage ratio
will be tested. For the lifespan and usage ratio, we will produce an
uncertainty interval, as we suppose that these parameters are easily
bounded.
We suppose that no servers have a mean lifespan of less than 1 year
and no more than 8 years, and suppose that the servers never have a
usage ratio of less than 10% and never have a higher ratio than 95%.

Results will therefore be compared when using the default value and
the values producting the highest (lowest lifespan and usage) and lowest
(highest lifespan and usage) impacts. A comparison taking the values
given in \cite{Wu2022sutainable} for the lifespan and usage of
facebook ML servers (3 years, used 50% of the time)

For the sensitivity to changes in the estimated memory density, we wil
test to scenarios, one when using the default value and another one
when using the density used in \cite{Groger2021green} 

Sensitivity to changes in location will be explored through two
different scenarios, one in France and one in the USA.

*** running the estimates

#+begin_src python : post attr_wrap(caption="Comparison of the presented measures with our estimates", data=*this*) :results drawer :session :exports results
table = pd.read_csv('expected/training_strubell_new.csv', sep=',', header=[0,1,2,3])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2', 'Unnamed: 0_level_3'), ('model', '','',''))

def set(model, col, val):
    table.loc[table[('model', '','','')] == model, col] = val


print("estimates base parameters")
estimates(base_setup,DGX_2H_setup, "base")
print("\n\nestimates changed density")
estimates(get_different_density(base_setup,1.875),get_different_density(DGX_2H_setup,1.875), "changedDensity")
print("\n\nestimates changed location")
estimates(get_different_location(base_setup,"FRA"),get_different_location(DGX_2H_setup,'FRA'), "changedLocation")

table.to_csv('results/training_strubell_results.csv', sep=',', header=True, index=False)
to_org_table(multi_index_to_multiline_header(table))
#+end_src

#+RESULTS:
:RESULTS:
| model           |       base |       base |       base |       base |     base |     base |     base |     base |  base |  base |     base |  base | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedDensity | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation | changedLocation |
|                 |        GWP |        GWP |        GWP |        GWP |      ADP |      ADP |      ADP |      ADP |    PE |    PE |       PE |    PE |            GWP |            GWP |            GWP |            GWP |            ADP |            ADP |            ADP |            ADP |             PE |             PE |             PE |             PE |             GWP |             GWP |             GWP |             GWP |             ADP |             ADP |             ADP |             ADP |              PE |              PE |              PE |              PE |
|                 |       base |        min |   facebook |        max |     base |      min | facebook |      max |  base |   min | facebook |   max |           base |            min |       facebook |            max |           base |            min |       facebook |            max |           base |            min |       facebook |            max |            base |             min |        facebook |             max |            base |             min |        facebook |             max |            base |             min |        facebook |             max |
|                 | (\COtwo{}) | (\COtwo{}) | (\COtwo{}) | (\COtwo{}) | (\Sbe{}) | (\Sbe{}) | (\Sbe{}) | (\Sbe{}) |  (MJ) |  (MJ) |     (MJ) |  (MJ) |     (\COtwo{}) |     (\COtwo{}) |     (\COtwo{}) |     (\COtwo{}) |       (\Sbe{}) |       (\Sbe{}) |       (\Sbe{}) |       (\Sbe{}) |           (MJ) |           (MJ) |           (MJ) |           (MJ) |      (\COtwo{}) |      (\COtwo{}) |      (\COtwo{}) |      (\COtwo{}) |        (\Sbe{}) |        (\Sbe{}) |        (\Sbe{}) |        (\Sbe{}) |            (MJ) |            (MJ) |            (MJ) |            (MJ) |
|-----------------+------------+------------+------------+------------+----------+----------+----------+----------+-------+-------+----------+-------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------|
| Transformer_base |         12 |         12 |         13 |         31 |  7.9e-05 |  5.4e-05 |  0.00026 |   0.0039 |   360 |   360 |      370 |   590 |             12 |             12 |             13 |             25 |        7.7e-05 |        5.2e-05 |        0.00025 |         0.0037 |            360 |            360 |            370 |            520 |             3.5 |             3.3 |             4.3 |              22 |         7.8e-05 |         5.3e-05 |         0.00026 |          0.0039 |             360 |             360 |             370 |             580 |
| Transformer_big  |         90 |         89 |         96 |        220 |  0.00056 |  0.00038 |   0.0018 |    0.027 |  2700 |  2700 |     2800 |  4300 |             89 |             88 |             94 |            180 |        0.00054 |        0.00037 |         0.0018 |          0.026 |           2700 |           2700 |           2800 |           3800 |              26 |              25 |              32 |             160 |         0.00055 |         0.00037 |          0.0018 |           0.027 |            2700 |            2700 |            2800 |            4300 |
| BERT_base        |        830 |        810 |        970 |       3900 |   0.0049 |   0.0034 |    0.016 |     0.24 | 24000 | 24000 |    26000 | 61000 |            800 |            790 |            860 |           2100 |         0.0039 |         0.0027 |          0.013 |           0.19 |          24000 |          24000 |          25000 |          40000 |             260 |             240 |             410 |            3300 |          0.0048 |          0.0032 |           0.016 |            0.24 |           24000 |           24000 |           26000 |           61000 |
| ELMo            |        130 |        120 |        140 |        440 |   0.0014 |  0.00094 |   0.0047 |    0.069 |  3800 |  3800 |     4000 |  7700 |            130 |            120 |            140 |            380 |         0.0014 |        0.00092 |         0.0045 |          0.068 |           3800 |           3800 |           3900 |           7000 |              38 |              36 |              53 |             350 |          0.0014 |         0.00093 |          0.0046 |           0.069 |            3800 |            3700 |            4000 |            7700 |
:END:

create a separate file for each indicator and each scenario
#+begin_src python :results output :session :exports both
table = pd.read_csv('results/training_strubell_results.csv', sep=',', header=[0,1,2,3])

rename_multi_index(table, ('model', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2', 'Unnamed: 0_level_3'), ('model', '','',''))

table.set_index(('model','','',''),inplace=True)


for scenario in ['base','changedDensity','changedLocation']:
    for metric in ['GWP','ADP','PE']:
        new_table = copy.deepcopy(table[(scenario,metric)])
        new_table.columns = [a for (a,b) in new_table.columns.values]
        new_table.index.name = 'model'
        new_table.rename(index = (lambda x : re.sub('(.+)_(.+)', '\g<1>\\\\textsubscript{\g<2>}', x)), inplace=True)
        # change columns to obtain relative change because this is how error bars are computed in pgfplots
        new_table['min'] = new_table['base'] - new_table['min']
        new_table['max'] = new_table['max'] - new_table['base']
        # re-order rows to have the legend in the future figure not overlap the datapoints
        new_table.sort_index(inplace=True)
        # print(new_table)
        new_table.to_csv('results/Strubell2019energy/' + scenario + metric + '.csv')
#+end_src

#+RESULTS:
#+begin_example
base   min  facebook     max
model                                                         
BERT\textsubscript{base}         830.0  20.0     970.0  3070.0
ELMo                             130.0  10.0     140.0   310.0
Transformer\textsubscript{base}   12.0   0.0      13.0    19.0
Transformer\textsubscript{big}    90.0   1.0      96.0   130.0
                                     base       min  facebook       max
model                                                                  
BERT\textsubscript{base}         0.004900  0.001500   0.01600  0.235100
ELMo                             0.001400  0.000460   0.00470  0.067600
Transformer\textsubscript{base}  0.000079  0.000025   0.00026  0.003821
Transformer\textsubscript{big}   0.000560  0.000180   0.00180  0.026440
                                    base  min  facebook      max
model                                                           
BERT\textsubscript{base}         24000.0  0.0   26000.0  37000.0
ELMo                              3800.0  0.0    4000.0   3900.0
Transformer\textsubscript{base}    360.0  0.0     370.0    230.0
Transformer\textsubscript{big}    2700.0  0.0    2800.0   1600.0
                                  base   min  facebook     max
model                                                         
BERT\textsubscript{base}         800.0  10.0     860.0  1300.0
ELMo                             130.0  10.0     140.0   250.0
Transformer\textsubscript{base}   12.0   0.0      13.0    13.0
Transformer\textsubscript{big}    89.0   1.0      94.0    91.0
                                     base       min  facebook       max
model                                                                  
BERT\textsubscript{base}         0.003900  0.001200   0.01300  0.186100
ELMo                             0.001400  0.000480   0.00450  0.066600
Transformer\textsubscript{base}  0.000077  0.000025   0.00025  0.003623
Transformer\textsubscript{big}   0.000540  0.000170   0.00180  0.025460
                                    base  min  facebook      max
model                                                           
BERT\textsubscript{base}         24000.0  0.0   25000.0  16000.0
ELMo                              3800.0  0.0    3900.0   3200.0
Transformer\textsubscript{base}    360.0  0.0     370.0    160.0
Transformer\textsubscript{big}    2700.0  0.0    2800.0   1100.0
                                  base   min  facebook     max
model                                                         
BERT\textsubscript{base}         260.0  20.0     410.0  3040.0
ELMo                              38.0   2.0      53.0   312.0
Transformer\textsubscript{base}    3.5   0.2       4.3    18.5
Transformer\textsubscript{big}    26.0   1.0      32.0   134.0
                                     base       min  facebook       max
model                                                                  
BERT\textsubscript{base}         0.004800  0.001600   0.01600  0.235200
ELMo                             0.001400  0.000470   0.00460  0.067600
Transformer\textsubscript{base}  0.000078  0.000025   0.00026  0.003822
Transformer\textsubscript{big}   0.000550  0.000180   0.00180  0.026450
                                    base    min  facebook      max
model                                                             
BERT\textsubscript{base}         24000.0    0.0   26000.0  37000.0
ELMo                              3800.0  100.0    4000.0   3900.0
Transformer\textsubscript{base}    360.0    0.0     370.0    220.0
Transformer\textsubscript{big}    2700.0    0.0    2800.0   1600.0
#+end_example

* comparing manufacture impacts with Dell LCAs 
#+LaTeX:  \label{sec:manufacture_comparison}
In order to validate the embodied impact estimations our tool
produces, we compare the results our tool produces with the \gls{LCA}
results presented by Thinkstep for DELL on the R740
\cite{thinkstep2019lca} and By Sphera for Dell on the R6515, R7515, R7525
servers \cite{sphera2021lca}.

** Dell R740 
#+LaTeX:  \label{sec:R740}

This first \gls{LCA} of a server was already used by Boavizta to
validate their tool. Since our tool does not greatly differ from
Boavizta's one on the manufacture impacts estimate for servers with no
GPU, we expect to obtain close results to them.
   #+begin_src python :results output :exports none :session
with open("boaviztapi/data/devices/server/dellR740.json", 'r') as m:
    R740 = json.load(m)

#print(R740)
out = run_experiment_server(R740, "R740", directory='../results')
print_impacts_server(out)


def print_results_components(results):
    impact_dict = {}
    impact_dict['TOTAL'] = results['impacts']["gwp"]['manufacture']
    impact_dict["MAINBOARD (excl. CPU)"] =  get_result_component(results,"MOTHERBOARD")
    impact_dict['CPU'] = get_result_component(results,"CPU")
    for c in ['RAM', 'SSD']:
        r = get_result_component(results,c)
        impact_dict[c] = r
        print(f'{c} gwp: {r} kgCO2eq')
    total = 0
    for c in ['CASE', 'ASSEMBLY', 'POWER_SUPPLY']:
        total += get_result_component(results,c)
    impact_dict['OTHER'] = total
    print(f'Other component GWP impacts: {total:.0f} kgCO2eq')
    return impact_dict

def get_impact_dict(results):
    impact_dict = print_results_components(results)
    impact_dict["SSD_3.84TB"] = results['verbose']['SSD-2']["impacts"]['gwp']['value']
    return impact_dict


impact_dict = get_impact_dict(out)


   #+end_src

   #+RESULTS:
   : GWP: {'manufacture': 2400.0, 'use': 1170.0, 'unit': 'kgCO2eq'}
   : PE: {'manufacture': 31000.0, 'use': 39700.0, 'unit': 'MJ'}
   : ADP: {'manufacture': 0.19, 'use': 0.000198, 'unit': 'kgSbeq'}
   : RAM gwp: 540.0 kgCO2eq
   : SSD gwp: 24.0 kgCO2eq
   : Other component GWP impacts: 302 kgCO2eq

   #+begin_src python :results pp :exports none :session
impact_dict
   #+end_src

   #+RESULTS:
   : {'CPU': 45.6,
   :  'MAINBOARD (excl. CPU)': 66.1,
   :  'OTHER': 302.0,
   :  'RAM': 540.0,
   :  'SSD': 24.0,
   :  'SSD_3.84TB': 1440.0,
   :  'TOTAL': 2400.0}

  #+begin_src python :results pp :exports none :session
impact_dict_DELL = {
    'CPU': .266*175.3,
    'MAINBOARD (excl. CPU)': 175.3,
    'OTHER': 34.1 +  31.3 + 11.1 + 1.9,
    'RAM': 591.8,
    'SSD': 64.1,
    'SSD_3.84TB': 3373.5,
    'TOTAL': 4283.1
}
impact_dict_DELL
  #+end_src

  #+RESULTS:
  : {'CPU': 46.6298,
  :  'MAINBOARD (excl. CPU)': 175.3,
  :  'OTHER': 78.4,
  :  'RAM': 591.8,
  :  'SSD': 64.1,
  :  'SSD_3.84TB': 3373.5,
  :  'TOTAL': 4283.1}


  #+begin_src python :results output :exports none :session
def get_result_component_b(results, component):
    units = results['verbose'][component + '-1']["units"]
    value = results['verbose'][component + '-1']["manufacture_impacts"]['gwp']['value']
    return units * value

def print_results_components_b(results):
    impact_dict = {}
    impact_dict['TOTAL'] = results['impacts']["gwp"]['manufacture']
    impact_dict["MAINBOARD (excl. CPU)"] =  get_result_component_b(results,"MOTHERBOARD")
    impact_dict['CPU'] = get_result_component_b(results,"CPU")
    for c in ['RAM', 'SSD']:
        r = get_result_component_b(results,c)
        impact_dict[c] = r
        print(f'{c} gwp: {r} kgCO2eq')
    total = 0
    for c in ['POWER_SUPPLY', 'CASE', 'ASSEMBLY']:
        total += get_result_component_b(results,c)
    impact_dict['OTHER'] = total
    print(f'Other component GWP impacts: {total:.0f} kgCO2eq')
    return impact_dict

def get_impact_dict_b(results):
    impact_dict = print_results_components_b(results)
    impact_dict["SSD_3.84TB"] = results['verbose']['SSD-2']["manufacture_impacts"]['gwp']['value'] * results['verbose']['SSD-2']["units"]
    return impact_dict

model = {
  "model": {
    "name": "R740",
    "type": "rack"
  },
  "configuration": {
 "ram":
    [
      {
        "units": 12,
        "capacity": 32,
        "density": 1.79
      }
    ],
    "disk":
    [
      {
        "units": 1,
        "type": "ssd",
        "capacity": 400,
        "density": 50.6
      },
	{
	    "units": 8,
	    "type": "ssd",
	    "capacity": 3840
	}
    ]
  }
}

with open("tmp.json", "w") as tmp:
    json.dump(model, tmp)
path = "results/" + datetime.now().strftime("%d-%m-%y_%H-%M") + "_DellR740_boavizta.json"
with open(path, "w") as out:
    request = "curl -X 'POST' 'https://api.boavizta.org/v1/server/?verbose=true&allocation=TOTAL' -H 'accept: application/json' -H 'Content-Type: application/json' -d @tmp.json"
    results = subprocess.run(request, shell=True, check=True, capture_output=True, text=True)
    output = json.JSONDecoder().decode(results.stdout)
    print(output)
    subprocess.run("rm tmp.json", shell=True)
    json.dump(output, out, indent=4, ensure_ascii=True)

impact_dict_boavizta = get_impact_dict_b(output)
  #+end_src

  #+RESULTS:
  #+begin_example
  {'impacts': {'gwp': {'embedded': {'value': 2200.0, 'min': 1395.0, 'max': 5523.0, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 8000.0, 'min': 281.7, 'max': 53160.0}, 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.19, 'min': 0.1071, 'max': 0.3459, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 0.001, 'min': 0.0001622, 'max': 0.01248}, 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 29000.0, 'min': 17840.0, 'max': 69950.0, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 300000.0, 'min': 159.2, 'max': 21990000.0, 'warnings': ['Uncertainty from technical characteristics is very important. Results should be interpreted with caution (see min and max values)']}, 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'verbose': {'duration': {'value': 35040.0, 'unit': 'hours'}, 'ASSEMBLY-1': {'impacts': {'gwp': {'embedded': {'value': 6.68, 'min': 6.68, 'max': 6.68, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 1.41e-06, 'min': 1.41e-06, 'max': 1.41e-06, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 68.6, 'min': 68.6, 'max': 68.6, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 1, 'status': 'ARCHETYPE', 'min': 1, 'max': 1}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'CPU-1': {'impacts': {'gwp': {'embedded': {'value': 40.0, 'min': 10.92, 'max': 327.3, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 5000.0, 'min': 146.9, 'max': 28900.0}, 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.041, 'min': 0.0204, 'max': 0.08169, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 0.0008, 'min': 8.454e-05, 'max': 0.006783}, 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 600.0, 'min': 179.9, 'max': 4534.0, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 200000.0, 'min': 83.01, 'max': 11960000.0, 'warnings': ['Uncertainty from technical characteristics is very important. Results should be interpreted with caution (see min and max values)']}, 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 2.0, 'status': 'ARCHETYPE', 'min': 1.0, 'max': 4.0}, 'die_size': {'value': 521.0, 'status': 'COMPLETED', 'unit': 'mm2', 'source': 'Average value for all families', 'min': 41.2, 'max': 3640.0}, 'duration': {'value': 35040.0, 'unit': 'hours'}, 'avg_power': {'value': 182.23023303189055, 'status': 'COMPLETED', 'unit': 'W', 'min': 182.23023303189055, 'max': 182.23023303189055, 'warnings': ['value for one cpu unit']}, 'time_workload': {'value': 50.0, 'status': 'ARCHETYPE', 'unit': '%', 'min': 0.0, 'max': 100.0}, 'usage_location': {'value': 'EEE', 'status': 'DEFAULT', 'unit': 'CodSP3 - NCS Country Codes - NATO'}, 'use_time_ratio': {'value': 1.0, 'status': 'ARCHETYPE', 'unit': '/1', 'min': 1.0, 'max': 1.0}, 'hours_life_time': {'value': 35040.0, 'status': 'COMPLETED', 'unit': 'hours', 'source': 'from device', 'min': 35040.0, 'max': 35040.0}, 'params': {'value': {'a': 171.2, 'b': 0.0354, 'c': 36.89, 'd': -10.13}, 'status': 'ARCHETYPE'}, 'gwp_factor': {'value': 0.38, 'status': 'DEFAULT', 'unit': 'kg CO2eq/kWh', 'source': 'https://www.sciencedirect.com/science/article/pii/S0306261921012149', 'min': 0.023, 'max': 1.13161}, 'adp_factor': {'value': 6.42317e-08, 'status': 'DEFAULT', 'unit': 'kg Sbeq/kWh', 'source': 'ADEME Base IMPACTS ®', 'min': 1.324e-08, 'max': 2.65575e-07}, 'pe_factor': {'value': 12.873, 'status': 'DEFAULT', 'unit': 'MJ/kWh', 'source': 'ADPf / (1-%renewable_energy)', 'min': 0.013, 'max': 468.15}}, 'RAM-1': {'impacts': {'gwp': {'embedded': {'value': 534.6, 'min': 534.6, 'max': 534.6, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 1500.0, 'min': 87.89, 'max': 4324.0}, 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.0338, 'min': 0.0338, 'max': 0.0338, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 0.00025, 'min': 5.059e-05, 'max': 0.001015}, 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 6745.0, 'min': 6745.0, 'max': 6745.0, 'warnings': ['End of life is not included in the calculation']}, 'use': {'value': 50000.0, 'min': 49.68, 'max': 1789000.0, 'warnings': ['Uncertainty from technical characteristics is very important. Results should be interpreted with caution (see min and max values)']}, 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 12, 'status': 'INPUT'}, 'capacity': {'value': 32, 'status': 'INPUT', 'unit': 'GB'}, 'density': {'value': 1.79, 'status': 'INPUT', 'unit': 'GB/cm2'}, 'duration': {'value': 35040.0, 'unit': 'hours'}, 'avg_power': {'value': 9.088, 'status': 'COMPLETED', 'unit': 'W', 'min': 9.088, 'max': 9.088}, 'time_workload': {'value': 50.0, 'status': 'ARCHETYPE', 'unit': '%', 'min': 0.0, 'max': 100.0}, 'usage_location': {'value': 'EEE', 'status': 'DEFAULT', 'unit': 'CodSP3 - NCS Country Codes - NATO'}, 'use_time_ratio': {'value': 1.0, 'status': 'ARCHETYPE', 'unit': '/1', 'min': 1.0, 'max': 1.0}, 'hours_life_time': {'value': 35040.0, 'status': 'COMPLETED', 'unit': 'hours', 'source': 'from device', 'min': 35040.0, 'max': 35040.0}, 'params': {'value': {'a': 9.088}, 'status': 'COMPLETED', 'source': '(ram_electrical_factor_per_go : 0.284) * (ram_capacity: 32) '}, 'gwp_factor': {'value': 0.38, 'status': 'DEFAULT', 'unit': 'kg CO2eq/kWh', 'source': 'https://www.sciencedirect.com/science/article/pii/S0306261921012149', 'min': 0.023, 'max': 1.13161}, 'adp_factor': {'value': 6.42317e-08, 'status': 'DEFAULT', 'unit': 'kg Sbeq/kWh', 'source': 'ADEME Base IMPACTS ®', 'min': 1.324e-08, 'max': 2.65575e-07}, 'pe_factor': {'value': 12.873, 'status': 'DEFAULT', 'unit': 'MJ/kWh', 'source': 'ADPf / (1-%renewable_energy)', 'min': 0.013, 'max': 468.15}}, 'SSD-1': {'impacts': {'gwp': {'embedded': {'value': 23.73, 'min': 23.73, 'max': 23.73, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.001061, 'min': 0.001061, 'max': 0.001061, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 292.7, 'min': 292.7, 'max': 292.7, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 1, 'status': 'INPUT'}, 'capacity': {'value': 400, 'status': 'INPUT', 'unit': 'GB'}, 'density': {'value': 50.6, 'status': 'INPUT', 'unit': 'GB/cm2'}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'SSD-2': {'impacts': {'gwp': {'embedded': {'value': 1300.0, 'min': 578.7, 'max': 4172.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.04, 'min': 0.01962, 'max': 0.1225, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 16000.0, 'min': 7167.0, 'max': 51750.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 8, 'status': 'INPUT'}, 'capacity': {'value': 3840, 'status': 'INPUT', 'unit': 'GB'}, 'density': {'value': 54.8842105263158, 'status': 'COMPLETED', 'unit': 'GB/cm2', 'source': 'Average of 19 rows', 'min': 16.4, 'max': 128.0}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'POWER_SUPPLY-1': {'impacts': {'gwp': {'embedded': {'value': 150.0, 'min': 24.3, 'max': 243.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.05, 'min': 0.0083, 'max': 0.083, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 2100.0, 'min': 352.0, 'max': 3520.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 2.0, 'status': 'ARCHETYPE', 'min': 1.0, 'max': 2.0}, 'unit_weight': {'value': 2.99, 'status': 'ARCHETYPE', 'unit': 'kg', 'min': 1.0, 'max': 5.0}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'CASE-1': {'impacts': {'gwp': {'embedded': {'value': 150.0, 'min': 150.0, 'max': 150.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.0202, 'min': 0.0202, 'max': 0.0202, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 2200.0, 'min': 2200.0, 'max': 2200.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 1, 'status': 'ARCHETYPE', 'min': 1, 'max': 1}, 'case_type': {'value': 'rack', 'status': 'INPUT'}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'MOTHERBOARD-1': {'impacts': {'gwp': {'embedded': {'value': 66.1, 'min': 66.1, 'max': 66.1, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgCO2eq', 'description': 'Total climate change'}, 'adp': {'embedded': {'value': 0.00369, 'min': 0.00369, 'max': 0.00369, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'kgSbeq', 'description': 'Use of minerals and fossil ressources'}, 'pe': {'embedded': {'value': 836.0, 'min': 836.0, 'max': 836.0, 'warnings': ['End of life is not included in the calculation']}, 'use': 'not implemented', 'unit': 'MJ', 'description': 'Consumption of primary energy'}}, 'units': {'value': 1, 'status': 'ARCHETYPE', 'min': 1, 'max': 1}, 'duration': {'value': 35040.0, 'unit': 'hours'}}, 'avg_power': {'value': 629.7762799999999, 'status': 'COMPLETED', 'unit': 'W', 'min': 349.5431999999999, 'max': 1340.7615999999998}, 'usage_location': {'value': 'EEE', 'status': 'DEFAULT', 'unit': 'CodSP3 - NCS Country Codes - NATO'}, 'use_time_ratio': {'value': 1.0, 'status': 'ARCHETYPE', 'unit': '/1', 'min': 1.0, 'max': 1.0}, 'hours_life_time': {'value': 35040.0, 'status': 'ARCHETYPE', 'unit': 'hours', 'min': 35040.0, 'max': 35040.0}, 'other_consumption_ratio': {'value': 0.33, 'status': 'ARCHETYPE', 'unit': 'ratio /1', 'min': 0.2, 'max': 0.6}, 'gwp_factor': {'value': 0.38, 'status': 'DEFAULT', 'unit': 'kg CO2eq/kWh', 'source': 'https://www.sciencedirect.com/science/article/pii/S0306261921012149', 'min': 0.023, 'max': 1.13161}, 'adp_factor': {'value': 6.42317e-08, 'status': 'DEFAULT', 'unit': 'kg Sbeq/kWh', 'source': 'ADEME Base IMPACTS ®', 'min': 1.324e-08, 'max': 2.65575e-07}, 'pe_factor': {'value': 12.873, 'status': 'DEFAULT', 'unit': 'MJ/kWh', 'source': 'ADPf / (1-%renewable_energy)', 'min': 0.013, 'max': 468.15}, 'units': {'value': 1, 'status': 'ARCHETYPE', 'min': 1, 'max': 1}}}
  Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
    File "/tmp/babel-dpt1i7/python-K3Ydvn", line 69, in <module>
      impact_dict_boavizta = get_impact_dict_b(output)
    File "/tmp/babel-dpt1i7/python-K3Ydvn", line 23, in get_impact_dict_b
      impact_dict = print_results_components_b(results)
    File "/tmp/babel-dpt1i7/python-K3Ydvn", line 8, in print_results_components_b
      impact_dict['TOTAL'] = results['impacts']["gwp"]['manufacture']
  KeyError: 'manufacture'
  #+end_example

#+NAME:data-for-R-DellR740
#+begin_src python :results silent :exports none :session
[('process', 'component', 'GWP'), None] + [('Boavizta', k, v) for k,v in impact_dict_boavizta.items()] + [('MLCA', k, v) for k,v in impact_dict.items()]  +  [('Dell LCA', k, v) for k,v in impact_dict_DELL.items()]
#+end_src

#+begin_src R :results output graphics file :file figures/R470.png :width 600 :height 400 :exports none :session *R* :var data=data-for-R-DellR740
get_bar_plot(data, 'DELL R470')
#+end_src

#+RESULTS:
[[file:figures/R470.png]]


#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
  \includegraphics[width=.95\linewidth,page=1]{./figures/R470.png}                                                                                                                               
  \label{fig:R740}
  \caption{Component-wise comparison of the GWP of manufacture of the Dell R470 server}
\end{figure}
#+END_EXPORT


Figure \ref{fig:R740} compares the \gls{GWP} value obtained for the
different components by the boavizta tool, our tool (MLCA) and the
Dell \gls{LCA} result. As we can see, the boavizta tool and MLCA
obtain very close results. This is expected since MLCA is based on
Boavizta with some changes in the way CPU impacts are computed and
some bugfixes. We can see however that MLCA obtains a way lower
estimate than the expected results (Dell \gls{LCA}) but it seems to be
mainly explained by the difference in the estimate for the 3.84TB
SSDs. We can see that MLCA provides significantly lower estimates than
the expected result for these components. If we look at the server
without these big disks in figure \ref{fig:R740_no_SSD}, we can see that we obtain pretty close
estimates for the CPU, RAM and Total impacts with a lower estimate of
the impacts of the motherboard and an overestimate for the other
components that compensate a little.

#+NAME:data-for-R-DellR740-no-SSD
#+begin_src python :results silent :exports none :session
def rm_SSD(impact_dict):
    impact_dict['TOTAL'] -= impact_dict['SSD_3.84TB']
    del impact_dict['SSD_3.84TB']

rm_SSD(impact_dict)
rm_SSD(impact_dict_DELL)
rm_SSD(impact_dict_boavizta)
[('process', 'component', 'GWP'), None] + [('Boavizta', k, v) for k,v in impact_dict_boavizta.items()] +  [('MLCA', k, v) for k,v in impact_dict.items()] +  [('Dell LCA', k, v) for k,v in impact_dict_DELL.items()]
#+end_src

#+begin_src R :results output graphics file :file figures/R470_no_SSD.png :width 600 :height 400 :exports none :session *R* :var data=data-for-R-DellR740-no-SSD
get_bar_plot(data, 'DELL R470')
#+end_src

#+RESULTS:
[[file:figures/R470_no_SSD.png]]

#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
  \includegraphics[width=.95\linewidth,page=1]{./figures/R470_no_SSD.png}                                                                                                                               
  \label{fig:R740}
  \caption{Component-wise comparison of the GWP of manufacture of the Dell R470 server not considering the 3.84TB SSDs}
\end{figure}
#+END_EXPORT

# | Component | ACV DELL - GWP (kgCO2eq) | MLCA - GWP (kgCO2eq) | Boavizta - GWP (kgCO2eq) |
# | CPU       |                       47 |                 45.6 |                       43 |
# | RAM       |                      533 |                  540 |                      534 |
# | SSD       |                       64 |                   24 |                       24 |
# | OTHER     |                      266 |                  368 |                      369 |
# | TOTAL     |                      910 |                  970 |                      970 |


** Dell R6515, R7515, R6525, R7525

In this section we compare the results our tool produces with
\gls{LCA} results produced by Sphera for Dell on the R6515, R7515, R7525
servers \cite{sphera2021lca}. Since there are few configuration differences
between the R6515 and R7515 and between the R6525 and R7525, we will
only focus on the R6515 and R6525.

#+begin_src python :results output :exports none
total_energy = (213.92 + 595.11 + 347.16 + 207.39)*4
CI_europe = (3450 - 1343) / total_energy
CI_US = (4280 - 1343) / total_energy 
print(total_energy, CI_europe, CI_US)

print(0.15216000000000002 * 4 *365 * 24)
#+end_src

#+RESULTS:
: 5454.32 0.386299300371082 0.5384722568532833
: 5331.6864000000005

#+begin_src python :results output :exports none :session

with open("boaviztapi/data/devices/server/R6515.json", 'r') as m:
    R6515 = json.load(m)

R6515["usage"]["workload"] = {
      "100": {
        "time": 2.4/24,
        "power": 1.0
      },
      "50": {
        "time": 8.4/24,
        "power": 184.1/244.2 
      },
      "10": {
        "time": 7.2/24,
        "power":  132.1/244.2
      },
      "idle": {
        "time": 6/24,
        "power": 94.7/244.2
      }
    }


print("Europe Scenario")
R6515["usage"]["usage_location"] = "EEE"
R6515["usage"]["gwp_factor"] =  0.386299300371082
out = run_experiment_server(R6515, "R6515_Europe", directory='../results')
print_impacts_server(out)
impact_dict_R6515 = print_results_components(out)

print("US Scenario")
R6515["usage"]["usage_location"] = "USA"
R6515["usage"]["gwp_factor"] = 0.5384722568532833
out = run_experiment_server(R6515, "R6515_USA", directory='../results')
print_impacts_server(out)


R6525 = R6515
R6525["configuration"]['cpu']['units'] = 2
R6525["configuration"]['ram'][0]['units'] = 16

print("R6525 US Scenario")
out = run_experiment_server(R6525, "R6525_USA", directory='../results')
print_impacts_server(out)

impact_dict_R6525 = print_results_components(out)
#+end_src 

#+RESULTS:
#+begin_example
Europe Scenario
GWP: {'manufacture': 950.0, 'use': 2060.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 12000.0, 'use': 68600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.12, 'use': 0.000342, 'unit': 'kgSbeq'}
RAM gwp: 192.0 kgCO2eq
SSD gwp: 380.0 kgCO2eq
Other component GWP impacts: 302 kgCO2eq
US Scenario
GWP: {'manufacture': 950.0, 'use': 2870.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 12000.0, 'use': 60600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.12, 'use': 0.000526, 'unit': 'kgSbeq'}
R6525 US Scenario
GWP: {'manufacture': 1100.0, 'use': 2870.0, 'unit': 'kgCO2eq'}
PE: {'manufacture': 15000.0, 'use': 60600.0, 'unit': 'MJ'}
ADP: {'manufacture': 0.16, 'use': 0.000526, 'unit': 'kgSbeq'}
RAM gwp: 384.0 kgCO2eq
SSD gwp: 380.0 kgCO2eq
Other component GWP impacts: 302 kgCO2eq
#+end_example

First, we compare the total manufacture impact estimated by our tool
with the expected results : 

For the manufacture of the R6515, we obtain an estimate of 1200 kgCO_2
e when the expected results stand at 1343 kgCO_2 e.
For the R6525, we obtain an estimate of 1600 kgCO_2 e when the expected
result stands at 1709 kgCO_2 e.

We can see that we obtain close results. If we now take a deeper look
at the repartition of impacts by components, Figure
\ref{fig:R6515_R6525} compares our tool (MLCA) with the expected
results from the Dell \gls{LCA}. As in section \ref{sec:R740}, we can
see that our tool underestimates the SSD impacts and produces a close
estimate of the total manufacture \gls{GWP} impact. We also see that
for the mainboard, we get a lower estimate that counterbalances the
overestimate for the other components. This time, the estimates for
the RAM and CPU impacts are farther from the expected result than in
the comparison for the Dell R470. Still, the overall results tend to
confirm the adequacy of the results our tool produces with expected
results about the manufacture impacts of a server.

#+begin_src python :results silent :exports none :session
impact_dict_DELL_R6515 = {
'CPU': .28*145.2,
"MAINBOARD (excl. CPU)":(1-.28) * 145.2,
'RAM':263.7,
'SSD':854.7,
'OTHER': 33.6 + 11.2 + 9.3 + 7.9 + 6.7 + 11.9 + 30.9 ,
'TOTAL': 1375.2
}

impact_dict_DELL_R6525 = {
'CPU': .29*277.4,
"MAINBOARD (excl. CPU)":(1-.29) * 277.4,
'RAM':527.4,
'SSD':854.7,
'OTHER': 36 + 11.2 + 4.8 + 9.8 + 6.1 + 11.9 + 30.9 ,
'TOTAL': 1770.3
}
#+end_src



#+NAME:data-for-R-DellR6515
#+begin_src python :results value :exports none :session
[('process', 'component', 'GWP'), None] + [('MLCA', k, v) for k,v in impact_dict_R6515.items()] +  [('DELL', k, v) for k,v in impact_dict_DELL_R6515.items()]
#+end_src

#+RESULTS: data-for-R-DellR6515
| process | component             |                GWP |
|---------+-----------------------+--------------------|
| MLCA    | TOTAL                 |              950.0 |
| MLCA    | MAINBOARD (excl. CPU) |               66.1 |
| MLCA    | CPU                   |               11.0 |
| MLCA    | RAM                   |              192.0 |
| MLCA    | SSD                   |              380.0 |
| MLCA    | OTHER                 |              302.0 |
| DELL    | CPU                   |             40.656 |
| DELL    | MAINBOARD (excl. CPU) | 104.54399999999998 |
| DELL    | RAM                   |              263.7 |
| DELL    | SSD                   |              854.7 |
| DELL    | OTHER                 |              111.5 |
| DELL    | TOTAL                 |             1375.2 |


#+begin_src R :results output graphics file :file figures/Dell_R6515.png :exports none :width 800 :height 500 :session *R* :var data=data-for-R-DellR6515
data %>% get_bar_plot('DELL R6515')
#+end_src

#+RESULTS:
[[file:figures/Dell_R6515.png]]

#+NAME:data-for-R-DellR6525
#+begin_src python :results silent :exports none :session
[('process', 'component', 'GWP'), None] + [('MLCA', k, v) for k,v in impact_dict_R6525.items()] +  [('DELL', k, v) for k,v in impact_dict_DELL_R6525.items()]
#+end_src


#+begin_src R :results output graphics file :file figures/Dell_R6525.png :exports none :width 800 :height 500 :session *R* :var data=data-for-R-DellR6525
get_bar_plot(data, 'DELL R6525')
#+end_src

#+RESULTS:
[[file:figures/Dell_R6525.png]]


#+BEGIN_EXPORT latex
\begin{figure}[t]
  \centering
  \begin{minipage}{.47\linewidth}
  \includegraphics[width=.95\linewidth,page=1]{./figures/Dell_R6515.png} 
  \end{minipage}
  \hspace{.06\linewidth}
  \begin{minipage}{.47\linewidth}
  \includegraphics[width=.95\linewidth,page=1]{./figures/Dell_R6525.png} 
  \end{minipage}                                                                                                                              
  \label{fig:R6515_R6525}
  \caption{Component-wise comparison of the GWP of manufacture for the Dell R6515 and R6525 servers}
\end{figure}
#+END_EXPORT


The comparison of our tool with the Dell \gls{LCA} results confirms
that overall, our tool produces adequate results component by
component even if it tends to
underestimate the impacts of storage. 

* replicating the Bloom estimates from \cite{Luccioni2022estimating}
#+LaTeX:  \label{sec:bloom}
Now that we have tested our tool on the results it produces about the
energy consumption then on the manufacture impacts, let us test our
tool on all of this at the same time on the case of the Bloom carbon
footprint study.
** Gathering information about the setup
To replicate their experiments, we first need to gather some
information on the time duration and hardware setup for the training
phase.

We can see in the paper that the training phase lasted for 118 days, 5
hours and 41 minutes for a total of 1,082,990 GPU hours. (table 1 of
the paper)

in section 4.1, we can read that training used on average 48 computing
nodes with 8 GPUs each.


#+begin_src python :results value :exports none
real_time_hours = 118*24 + 5 + 41/60
estimated_gpu_hours = real_time_hours * 48 * 8
return estimated_gpu_hours
#+end_src

#+RESULTS:
: 1089670.4

Combining the real time and these information about the setup, we obtain an estimate of the number of GPU hours of 1,089,670.4 hours
this gives us a pretty close figure to the real GPU time.

It is written in the paper that training took place on the Jean Zay
supercomputer, using [[https://buy.hpe.com/fr/fr/compute/apollo-systems/apollo-6500-system/apollo-6500-system/hpe-apollo-6500-gen10-plus-system/p/1013092236][HPE's Apollo 6500 Gen10 Plus]]. We can read on
their website that it uses AMD EPYC 7000 Series CPUs. Combining this
information with information about the Jean Zay supercomputer on
[[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][IDRIS's website]], we can see that only the **gpu_p5**  partition uses
such CPUs. 
We can conclude that for each of the 48 used nodes, the server
configuration is :
+ 2 CPUs : AMD Milan EPYC 7543
+ 512 Go of Memory
+ 8 NVIDIA A100 SXM4 80Go

** comparing the server footprint with the PCF sheet.

   In section 4.1, it is stated that they use values provided in the
   [[https://www.hpe.com/psnow/doc/a50005151enw][HPE ProLiant DL345 Gen10 Plus PCF]], the closest server with
   information provided. In this PCF sheet, we can read that servers
   are of type rack and that the estimated Carbon Footprint is of
   2503.2 kg CO_2 e.

   #+begin_src python :results output :exports results :session
server = {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}
out = run_experiment_server(server, "HPE ProLiant DL345 Gen10 Plus")
print_impacts_server(out)
ram_gwp = out['verbose']["RAM-1"]['impacts']['gwp']
print(f"RAM impact GWP: {ram_gwp}")
   #+end_src

   #+RESULTS:
   : Traceback (most recent call last):
   :   File "<stdin>", line 1, in <module>
   :   File "/tmp/babel-2NBS1C/python-jUw1Qs", line 19, in <module>
   :     print_impacts_server(out)
   :   File "<stdin>", line 2, in print_impacts_server
   : TypeError: 'NoneType' object is not subscriptable

If we try our tool with the server configuration used for training, we
can see manufacture impacts of 2300 kg CO_2 e. This impact is close
to the 2500 kgCO_2 e provided on the PCF sheet and is mainly impacted
by the quantity of memory used, as it accounts for 1800 kg CO_2 e.

** comparing the GPU footprint with the chosen value

In section 4.1 of the paper, it is stated that a value of 150 kg CO_2 e is
chosen. Taking a look at the source, there is no real justification
given for that value. Given that in \cite{Loubet2023life} a small GPUs
manufacture is estimated at emitting around 30 kg CO_2 e, we could
hypothesize that GPU manufacture impacts would be in the order of 50
to 150 kg CO_2 e.

#+begin_src shell :results output :exports none
curl -X 'POST' \
  'http://localhost:5000/v1/component/gpu?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "NVIDIA A100 SXM4 80 GB"
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"manufacture":330.0,"use":"not implemented","unit":"kgCO2eq"},"pe":{"manufacture":3900.0,"use":"not implemented","unit":"MJ"},"adp":{"manufacture":0.027,"use":"not implemented","unit":"kgSbeq"}},"verbose":{"units":1,"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":330.0,"unit":"kgCO2eq"},"pe":{"value":3900.0,"unit":"MJ"},"adp":{"value":0.027,"unit":"kgSbeq"}}}}

For the specific model used, the "NVIDIA A100 SMX4 80GB", our tool
provides an estimate of 330 kgCO_2 e for the manufacture of one GPU. this impact is mainly influenced
by the quantity of memory on the GPU with a carbon footprint of 290
kgCO_2 e, leaving 40 kgCO_2 e for the rest of the GPU.
This estimate of 40kgCO_2 e for the GPU without any memory is
consistent with the values provided in \cite{Loubet2023life}. The
importance of the memory present on the GPU in its manufacture impacts
show the need for an \gls{LCA} of a modern GPU used for \gls{HPC} to
obtain good quality estimates


** Estimating the total impacts

with all of the previous information, we can run the estimation

#+begin_src python :results output :exports none :session
with open("boaviztapi/data/ml_setups/test_bloom.json",'r') as bloom:
    bloom_model = json.load(bloom)
out = run_experiment(bloom_model,"bloom")
embodied = out["verbose"]["embodied impacts"]["gwp"]
dynamic = out["verbose"]["dynamic impacts"]["gwp"]
dynamic_energy = out['verbose']['dynamic energy consumption']
idle = out['impacts']['gwp']['direct'] - dynamic['value']
total = out['impacts']['gwp']['total']

print(f"embodied impacts gwp: {embodied}")
print(f"dynamic impacts gwp: {dynamic}")
print(f"dynamic energy consumption: {dynamic_energy}")
print(f"idle consumption: {idle} kgCO2e")
print('percentage of total: embodied ' + str(round(out['impacts']['gwp']['embodied'] / total * 100,1)) + ', dynamic ' + str(round(dynamic['value'] / total * 100,1)) + ', idle ' + str(round(idle/total*100,1)))
#+end_src

#+RESULTS:
: Traceback (most recent call last):
:   File "<stdin>", line 1, in <module>
:   File "/tmp/babel-2NBS1C/python-ATO7cL", line 4, in <module>
:     embodied = out["verbose"]["embodied impacts"]["gwp"]
: TypeError: 'NoneType' object is not subscriptable

with embodied impacts of 7T CO_2 e for the servers and 8.1T for the
GPUs to compare with the 7.6T for the servers and 3.6 T for the GPUs
in the paper. Most of the difference is due to estimated impacts of
330 kgCO_2 e for one GPU while it was estimated to 150 kgCO_2 e in the
paper.

For the dynamic consumption, we obtain an estimate of 23.7T CO_2 e,
mainly due to the GPUs (accountable for 22.4T, the only difference with
the figure obtained in the paper being the slightly off conversion
from real time to GPU hours) while the memory, not accounted for in
the paper brings another 1.35T CO_2 e.


#+ATTR_LATEX: :float t :caption \caption{Comparison of Estimated impacts with the expected impacts over the different sources of emissions} 
| Process              | Expected CO_2 | Expected share | Estimated CO_2 | Estimated share |
|                      |              |       of total |               |        of total |
|                      |     (TCO_2 e) |            (%) |      (TCO_2 e) |             (%) |
|----------------------+--------------+----------------+---------------+-----------------|
| Embodied emissions   |         11.2 |           22.2 |            15 |            25.4 |
| Dynamic consumption  |        24.69 |           48.9 |          23.7 |            40.2 |
| Indirect consumption |         14.6 |           28.9 |          19.8 |            33.6 |
|----------------------+--------------+----------------+---------------+-----------------|
| Total                |         50.5 |            100 |            59 |             100 |

Table \ref{tab:bloom} compares  the results our tool produces on the
different sources of CO_2 emissions with the expected results.
As we can see, results for each category of emissions are pretty
similar even if we obtain a higher estimate for embodied emissions due
to a higher estimate of the manufacturing impacts of a GPU. More
surprisingly a higher Indirect consumption estimate than the one presented in
the paper estimate even if we are supposedly based on the same figures
to convert from dinamyc to Indirect consumption. This can be explained
by the fact that for an unknown reason, when presenting the results in
the paper, the authors did not talk about the Infrastructure consumption they
previously mentionned but only presented Idle consumptiion induced by
the Dynamic consumption.


* Conclusions

After these experiments trying to evaluate the validity of our tool,
we can draw some conclusions, firstly about the challenges of
replicating results and then about the validity of our tool.

** about the replication of results

Overall, reproducing results from different papers proved way harder
than expected. Indeed, Unless a real effort is made by authors to allow replication of
their results, it is most of the time really difficult to find
enough information to run estimates and reproduce their
results.
This is also particularly true for results produced
using a measurement tool, indeed, If the hardware on which those
results were produced isn't detailed, it is impossible to
reproduce the experiments and check the quality of the results
presented. We were only able to conduct experiments for all of these
papers because we were able to contact the authors and they were
able to give us some insight about the hardware configuration of their experiments.

Even when we had enough information to run our estimates precisely
enough to hopefully match the expected results, we faced multiple
times important errors and inconsistencies in the data presented in
different tables. This was for example the case with the results
presented in \cite{Bannour2021evaluating} and in
\cite{Cattan2022benchmarking}. This was also the case to a lesser
extent in \cite{Jay2023experimental} were a notable effort for
reproducibility was realised by the authors but there were still
some problems and assumptions that needed to be made in order to
reproduce the results. 
After pointing out the problems with the data presented in
\cite{Cattan2022benchmarking}, the authors conducted new experiments
to resolve the problems with their data and we were able to reproduce
these new results.

** about the validity of the tool

Running new experiments often required us to gather some information
about a CPU not present in our database. This was not needed for
GPUs. It seems like there is much more diversity in CPUs used than in
GPU used. However, it was relatively easy to find all the information
we needed when encountering a new CPU and when running estimations
about GPU intensive tasks such as training NLP models, the CPU usage
is often set close to 0. Moreover, CPU manufacturing does not play a
huge part in the manufacturing impacts of a server in terms of
\gls{GWP}, it does however play an important part of the impacts in
terms of mineral resource usage (ADP)

We were unfortunately not able to find experiments to demonstrate the
validity of other indicators than the Global Warming Potential.

Still, we can see that overall, we were able to reproduce results for the
dynamic consumption and for the embodied impacts. These experiments
also demonstrate the usability of our tool in diverse scenarios.


* remaining stuff TODO                                             :noexport:

faire des jolis camemberts ?
de manière générale rédiger la section sur la comparaison aux ACV.


faire un truc sur la variation du dynamic ratio ?
variation de la durée de vie ?
baisser le dynamic ratio mais baisser la durée de vie du
matériel. (scenario à la patterson)






/!\ résultats de variabilité qui exploitent ADP dans strubell, à
modifier quand changement dynamic ratio sera fait.


modifier le code pour mettre des valeurs approximatives pour les GPU
modifier dynamic ratio
