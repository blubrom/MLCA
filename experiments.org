Experiments for validating our tool :

first, run the program, we will then be able to send it requests
#+begin_src shell :results output :exports both
pipenv run uvicorn boaviztapi.main:app --host=localhost --port 5000 &
#+end_src

* Checking that we can get the same dynamic consumption estimate as Green Algorithms

To do a first sanity check, we verifiy that we are able to reproduce
the same results as GA on the dynamic consumption part :

We choose a configuration that we know is available in both databases
(GA version 2.2 at the time of this experiment):
- 1 CPU A8-7680 (4 cores)
- 1 GPU NVIDIA GTX 1080 Ti
- 64 GB Memory

- Use time of 12h 0min
- no PUE / dynamic ratio
- carbon intensity of France is used (51.28 g CO_2 e/kWh)

for an expected result of 196.32g of CO_2 e and 3.83 kWh of dynamic
consumption (this [[http://calculator.green-algorithms.org//?runTime_hour=12&runTime_min=0&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=4&CPUmodel=A8-7680&numberGPUs=1&GPUmodel=NVIDIA%20GTX%201080%20Ti&memory=64&platformType=localServer][link]] should in theory get you to the page with this
exact setup and results but it seems like GA is kind of broken right
now).

If we now run the experiment with our tool :

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=false' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "configuration": {
      "cpu": {
        "units": 1,
        "model": "A8-7680"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 64,
          "density": 1.79
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 1,
      "model": "NVIDIA GeForce GTX 1080 Ti"
    }
  ],
  "usage": {
    "hours_use_time": 12,
    "gwp_factor": 51.28E-3,
    "dynamic_ratio": 1
  }
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"embodied":0.2,"direct":0.196,"total":0.4,"unit":"kgCO2eq"},"pe":{"embodied":2.0,"direct":49.3,"total":50.0,"unit":"MJ"},"adp":{"embodied":3e-05,"direct":2.46e-07,"total":3e-05,"unit":"kgSbeq"},
"energy consumption":{"value":3.83,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":0.0002,"unit":"Emissions of X Person per year in the \"Strat√©gie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":0.0004,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":0.001,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}}}

we see that we indeed obtain the same results of 196g CO_2 e and 3.83
kWh of dynamic energy consumption.

* replicating the Bloom estimates from [Luccioni2021estimating]

** Gathering information about the setup
To replicate their experiments, we first need to gather some
information on the time duration and hardware setup for the training
phase.

We can see in the paper that the training phase lasted for 118 days, 5
hours and 41 mins for a total of 1,082,990 GPU hours. (table 1)

in section 4.1, we can read that training used on average 48 computing
nodes with 8 GPUs each.
Combining the real time and these information about the setup, we
obtain

#+begin_src python :results output :exports both
real_time_hours = 118*24 + 5 + 41/60
estimated_gpu_hours = real_time_hours * 48 * 8
print(estimated_gpu_hours)
#+end_src

#+RESULTS:
: 1089670.4

we obtain an estimate of the number of GPU hours of 1,089,670.4 hours
this gives us a pretty close figure to the real GPU time.

It is written in the paper that training took place on the Jean Zay
supercomputer, using [[https://buy.hpe.com/fr/fr/compute/apollo-systems/apollo-6500-system/apollo-6500-system/hpe-apollo-6500-gen10-plus-system/p/1013092236][HPE's Apollo 6500 Gen10 Plus]]. We can read on
their website that it uses AMD EPYC 7000 Series CPUs. Combining this
information with informations about the Jean Zay supercomputer on
[[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][IDRIS's website]], we can see that only the **gpu_p5**  partition uses
such CPUs. 
We can conclude that for each of the 48 used nodes, the server
configuration is :
+ 2 CPUs : AMD Milan EPYC 7543
+ 512 Go of Memory
+ 8 NVIDIA A100 SXM4 80Go

** comparing the server footprint with the PCF sheet.

   In section 4.1, it is stated that they use values provided in the
   [[https://www.hpe.com/psnow/doc/a50005151enw][HPE ProLiant DL345 Gen10 Plus PCF]], the closest server with
   information provided. In this PCF sheet, we can read that servers
   are of type rack and that the estimated Carbon Footprint is of
   2503.2 kg CO_2 e.
   If we try our tool with the server configuration used for training,
   we obtain :
   #+begin_src shell :results output :exports both
   curl -X 'POST' \
  'http://localhost:5000/v1/server/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}'
   #+end_src

   #+RESULTS:
   : {"impacts":{"gwp":{"manufacture":2300.0,"use":1170.0,"unit":"kgCO2eq"},"pe":{"manufacture":29000.0,"use":39700.0,"unit":"MJ"},"adp":{"manufacture":0.17,"use":0.000198,"unit":"kgSbeq"}},"verbose":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"05f20fab521cfc551ec4d5ff4888e0ed7b1cccf43170e03f2234ec6b4c99db1c","capacity":{"input_value":512,"used_value":512,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":22000.0,"unit":"MJ"},"adp":{"value":0.053,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}},"USAGE-1":{"unit":1,"hash":0,"years_use_time":{"input_value":null,"used_value":1,"status":"SET"},"hours_electrical_consumption":{"input_value":null,"used_value":0.35175,"status":"SET"},"usage_location":{"input_value":null,"used_value":"EEE","status":"SET"},"gwp_factor":{"input_value":null,"used_value":0.38,"status":"SET"},"pe_factor":{"input_value":null,"used_value":12.874,"status":"SET"},"adp_factor":{"input_value":null,"used_value":6.42e-08,"status":"SET"},"max_power":{"input_value":null,"used_value":510,"status":"SET"},"workload":{"100":{"time":{"input_value":null,"used_value":0.15,"status":"SET"},"power":{"input_value":null,"used_value":1.0,"status":"SET"}},"50":{"time":{"input_value":null,"used_value":0.5499999999999999,"status":"SET"},"power":{"input_value":null,"used_value":0.7235294117647059,"status":"SET"}},"10":{"time":{"input_value":null,"used_value":0.19999999999999998,"status":"SET"},"power":{"input_value":null,"used_value":0.5117647058823529,"status":"SET"}},"idle":{"time":{"input_value":null,"used_value":0.09999999999999999,"status":"SET"},"power":{"input_value":null,"used_value":0.3941176470588235,"status":"SET"}},"off":{"time":{"input_value":null,"used_value":0.0,"status":"SET"},"power":{"input_value":null,"used_value":0.0,"status":"SET"}}},"impacts":{"gwp":{"value":1170.0,"unit":"kgCO2eq"},"pe":{"value":39700.0,"unit":"MJ"},"adp":{"value":0.000198,"unit":"kgSbeq"}}}}}

we can see manufacture impacts of 2300 kg CO_2 e. This impact is close
to the 2500 kgCO_2 e provided on the PCF sheet and is mainly impacted
by the quantity of memory used, as it accounts for 1800 kg CO_2 e.

** comparing the GPU footprint with the chosen value

In section 4.1, it is stated that a value of 150 kg CO_2 e is
chosen. Taking a look at the source, there is no real justification
given for that value. Given that in [Loubet2023life] a small GPUs
manufacture is estimated at emiting around 30 kg CO_2 e, we can
hypothesize that GPU manufacture impacts would be in the order of 50
to 150 kg CO_2 e.

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/component/gpu?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "NVIDIA A100 SXM4 80 GB"
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"manufacture":300.0,"use":"not implemented","unit":"kgCO2eq"},"pe":{"manufacture":4000.0,"use":"not implemented","unit":"MJ"},"adp":{"manufacture":0.03,"use":"not implemented","unit":"kgSbeq"}},
"verbose":{"units":1,"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA
A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80
GB","status":"UNCHANGED"},
"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},
"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}

For the specific model used, the "NVIDIA A100 SMX4 80GB", we can see
a manufacture impact of 300 kgCO_2 e. this impact is mainly influenced
by the quantity of memory on the GPU with 290 kg CO_2 e.
These are preliminary results since the base value for gpu impacts is
not proporly set yet.

** Estimating the total impacts

with all of the previous information, we can run the estimation with
the following command : 
   #+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 518
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 8,
      "model": "NVIDIA A100 SXM4 80 GB"
    }
  ],
  "psf": 1,
  "nb_nodes": 48,
  "cpu_usage_ratio": 0,
  "usage": {
    "days_use_time": 118,
    "hours_use_time": 5,
    "minute_use_time": 41,
    "usage_location": "FRA",
    "gwp_factor": 57.3E-3
  }
}'
   #+end_src

   #+RESULTS:
   : {"impacts":{"gwp":{"embodied":10000.0,"direct":82000.0,"total":100000.0,"unit":"kgCO2eq"},"pe":{"embodied":200000.0,"direct":16200000.0,"total":20000000.0,"unit":"MJ"},"adp":{"embodied":1.0,"direct":0.0696,"total":1.0,"unit":"kgSbeq"},"energy consumption":{"value":462000.0,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":50.0,"unit":"Emissions of X Person per year in the \"Strat√©gie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":100.0,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":40.0,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"usage":{"days_use_time":{"input_value":118.0,"used_value":118.0,"status":"UNCHANGED"},"hours_use_time":{"input_value":5.0,"used_value":5.0,"status":"UNCHANGED"},"hours_electrical_consumption":{"input_value":null,"used_value":3.3929549999999997,"status":"SET"},"usage_location":{"input_value":"FRA","used_value":"FRA","status":"UNCHANGED"},"gwp_factor":{"input_value":0.0573,"used_value":0.0573,"status":"UNCHANGED"},"pe_factor":{"input_value":null,"used_value":11.289,"status":"SET"},"adp_factor":{"input_value":null,"used_value":4.86e-08,"status":"SET"},"dynamic_ratio":{"input_value":null,"used_value":3.0969267139479904,"status":"SET"},"minute_use_time":{"input_value":41.0,"used_value":41.0,"status":"UNCHANGED"},"dynamic_impact_gwp":{"input_value":null,"used_value":[551.6919552485249,3],"status":"SET"},"dynamic_impact_adp":{"input_value":null,"used_value":[0.00046792720811654996,3],"status":"SET"},"dynamic_impact_pe":{"input_value":null,"used_value":[108691.98050262824,3],"status":"SET"},"impacts":{"gwp":{"value":1710.0,"unit":"kgCO2eq"},"pe":{"value":337000.0,"unit":"MJ"},"adp":{"value":0.00145,"unit":"kgSbeq"}}},"embodied impacts":{"gwp":{"server":6900.0,"gpus":8000.0,"unit":"kgCO2eq"},"pe":{"server":88000.0,"gpus":100000.0,"unit":"MJ"},"adp":{"server":0.52,"gpus":0.7,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":26500.0,"gpus":25000.0,"ram":1510.0,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":5220000.0,"gpus":4920000.0,"ram":297000.0,"cpus":0.0,"unit":"MJ"},"adp":{"value":0.0225,"gpus":0.0212,"ram":0.00128,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"47c27f3005e66f4e9e37a37249fc33b8fc7abd50335b06a7fd8b3bfd089c60b8","capacity":{"input_value":518,"used_value":518,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":23000.0,"unit":"MJ"},"adp":{"value":0.054,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}

 {"impacts":{"gwp":{"embodied":10000.0,"direct":82000.0,"total":100000.0,"unit":"kgCO2eq"},"pe":{"embodied":200000.0,"direct":16200000.0,"total":20000000.0,"unit":"MJ"},"adp":{"embodied":1.0,"direct":0.0696,"total":1.0,"unit":"kgSbeq"},"energy consumption":{"value":462000.0,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":50.0,"unit":"Emissions of X Person per year in the \"Strat√©gie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":100.0,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":40.0,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"embodied impacts":{"gwp":{"server":6900.0,"gpus":8000.0,"unit":"kgCO2eq"},"pe":{"server":88000.0,"gpus":100000.0,"unit":"MJ"},"adp":{"server":0.52,"gpus":0.7,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":26500.0,"gpus":25000.0,"ram":1510.0,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":5220000.0,"gpus":4920000.0,"ram":297000.0,"cpus":0.0,"unit":"MJ"},"adp":{"value":0.0225,"gpus":0.0212,"ram":0.00128,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"47c27f3005e66f4e9e37a37249fc33b8fc7abd50335b06a7fd8b3bfd089c60b8","capacity":{"input_value":518,"used_value":518,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":23000.0,"unit":"MJ"},"adp":{"value":0.054,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"input_value":null,"used_value":{"hash":"1d674b295466533ec734e75dd37f1c46e74a3decf6c0d5e55ebd348d81a3c48c","TYPE":"RAM","capacity":80,"density":0.625,"process":null,"manufacturer":null,"manufacture_date":null,"model":null,"integrator":null},"status":"SET"},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}


we can see in the results that we obtain close figures to those in the
paper.
with embodied impacts of 6.9T CO_2 e for the servers and 8T for the
GPUs to compare with the 7.6T for the servers and 3.6 T for the GPUs
in the paper. Most of the difference is due to estimated impacts of
300 kgCO_2 e for one GPU while it was estimated to 125 kgCO_2 e in the
paper.

For the dynamic consumption, we obtain an estimate of 26.5T CO_2 e,
mainly due to the GPUs (accountable for 25T, the only difference with
the figure obtained in the paper being the slightly off conversion
from real time to GPU hours) while the memory, not accounted for in
the paper brings another 1.5T CO_2 e.

The only thing that differs greatly is the value for the idle
consumption. (not so surprising since figures differ quite a lot).

* replicating results from [Bannour2021evaluating]

** detailling the Hardware configurations
the facility setup is the [[https://doc.lab-ia.fr/][LaBia]]. We can see that the only nodes using a
20 core CPU are: n[101-102]:

-  2 x Intel Xeon Gold 6148 20 cores / 40 threads @ 2.4 GHz (Skylake)
-  384 GiB of RAM
-  4 x NVIDIA Tesla V100 with 32 GiB of RAM (NVLink)

using 32 GB of RAM and not the full 384.

while the lab server is using one GTX 1080 Ti with 11GB of memory.
it is a Dell PowerEdge R730 with 2 GTW 1080 Ti, 2 Intel Xeon E5-2620
v4 CPU and 125 GB memory (only 11 of whihch are requested).

while we do not have the Intel Xeon Gold 6148 in our CPU database, we
can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/120489/intel-xeon-gold-6148-processor-27-5m-cache-2-40-ghz/specifications.html][Intel's website]] that it has a TDP of 150W, was realeased in
2017 with a process of 14nm with the Skylake architecture, this is
sufficient information to add one entry to our database, knowing the
information about the Skylake architecture from [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)][WikiChips]]. 

** Problems with the provided data

*** incoherences between tables 3 and 4
les r√©sultats affich√©s dans le papier ne sont pas coh√©rent d'un
tableau √† l'autre. Si on essaie de passer des valeurs de consommation
d'√©nergie (pour GA au moins) avec le facteur d'intensit√© carbone
indiqu√©, on ne retombe pas du tout sur les √©missions de carbone
indiqu√©es.

Par exemple : pour French Press, server: il est indiqu√© 1.38 kWh et
dans la section 4.2 il est indiqu√© 39 gCO_2 e/kWh comme intensit√©
carbone utilis√©e.
#+begin_src python :results output :exports both
print(39*1.38)
#+end_src

#+RESULTS:
: 53.81999999999999

on obtient 53.8g alors que dans la table 3, il est indiqu√© 350g pour
cette m√™me exp√©rience.

*** Not being able to find the same energy consumption using the same formula

An NVIDIA Tesla V100 as a TDP of 250W, therefore, if used for 2 hours,
we would expect an energy consumption of 500Wh 

However, in the paper, this consumption is estimated at a little more
than 1kWh + 32*.37W * 2 = 23Wh for the memory

#+begin_src python :results output :exports both
print(32*.37)
print((500 + 11.84) * 118/60) 
#+end_src

#+RESULTS:
: 11.84
: 1006.6186666666666

We can see that If we were to assume the usage of two GPUs, we would
obtain an estimate of 1.006 kWh, that is close to the 1.03kWh
estimated for French Press on the Facility but not exactly the same
value.
This is the closest explaination of the results I am able to formulate
while still not being exact.

#+begin_src python :results output :exports both
import subprocess

server = {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}

facility = {
  "configuration": {
      "cpu": {
      "units" : 1,
      "model": " Xeon Gold 6148"
      }
      
  }
}

request = f"curl -x 'POST' \
 'http://localhost:5000/v1/server/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d {server}"
s = subprocess.run(request, shell = True, capture_output=True, check=True)
print(request)
print(s.stdout)

#+end_src

#+RESULTS:

** experiments

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "Xeon Gold 6148"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 32
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 4,
      "model": "NVIDIA Tesla V100 PCIe 32 GB"
    }
  ],
  "psf": 1,
  "nb_nodes": 1,
  "cpu_usage_ratio": 0,
  "usage": {
    "minute_use_time": 118.04,
    "usage_location": "FRA",
    "gwp_factor": 39E-3
  }
}'
#+end_src

: #+RESULTS:{"impacts":{"gwp":{"embodied":0.05,"direct":0.24,"total":0.3,"unit":"kgCO2eq"},"pe":{"embodied":0.7,"direct":69.6,"total":70.0,"unit":"MJ"},"adp":{"embodied":1e-05,"direct":3e-07,"total":1e-05,"unit":"kgSbeq"},"energy consumption":{"value":1.99,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":0.0001,"unit":"Emissions of X Person per year in the \"Strat√©gie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":0.0003,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":0.0003,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"usage":{"years_use_time":{"input_value":null,"used_value":0,"status":"SET"},"hours_electrical_consumption":{"input_value":null,"used_value":1.01192,"status":"SET"},"usage_location":{"input_value":"FRA","used_value":"FRA","status":"UNCHANGED"},"gwp_factor":{"input_value":0.039,"used_value":0.039,"status":"UNCHANGED"},"pe_factor":{"input_value":null,"used_value":11.289,"status":"SET"},"adp_factor":{"input_value":null,"used_value":4.86e-08,"status":"SET"},"dynamic_ratio":{"input_value":null,"used_value":3.0969267139479904,"status":"SET"},"minute_use_time":{"input_value":118.04,"used_value":118.04,"status":"UNCHANGED"},"dynamic_impact_gwp":{"input_value":null,"used_value":[0.07764057392,3],"status":"SET"},"dynamic_impact_adp":{"input_value":null,"used_value":[9.6752099808e-08,3],"status":"SET"},"dynamic_impact_pe":{"input_value":null,"used_value":[22.47395997392,3],"status":"SET"},"impacts":{"gwp":{"value":0.24,"unit":"kgCO2eq"},"pe":{"value":69.6,"unit":"MJ"},"adp":{"value":3e-07,"unit":"kgSbeq"}}},"embodied impacts":{"gwp":{"server":0.026,"gpus":0.03,"unit":"kgCO2eq"},"pe":{"server":0.35,"gpus":0.3,"unit":"MJ"},"adp":{"server":5.3e-06,"gpus":4e-06,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":0.0776,"gpus":0.0767,"ram":0.000915,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":22.5,"gpus":22.2,"ram":0.265,"cpus":0.0,"unit":"MJ"},"adp":{"value":9.68e-08,"gpus":9.56e-08,"ram":1.14e-09,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"e9fb3b5d6c10d5704f77b5ceb8b83db4da55d51793389f5c5d1ac968decb6146","die_size":{"input_value":null,"used_value":6.94,"status":"SET"},"model":{"input_value":"Xeon Gold 6148","used_value":"Xeon Gold 6148","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":150,"status":"SET"},"impacts":{"gwp":{"value":45.6,"unit":"kgCO2eq"},"pe":{"value":680.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"a34b138e4ee0b4c832576fe84c3ef50c4e9713ab83fe8269fdc4dbacfd382efb","capacity":{"input_value":32,"used_value":32,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":120.0,"unit":"kgCO2eq"},"pe":{"value":1500.0,"unit":"MJ"},"adp":{"value":0.0049,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"d510a031d97870b128df7e34c32ed8264c7ac8f1786f012cce7f6dbf2a6ffebf","case_type":{"input_value":null,"used_value":"rack","status":"SET"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.15,"status":"SET"},"model":{"input_value":"NVIDIA Tesla V100 PCIe 32 GB","used_value":"NVIDIA Tesla V100 PCIe 32 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":250,"status":"SET"},"memory_size":{"input_value":null,"used_value":32,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":32,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":120.0,"unit":"kgCO2eq"},"pe":{"value":1500.0,"unit":"MJ"},"adp":{"value":0.0049,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":100.0,"unit":"kgCO2eq"},"pe":{"value":2000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}



* replicating results from [Dinarelli2022toward]

Je commence √† regarder pour essayer de retrouver leurs r√©sultats. Pour
 l'instant, une premi√®re nouvelle rassurante c'est que j'arrive √†
 passer des valeurs d'√©nergie aux valeurs
 d'√©quivalent carbone indiqu√©es en utilisant l'intensit√© carbone indiqu√©e.
Seul probl√®me, ils ont visiblement fait une erreur dans la traduction
 entre fran√ßais et anglais pour les valeurs de consommation
 √©nerg√©tique
 pour la table 1. Si on lit 4,473 comme 4.473, on retrouve bien 4.473*51 = 228.123 g CO_2 e.
Maintenant reste √† trouver des valeurs pour la consommation
√©nerg√©tique coh√©rentes


on peut estimer que la partition de Jean Zay √† 32 GB soit celle ci :

Avec la partition **gpu\_p2**, **gpu\_p2s** ou **gpu\_p2l** (partitions d√©di√©es √† la communaut√© IA), vous aurez acc√®s aux ressources suivantes :

+   31 n≈ìuds de calcul acc√©l√©r√©s octo-GPU avec :
    +   2 processeurs Intel Cascade Lake 6226 (12 c≈ìurs √† 2,7 GHz), soit 24 c≈ìurs par n≈ìud
    +   20 n≈ìuds √† 384 Go de m√©moire (avec **gpu\_p2** ou **gpu\_p2s**)
       +   11 n≈ìuds √† 768 Go de m√©moire (avec **gpu\_p2** ou **gpu\_p2l**)
       +   8 GPU Nvidia Tesla V100 SXM2 32Go

Vu qu'apr√®s il est indiqu√© 4 GPU √† 32 GB pour rappel, c'est peut-√™tre celle ci :

+   612 n≈ìuds de calcul acc√©l√©r√©s quadri-GPU avec :
        +  2 processeurs Intel Cascade Lake 6248 (20 c≈ìurs √† 2,5 GHz), soit 40 c≈ìurs par n≈ìud
        +  192 Go de m√©moire par n≈ìud
        +  351 n≈ìuds avec 4 GPU Nvidia Tesla V100 SXM2 16 Go (avec **v100-16g**)
        +  261 n≈ìuds avec 4 GPU Nvidia Tesla V100 SXM2 32 Go (avec **v100-32g**)

En tout cas, sur le site de l'IDRIS, ce sont les deux seuls endroits
o√π des GPU avec 32GB de m√©moire sont indiqu√©s.




En tout cas, pour essayer de te donner les info dont tu as besoin, apr√®s si c'est pas √ßa, ou si tu as besoin d'autres informations, n'h√©site pas √† demander :
"CPU : nombre de coeurs utilis√©s, mod√®le" => je ne sais pas combien de coeur CPU sont utilis√© par les mod√®les wav2vec que j'ai utilis√©, mes mod√®les SLU en utilise un seul.
"GPU : nombre utilis√©s et mod√®les, m√©moire utilis√©e" (je pr√©sume que tu voulais √©crire "nombre de coeur utilis√©s") => 4 GPU pendant 100 heures pour fine-tuner le mod√®le wav2vec (seulement pour les exp√©riences o√π il est fine-tun√© √©videmment), 1 seule GPU pour mes mod√®les SLU.

Pour la taille des mod√®les :
environ 308 millions de param√®tres pour le mod√®le wav2vec2
environ 12 millions de param√®tres pour le mod√®le SLU

Pour la m√©moire utilis√©e, on est √† environ 80GB de m√©moire centrale (RAM de la CPU) et environ 8GB de m√©moire GPU pour les entra√Ænements des mes mod√®les SLU.
Pour le fine-tuning des mod√®les wav2vec je ne sais pas, je n'ai jamais regard√© pendant l'apprentissage de ces mod√®les, je sais que √ßa passe pas sur les GPU √† 24GB du LIG, du coup j'ai d√ª le faire sur JZ sur la partition de GPU √† 32 GB.
Je pr√©sume que la plupart des GPU (4 GPU √† 32GB pour rappel) est utilis√© par le mod√®le et les gradients des param√®tres, puisque l'apprentissage des mod√®les SLU sur les m√™mes donn√©es passe sur des GPU √† 12GB du LIG.
1:36 PM

Alors, sur JZ j'utilise les Tesla V100-SXM2-32GB .
Au LIG, pour les mod√®les SLU, j'utilise principalement des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go.
Il m'est arriv√© d'utiliser parfois des NVIDIA TITAN X (Pascal) 12Go et des NVIDIA Quadro RTX 6000 24Go.

En fait au LIG c'est OAR qui g√®re les job, du coup ce n'est pas facile de monitorer exactement o√π le job est ex√©cut√©.
Je sais que si je lance sur une machine donn√©, ce que je fais parce
que OAR par d√©faut te met sur la premi√®re disponible et du coup tout
le monde se retrouve sur les m√™mes machines, il y a telle ou telle
GPU, mais l√† je ne me rappelle pas dans quelle mesure je lance plus
sur une machine que sur une autre. √Ä priori c'est 90%-95% du temps sur
des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go en mesure
√©gale.
