Experiments for validating our tool :

first, run the program, we will then be able to send it requests
#+begin_src shell :results output :exports both
pipenv run uvicorn boaviztapi.main:app --host=localhost --port 5000 &
#+end_src

* Checking that we can get the same dynamic consumption estimate as Green Algorithms

To do a first sanity check, we verifiy that we are able to reproduce
the same results as GA on the dynamic consumption part :

We choose a configuration that we know is available in both databases
(GA version 2.2 at the time of this experiment):
- 1 CPU A8-7680 (4 cores)
- 1 GPU NVIDIA GTX 1080 Ti
- 64 GB Memory

- Use time of 12h 0min
- no PUE / dynamic ratio
- carbon intensity of France is used (51.28 g CO_2 e/kWh)

for an expected result of 196.32g of CO_2 e and 3.83 kWh of dynamic
consumption (this [[http://calculator.green-algorithms.org//?runTime_hour=12&runTime_min=0&appVersion=v2.2&locationContinent=Europe&locationCountry=France&locationRegion=FR&PUEradio=Yes&PUE=1&coreType=Both&numberCPUs=4&CPUmodel=A8-7680&numberGPUs=1&GPUmodel=NVIDIA%20GTX%201080%20Ti&memory=64&platformType=localServer][link]] should in theory get you to the page with this
exact setup and results but it seems like GA is kind of broken right
now).

If we now run the experiment with our tool :

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=false' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "configuration": {
      "cpu": {
        "units": 1,
        "model": "A8-7680"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 64,
          "density": 1.79
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 1,
      "model": "NVIDIA GeForce GTX 1080 Ti"
    }
  ],
  "usage": {
    "hours_use_time": 12,
    "gwp_factor": 51.28E-3,
    "dynamic_ratio": 1
  }
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"embodied":0.2,"direct":0.196,"total":0.4,"unit":"kgCO2eq"},"pe":{"embodied":2.0,"direct":49.3,"total":50.0,"unit":"MJ"},"adp":{"embodied":3e-05,"direct":2.46e-07,"total":3e-05,"unit":"kgSbeq"},
"energy consumption":{"value":3.83,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":0.0002,"unit":"Emissions of X Person per year in the \"Stratégie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":0.0004,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":0.001,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}}}

we see that we indeed obtain the same results of 196g CO_2 e and 3.83
kWh of dynamic energy consumption.

* replicating the Bloom estimates from [Luccioni2021estimating]

** Gathering information about the setup
To replicate their experiments, we first need to gather some
information on the time duration and hardware setup for the training
phase.

We can see in the paper that the training phase lasted for 118 days, 5
hours and 41 mins for a total of 1,082,990 GPU hours. (table 1)

in section 4.1, we can read that training used on average 48 computing
nodes with 8 GPUs each.
Combining the real time and these information about the setup, we
obtain

#+begin_src python :results output :exports both
real_time_hours = 118*24 + 5 + 41/60
estimated_gpu_hours = real_time_hours * 48 * 8
print(estimated_gpu_hours)
#+end_src

#+RESULTS:
: 1089670.4

we obtain an estimate of the number of GPU hours of 1,089,670.4 hours
this gives us a pretty close figure to the real GPU time.

It is written in the paper that training took place on the Jean Zay
supercomputer, using [[https://buy.hpe.com/fr/fr/compute/apollo-systems/apollo-6500-system/apollo-6500-system/hpe-apollo-6500-gen10-plus-system/p/1013092236][HPE's Apollo 6500 Gen10 Plus]]. We can read on
their website that it uses AMD EPYC 7000 Series CPUs. Combining this
information with informations about the Jean Zay supercomputer on
[[http://www.idris.fr/jean-zay/cpu/jean-zay-cpu-hw.html#gpu_p13][IDRIS's website]], we can see that only the **gpu_p5**  partition uses
such CPUs. 
We can conclude that for each of the 48 used nodes, the server
configuration is :
+ 2 CPUs : AMD Milan EPYC 7543
+ 512 Go of Memory
+ 8 NVIDIA A100 SXM4 80Go

** comparing the server footprint with the PCF sheet.

   In section 4.1, it is stated that they use values provided in the
   [[https://www.hpe.com/psnow/doc/a50005151enw][HPE ProLiant DL345 Gen10 Plus PCF]], the closest server with
   information provided. In this PCF sheet, we can read that servers
   are of type rack and that the estimated Carbon Footprint is of
   2503.2 kg CO_2 e.
   If we try our tool with the server configuration used for training,
   we obtain :
   #+begin_src shell :results output :exports both
   curl -X 'POST' \
  'http://localhost:5000/v1/server/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}'
   #+end_src

   #+RESULTS:
   : {"impacts":{"gwp":{"manufacture":2300.0,"use":1170.0,"unit":"kgCO2eq"},"pe":{"manufacture":29000.0,"use":39700.0,"unit":"MJ"},"adp":{"manufacture":0.17,"use":0.000198,"unit":"kgSbeq"}},"verbose":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"05f20fab521cfc551ec4d5ff4888e0ed7b1cccf43170e03f2234ec6b4c99db1c","capacity":{"input_value":512,"used_value":512,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":22000.0,"unit":"MJ"},"adp":{"value":0.053,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}},"USAGE-1":{"unit":1,"hash":0,"years_use_time":{"input_value":null,"used_value":1,"status":"SET"},"hours_electrical_consumption":{"input_value":null,"used_value":0.35175,"status":"SET"},"usage_location":{"input_value":null,"used_value":"EEE","status":"SET"},"gwp_factor":{"input_value":null,"used_value":0.38,"status":"SET"},"pe_factor":{"input_value":null,"used_value":12.874,"status":"SET"},"adp_factor":{"input_value":null,"used_value":6.42e-08,"status":"SET"},"max_power":{"input_value":null,"used_value":510,"status":"SET"},"workload":{"100":{"time":{"input_value":null,"used_value":0.15,"status":"SET"},"power":{"input_value":null,"used_value":1.0,"status":"SET"}},"50":{"time":{"input_value":null,"used_value":0.5499999999999999,"status":"SET"},"power":{"input_value":null,"used_value":0.7235294117647059,"status":"SET"}},"10":{"time":{"input_value":null,"used_value":0.19999999999999998,"status":"SET"},"power":{"input_value":null,"used_value":0.5117647058823529,"status":"SET"}},"idle":{"time":{"input_value":null,"used_value":0.09999999999999999,"status":"SET"},"power":{"input_value":null,"used_value":0.3941176470588235,"status":"SET"}},"off":{"time":{"input_value":null,"used_value":0.0,"status":"SET"},"power":{"input_value":null,"used_value":0.0,"status":"SET"}}},"impacts":{"gwp":{"value":1170.0,"unit":"kgCO2eq"},"pe":{"value":39700.0,"unit":"MJ"},"adp":{"value":0.000198,"unit":"kgSbeq"}}}}}

we can see manufacture impacts of 2300 kg CO_2 e. This impact is close
to the 2500 kgCO_2 e provided on the PCF sheet and is mainly impacted
by the quantity of memory used, as it accounts for 1800 kg CO_2 e.

** comparing the GPU footprint with the chosen value

In section 4.1, it is stated that a value of 150 kg CO_2 e is
chosen. Taking a look at the source, there is no real justification
given for that value. Given that in [Loubet2023life] a small GPUs
manufacture is estimated at emiting around 30 kg CO_2 e, we can
hypothesize that GPU manufacture impacts would be in the order of 50
to 150 kg CO_2 e.

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/component/gpu?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "NVIDIA A100 SXM4 80 GB"
}'
#+end_src

#+RESULTS:
: {"impacts":{"gwp":{"manufacture":300.0,"use":"not implemented","unit":"kgCO2eq"},"pe":{"manufacture":4000.0,"use":"not implemented","unit":"MJ"},"adp":{"manufacture":0.03,"use":"not implemented","unit":"kgSbeq"}},
"verbose":{"units":1,"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA
A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80
GB","status":"UNCHANGED"},
"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},
"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}

For the specific model used, the "NVIDIA A100 SMX4 80GB", we can see
a manufacture impact of 300 kgCO_2 e. this impact is mainly influenced
by the quantity of memory on the GPU with 290 kg CO_2 e.
These are preliminary results since the base value for gpu impacts is
not proporly set yet.

** Estimating the total impacts

with all of the previous information, we can run the estimation with
the following command : 
   #+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 518
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 8,
      "model": "NVIDIA A100 SXM4 80 GB"
    }
  ],
  "psf": 1,
  "nb_nodes": 48,
  "cpu_usage_ratio": 0,
  "usage": {
    "days_use_time": 118,
    "hours_use_time": 5,
    "minute_use_time": 41,
    "usage_location": "FRA",
    "gwp_factor": 57.3E-3
  }
}'
   #+end_src

   #+RESULTS:
   : {"impacts":{"gwp":{"embodied":10000.0,"direct":82000.0,"total":100000.0,"unit":"kgCO2eq"},"pe":{"embodied":200000.0,"direct":16200000.0,"total":20000000.0,"unit":"MJ"},"adp":{"embodied":1.0,"direct":0.0696,"total":1.0,"unit":"kgSbeq"},"energy consumption":{"value":462000.0,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":50.0,"unit":"Emissions of X Person per year in the \"Stratégie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":100.0,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":40.0,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"usage":{"days_use_time":{"input_value":118.0,"used_value":118.0,"status":"UNCHANGED"},"hours_use_time":{"input_value":5.0,"used_value":5.0,"status":"UNCHANGED"},"hours_electrical_consumption":{"input_value":null,"used_value":3.3929549999999997,"status":"SET"},"usage_location":{"input_value":"FRA","used_value":"FRA","status":"UNCHANGED"},"gwp_factor":{"input_value":0.0573,"used_value":0.0573,"status":"UNCHANGED"},"pe_factor":{"input_value":null,"used_value":11.289,"status":"SET"},"adp_factor":{"input_value":null,"used_value":4.86e-08,"status":"SET"},"dynamic_ratio":{"input_value":null,"used_value":3.0969267139479904,"status":"SET"},"minute_use_time":{"input_value":41.0,"used_value":41.0,"status":"UNCHANGED"},"dynamic_impact_gwp":{"input_value":null,"used_value":[551.6919552485249,3],"status":"SET"},"dynamic_impact_adp":{"input_value":null,"used_value":[0.00046792720811654996,3],"status":"SET"},"dynamic_impact_pe":{"input_value":null,"used_value":[108691.98050262824,3],"status":"SET"},"impacts":{"gwp":{"value":1710.0,"unit":"kgCO2eq"},"pe":{"value":337000.0,"unit":"MJ"},"adp":{"value":0.00145,"unit":"kgSbeq"}}},"embodied impacts":{"gwp":{"server":6900.0,"gpus":8000.0,"unit":"kgCO2eq"},"pe":{"server":88000.0,"gpus":100000.0,"unit":"MJ"},"adp":{"server":0.52,"gpus":0.7,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":26500.0,"gpus":25000.0,"ram":1510.0,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":5220000.0,"gpus":4920000.0,"ram":297000.0,"cpus":0.0,"unit":"MJ"},"adp":{"value":0.0225,"gpus":0.0212,"ram":0.00128,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"47c27f3005e66f4e9e37a37249fc33b8fc7abd50335b06a7fd8b3bfd089c60b8","capacity":{"input_value":518,"used_value":518,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":23000.0,"unit":"MJ"},"adp":{"value":0.054,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":80,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":290.0,"unit":"kgCO2eq"},"pe":{"value":3600.0,"unit":"MJ"},"adp":{"value":0.0098,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}

 {"impacts":{"gwp":{"embodied":10000.0,"direct":82000.0,"total":100000.0,"unit":"kgCO2eq"},"pe":{"embodied":200000.0,"direct":16200000.0,"total":20000000.0,"unit":"MJ"},"adp":{"embodied":1.0,"direct":0.0696,"total":1.0,"unit":"kgSbeq"},"energy consumption":{"value":462000.0,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":50.0,"unit":"Emissions of X Person per year in the \"Stratégie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":100.0,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":40.0,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"embodied impacts":{"gwp":{"server":6900.0,"gpus":8000.0,"unit":"kgCO2eq"},"pe":{"server":88000.0,"gpus":100000.0,"unit":"MJ"},"adp":{"server":0.52,"gpus":0.7,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":26500.0,"gpus":25000.0,"ram":1510.0,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":5220000.0,"gpus":4920000.0,"ram":297000.0,"cpus":0.0,"unit":"MJ"},"adp":{"value":0.0225,"gpus":0.0212,"ram":0.00128,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"50cbc426060b04c31b0009f1fb833c7a257a8e5d130d51b4dba3f36bfb49bef2","die_size":{"input_value":null,"used_value":2.1,"status":"SET"},"model":{"input_value":"AMD Milan EPYC 7543","used_value":"AMD Milan EPYC 7543","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":65,"status":"SET"},"impacts":{"gwp":{"value":26.0,"unit":"kgCO2eq"},"pe":{"value":420.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"47c27f3005e66f4e9e37a37249fc33b8fc7abd50335b06a7fd8b3bfd089c60b8","capacity":{"input_value":518,"used_value":518,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":1800.0,"unit":"kgCO2eq"},"pe":{"value":23000.0,"unit":"MJ"},"adp":{"value":0.054,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"083dcd17f9997756af73de7c61f0cf2986b25075ad00bbf7c07e08cc80a2183f","case_type":{"input_value":"rack","used_value":"rack","status":"UNCHANGED"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.26,"status":"SET"},"model":{"input_value":"NVIDIA A100 SXM4 80 GB","used_value":"NVIDIA A100 SXM4 80 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":400,"status":"SET"},"memory_size":{"input_value":null,"used_value":80,"status":"SET"},"memory":{"input_value":null,"used_value":{"hash":"1d674b295466533ec734e75dd37f1c46e74a3decf6c0d5e55ebd348d81a3c48c","TYPE":"RAM","capacity":80,"density":0.625,"process":null,"manufacturer":null,"manufacture_date":null,"model":null,"integrator":null},"status":"SET"},"impacts":{"gwp":{"value":300.0,"unit":"kgCO2eq"},"pe":{"value":4000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}


we can see in the results that we obtain close figures to those in the
paper.
with embodied impacts of 6.9T CO_2 e for the servers and 8T for the
GPUs to compare with the 7.6T for the servers and 3.6 T for the GPUs
in the paper. Most of the difference is due to estimated impacts of
300 kgCO_2 e for one GPU while it was estimated to 125 kgCO_2 e in the
paper.

For the dynamic consumption, we obtain an estimate of 26.5T CO_2 e,
mainly due to the GPUs (accountable for 25T, the only difference with
the figure obtained in the paper being the slightly off conversion
from real time to GPU hours) while the memory, not accounted for in
the paper brings another 1.5T CO_2 e.

The only thing that differs greatly is the value for the idle
consumption. (not so surprising since figures differ quite a lot).

* replicating results from [Bannour2021evaluating]

** detailling the Hardware configurations
the facility setup is the [[https://doc.lab-ia.fr/][LaBia]]. We can see that the only nodes using a
20 core CPU are: n[101-102]:

-  2 x Intel Xeon Gold 6148 20 cores / 40 threads @ 2.4 GHz (Skylake)
-  384 GiB of RAM
-  4 x NVIDIA Tesla V100 with 32 GiB of RAM (NVLink)

using 32 GB of RAM and not the full 384.

while the lab server is using one GTX 1080 Ti with 11GB of memory.
it is a Dell PowerEdge R730 with 2 GTW 1080 Ti, 2 Intel Xeon E5-2620
v4 CPU and 125 GB memory (only 11 of whihch are requested).

while we do not have the Intel Xeon Gold 6148 in our CPU database, we
can see on [[https://www.intel.fr/content/www/fr/fr/products/sku/120489/intel-xeon-gold-6148-processor-27-5m-cache-2-40-ghz/specifications.html][Intel's website]] that it has a TDP of 150W, was realeased in
2017 with a process of 14nm with the Skylake architecture, this is
sufficient information to add one entry to our database, knowing the
information about the Skylake architecture from [[https://en.wikichip.org/wiki/intel/microarchitectures/skylake_(server)][WikiChips]]. 

** Problems with the provided data

*** incoherences between tables 3 and 4
les résultats affichés dans le papier ne sont pas cohérent d'un
tableau à l'autre. Si on essaie de passer des valeurs de consommation
d'énergie (pour GA au moins) avec le facteur d'intensité carbone
indiqué, on ne retombe pas du tout sur les émissions de carbone
indiquées.

Par exemple : pour French Press, server: il est indiqué 1.38 kWh et
dans la section 4.2 il est indiqué 39 gCO_2 e/kWh comme intensité
carbone utilisée.
#+begin_src python :results output :exports both
print(39*1.38)
#+end_src

#+RESULTS:
: 53.81999999999999

on obtient 53.8g alors que dans la table 3, il est indiqué 350g pour
cette même expérience.

*** Not being able to find the same energy consumption using the same formula

An NVIDIA Tesla V100 as a TDP of 250W, therefore, if used for 2 hours,
we would expect an energy consumption of 500Wh 

However, in the paper, this consumption is estimated at a little more
than 1kWh + 32*.37W * 2 = 23Wh for the memory

#+begin_src python :results output :exports both
print(32*.37)
print((500 + 11.84) * 118/60) 
#+end_src

#+RESULTS:
: 11.84
: 1006.6186666666666

We can see that If we were to assume the usage of two GPUs, we would
obtain an estimate of 1.006 kWh, that is close to the 1.03kWh
estimated for French Press on the Facility but not exactly the same
value.
This is the closest explaination of the results I am able to formulate
while still not being exact.

#+begin_src python :results output :exports both
import subprocess

server = {
    "model": {
      "type": "rack"
    },
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "AMD Milan EPYC 7543"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 512
        }
      ]
    }
}

facility = {
  "configuration": {
      "cpu": {
      "units" : 1,
      "model": " Xeon Gold 6148"
      }
      
  }
}

request = f"curl -x 'POST' \
 'http://localhost:5000/v1/server/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d {server}"
s = subprocess.run(request, shell = True, capture_output=True, check=True)
print(request)
print(s.stdout)

#+end_src

#+RESULTS:

** experiments

#+begin_src shell :results output :exports both
curl -X 'POST' \
  'http://localhost:5000/v1/mlca/?verbose=true' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "server": {
    "configuration": {
      "cpu": {
        "units": 2,
        "model": "Xeon Gold 6148"
      },
      "ram": [
        {
          "units": 1,
          "capacity": 32
        }
      ]
    }
  },
  "gpu": [
    {
      "units": 4,
      "model": "NVIDIA Tesla V100 PCIe 32 GB"
    }
  ],
  "psf": 1,
  "nb_nodes": 1,
  "cpu_usage_ratio": 0,
  "usage": {
    "minute_use_time": 118.04,
    "usage_location": "FRA",
    "gwp_factor": 39E-3
  }
}'
#+end_src

: #+RESULTS:{"impacts":{"gwp":{"embodied":0.05,"direct":0.24,"total":0.3,"unit":"kgCO2eq"},"pe":{"embodied":0.7,"direct":69.6,"total":70.0,"unit":"MJ"},"adp":{"embodied":1e-05,"direct":3e-07,"total":1e-05,"unit":"kgSbeq"},"energy consumption":{"value":1.99,"unit":"kWh"}},"perspective":{"relative_SNBC":{"value":0.0001,"unit":"Emissions of X Person per year in the \"Stratégie Nationale Bas Carbone (SNBC)\" sustanability objectives for France"},"relative_PB_Climate_Change":{"value":0.0003,"unit":"person in a scenario where the Planetary Boundary for Climate Change is not exceded"},"relative_PB_ADP":{"value":0.0003,"unit":"person in a scenario where the Planetary Boundary for Abiotic Ressources Deplition is not exceded"}},"verbose":{"usage":{"years_use_time":{"input_value":null,"used_value":0,"status":"SET"},"hours_electrical_consumption":{"input_value":null,"used_value":1.01192,"status":"SET"},"usage_location":{"input_value":"FRA","used_value":"FRA","status":"UNCHANGED"},"gwp_factor":{"input_value":0.039,"used_value":0.039,"status":"UNCHANGED"},"pe_factor":{"input_value":null,"used_value":11.289,"status":"SET"},"adp_factor":{"input_value":null,"used_value":4.86e-08,"status":"SET"},"dynamic_ratio":{"input_value":null,"used_value":3.0969267139479904,"status":"SET"},"minute_use_time":{"input_value":118.04,"used_value":118.04,"status":"UNCHANGED"},"dynamic_impact_gwp":{"input_value":null,"used_value":[0.07764057392,3],"status":"SET"},"dynamic_impact_adp":{"input_value":null,"used_value":[9.6752099808e-08,3],"status":"SET"},"dynamic_impact_pe":{"input_value":null,"used_value":[22.47395997392,3],"status":"SET"},"impacts":{"gwp":{"value":0.24,"unit":"kgCO2eq"},"pe":{"value":69.6,"unit":"MJ"},"adp":{"value":3e-07,"unit":"kgSbeq"}}},"embodied impacts":{"gwp":{"server":0.026,"gpus":0.03,"unit":"kgCO2eq"},"pe":{"server":0.35,"gpus":0.3,"unit":"MJ"},"adp":{"server":5.3e-06,"gpus":4e-06,"unit":"kgSbeq"}},"dynamic impacts":{"gwp":{"value":0.0776,"gpus":0.0767,"ram":0.000915,"cpus":0.0,"unit":"kgCO2eq"},"pe":{"value":22.5,"gpus":22.2,"ram":0.265,"cpus":0.0,"unit":"MJ"},"adp":{"value":9.68e-08,"gpus":9.56e-08,"ram":1.14e-09,"cpus":0.0,"unit":"kgSbeq"}},"manufacture of one server node":{"CPU-1":{"unit":2,"hash":"e9fb3b5d6c10d5704f77b5ceb8b83db4da55d51793389f5c5d1ac968decb6146","die_size":{"input_value":null,"used_value":6.94,"status":"SET"},"model":{"input_value":"Xeon Gold 6148","used_value":"Xeon Gold 6148","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":150,"status":"SET"},"impacts":{"gwp":{"value":45.6,"unit":"kgCO2eq"},"pe":{"value":680.0,"unit":"MJ"},"adp":{"value":0.04,"unit":"kgSbeq"}}},"RAM-1":{"unit":1,"hash":"a34b138e4ee0b4c832576fe84c3ef50c4e9713ab83fe8269fdc4dbacfd382efb","capacity":{"input_value":32,"used_value":32,"status":"UNCHANGED"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":120.0,"unit":"kgCO2eq"},"pe":{"value":1500.0,"unit":"MJ"},"adp":{"value":0.0049,"unit":"kgSbeq"}}},"MOTHERBOARD-1":{"unit":1,"hash":"3a31a8fbd4b871719831ef11af93eefbb1c2afc0f62d850a31fb5475aac9336e","impacts":{"gwp":{"value":66.1,"unit":"kgCO2eq"},"pe":{"value":836.0,"unit":"MJ"},"adp":{"value":0.00369,"unit":"kgSbeq"}}},"ASSEMBLY-1":{"unit":1,"hash":"8bfe70a2b59691c050865455cc9cf1b561ec702e7cf930c1026a490964bbd364","impacts":{"gwp":{"value":6.68,"unit":"kgCO2eq"},"pe":{"value":68.6,"unit":"MJ"},"adp":{"value":1.41e-06,"unit":"kgSbeq"}}},"SSD-1":{"unit":1,"hash":"cb269039943b145f924c394acd2f665c10b23bddf954428af81bd8eccaff3d6a","capacity":{"input_value":null,"used_value":1000,"status":"SET"},"density":{"input_value":null,"used_value":48.5,"status":"SET"},"impacts":{"gwp":{"value":52.0,"unit":"kgCO2eq"},"pe":{"value":640.0,"unit":"MJ"},"adp":{"value":0.0019,"unit":"kgSbeq"}}},"POWER_SUPPLY-1":{"unit":2,"hash":"be84aabaaac41126e1bd93ec3c10b355c6c7534cf9e3d7337cef9d6d0bb116c6","unit_weight":{"input_value":null,"used_value":2.99,"status":"SET"},"impacts":{"gwp":{"value":145.32,"unit":"kgCO2eq"},"pe":{"value":2100.0,"unit":"MJ"},"adp":{"value":0.0496,"unit":"kgSbeq"}}},"CASE-1":{"unit":1,"hash":"d510a031d97870b128df7e34c32ed8264c7ac8f1786f012cce7f6dbf2a6ffebf","case_type":{"input_value":null,"used_value":"rack","status":"SET"},"impacts":{"gwp":{"value":150.0,"unit":"kgCO2eq"},"pe":{"value":2200.0,"unit":"MJ"},"adp":{"value":0.0202,"unit":"kgSbeq"}}}},"manufacture of one gpu":{"die_size":{"input_value":null,"used_value":8.15,"status":"SET"},"model":{"input_value":"NVIDIA Tesla V100 PCIe 32 GB","used_value":"NVIDIA Tesla V100 PCIe 32 GB","status":"UNCHANGED"},"tdp":{"input_value":null,"used_value":250,"status":"SET"},"memory_size":{"input_value":null,"used_value":32,"status":"SET"},"memory":{"capacity":{"input_value":null,"used_value":32,"status":"SET"},"density":{"input_value":null,"used_value":0.625,"status":"SET"},"impacts":{"gwp":{"value":120.0,"unit":"kgCO2eq"},"pe":{"value":1500.0,"unit":"MJ"},"adp":{"value":0.0049,"unit":"kgSbeq"}}},"impacts":{"gwp":{"value":100.0,"unit":"kgCO2eq"},"pe":{"value":2000.0,"unit":"MJ"},"adp":{"value":0.03,"unit":"kgSbeq"}}}}}



* replicating results from [Dinarelli2022toward]

Je commence à regarder pour essayer de retrouver leurs résultats. Pour
 l'instant, une première nouvelle rassurante c'est que j'arrive à
 passer des valeurs d'énergie aux valeurs
 d'équivalent carbone indiquées en utilisant l'intensité carbone indiquée.
Seul problème, ils ont visiblement fait une erreur dans la traduction
 entre français et anglais pour les valeurs de consommation
 énergétique
 pour la table 1. Si on lit 4,473 comme 4.473, on retrouve bien 4.473*51 = 228.123 g CO_2 e.
Maintenant reste à trouver des valeurs pour la consommation
énergétique cohérentes


on peut estimer que la partition de Jean Zay à 32 GB soit celle ci :

Avec la partition **gpu\_p2**, **gpu\_p2s** ou **gpu\_p2l** (partitions dédiées à la communauté IA), vous aurez accès aux ressources suivantes :

+   31 nœuds de calcul accélérés octo-GPU avec :
    +   2 processeurs Intel Cascade Lake 6226 (12 cœurs à 2,7 GHz), soit 24 cœurs par nœud
    +   20 nœuds à 384 Go de mémoire (avec **gpu\_p2** ou **gpu\_p2s**)
       +   11 nœuds à 768 Go de mémoire (avec **gpu\_p2** ou **gpu\_p2l**)
       +   8 GPU Nvidia Tesla V100 SXM2 32Go

Vu qu'après il est indiqué 4 GPU à 32 GB pour rappel, c'est peut-être celle ci :

+   612 nœuds de calcul accélérés quadri-GPU avec :
        +  2 processeurs Intel Cascade Lake 6248 (20 cœurs à 2,5 GHz), soit 40 cœurs par nœud
        +  192 Go de mémoire par nœud
        +  351 nœuds avec 4 GPU Nvidia Tesla V100 SXM2 16 Go (avec **v100-16g**)
        +  261 nœuds avec 4 GPU Nvidia Tesla V100 SXM2 32 Go (avec **v100-32g**)

En tout cas, sur le site de l'IDRIS, ce sont les deux seuls endroits
où des GPU avec 32GB de mémoire sont indiqués.




En tout cas, pour essayer de te donner les info dont tu as besoin, après si c'est pas ça, ou si tu as besoin d'autres informations, n'hésite pas à demander :
"CPU : nombre de coeurs utilisés, modèle" => je ne sais pas combien de coeur CPU sont utilisé par les modèles wav2vec que j'ai utilisé, mes modèles SLU en utilise un seul.
"GPU : nombre utilisés et modèles, mémoire utilisée" (je présume que tu voulais écrire "nombre de coeur utilisés") => 4 GPU pendant 100 heures pour fine-tuner le modèle wav2vec (seulement pour les expériences où il est fine-tuné évidemment), 1 seule GPU pour mes modèles SLU.

Pour la taille des modèles :
environ 308 millions de paramètres pour le modèle wav2vec2
environ 12 millions de paramètres pour le modèle SLU

Pour la mémoire utilisée, on est à environ 80GB de mémoire centrale (RAM de la CPU) et environ 8GB de mémoire GPU pour les entraînements des mes modèles SLU.
Pour le fine-tuning des modèles wav2vec je ne sais pas, je n'ai jamais regardé pendant l'apprentissage de ces modèles, je sais que ça passe pas sur les GPU à 24GB du LIG, du coup j'ai dû le faire sur JZ sur la partition de GPU à 32 GB.
Je présume que la plupart des GPU (4 GPU à 32GB pour rappel) est utilisé par le modèle et les gradients des paramètres, puisque l'apprentissage des modèles SLU sur les mêmes données passe sur des GPU à 12GB du LIG.
1:36 PM

Alors, sur JZ j'utilise les Tesla V100-SXM2-32GB .
Au LIG, pour les modèles SLU, j'utilise principalement des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go.
Il m'est arrivé d'utiliser parfois des NVIDIA TITAN X (Pascal) 12Go et des NVIDIA Quadro RTX 6000 24Go.

En fait au LIG c'est OAR qui gère les job, du coup ce n'est pas facile de monitorer exactement où le job est exécuté.
Je sais que si je lance sur une machine donné, ce que je fais parce
que OAR par défaut te met sur la première disponible et du coup tout
le monde se retrouve sur les mêmes machines, il y a telle ou telle
GPU, mais là je ne me rappelle pas dans quelle mesure je lance plus
sur une machine que sur une autre. À priori c'est 90%-95% du temps sur
des NVIDIA GTX 1080 Ti 12Go ou des NVIDIA RTX 2080 Ti 11Go en mesure
égale.
